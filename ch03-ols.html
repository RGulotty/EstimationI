<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3. Multivariate OLS – Estimation I: Computational Companion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8b4baf804e461d9b72633f0de59a0cac.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-3bbbbd466991e281563892c5dce73c3d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>
  MathJax = {
    tex: {
      macros: {
        E: "\\mathbb{E}",
        Var: "\\text{Var}",
        Cov: "\\text{Cov}",
        plim: "\\text{plim}",
        inprob: "\\xrightarrow{p}",
        indist: "\\xrightarrow{d}",
        bhat: "\\hat{\\boldsymbol{\\beta}}",
        N: "\\mathcal{N}",
        tr: "\\text{tr}",
        rank: "\\text{rank}",
        SE: "\\text{SE}",
        diag: "\\text{diag}"
      }
    }
  };
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Estimation I: Computational Companion</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-chapters" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Chapters</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-chapters">    
        <li>
    <a class="dropdown-item" href="./ch01-review.html">
 <span class="dropdown-text">1. Probability and Linear Algebra</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch02-cef-blp.html">
 <span class="dropdown-text">2. The CEF and Best Linear Predictor</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch03-ols.html">
 <span class="dropdown-text">3. Multivariate OLS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch04-sensitivity.html">
 <span class="dropdown-text">4. Sensitivity and Leverage</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch05-gls.html">
 <span class="dropdown-text">5. Efficiency and GLS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch06-small-sample.html">
 <span class="dropdown-text">6. Small Sample Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch07-probit.html">
 <span class="dropdown-text">7. Probit and MLE</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch08-asymptotics.html">
 <span class="dropdown-text">8. Asymptotics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch09-testing.html">
 <span class="dropdown-text">9. Hypothesis Testing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch10-iv.html">
 <span class="dropdown-text">10. Instrumental Variables and 2SLS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch11-gmm.html">
 <span class="dropdown-text">11. GMM</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch12-panel.html">
 <span class="dropdown-text">12. Panel Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch13-fixed-effects.html">
 <span class="dropdown-text">13. Fixed Effects and Modern DiD</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/UChicago-pol-methods/EstimationI"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#rs-matrix-toolkit" id="toc-rs-matrix-toolkit" class="nav-link active" data-scroll-target="#rs-matrix-toolkit"><span class="header-section-number">1</span> R’s matrix toolkit</a></li>
  <li><a href="#geometry-projection-in-two-dimensions" id="toc-geometry-projection-in-two-dimensions" class="nav-link" data-scroll-target="#geometry-projection-in-two-dimensions"><span class="header-section-number">2</span> Geometry: projection in two dimensions</a></li>
  <li><a href="#building-the-design-matrix" id="toc-building-the-design-matrix" class="nav-link" data-scroll-target="#building-the-design-matrix"><span class="header-section-number">3</span> Building the design matrix</a></li>
  <li><a href="#bivariate-ols-the-formula-connection" id="toc-bivariate-ols-the-formula-connection" class="nav-link" data-scroll-target="#bivariate-ols-the-formula-connection"><span class="header-section-number">4</span> Bivariate OLS: the formula connection</a></li>
  <li><a href="#sec-ols-derivation" id="toc-sec-ols-derivation" class="nav-link" data-scroll-target="#sec-ols-derivation"><span class="header-section-number">5</span> Deriving OLS with matrix calculus</a>
  <ul class="collapse">
  <li><a href="#the-second-order-condition" id="toc-the-second-order-condition" class="nav-link" data-scroll-target="#the-second-order-condition"><span class="header-section-number">5.1</span> The second-order condition</a></li>
  </ul></li>
  <li><a href="#what-collinearity-does-to-xx" id="toc-what-collinearity-does-to-xx" class="nav-link" data-scroll-target="#what-collinearity-does-to-xx"><span class="header-section-number">6</span> What collinearity does to <span class="math inline">\(X'X\)</span></a></li>
  <li><a href="#sec-projection-matrix" id="toc-sec-projection-matrix" class="nav-link" data-scroll-target="#sec-projection-matrix"><span class="header-section-number">7</span> The projection matrix</a>
  <ul class="collapse">
  <li><a href="#what-idempotency-means-for-eigenvalues" id="toc-what-idempotency-means-for-eigenvalues" class="nav-link" data-scroll-target="#what-idempotency-means-for-eigenvalues"><span class="header-section-number">7.1</span> What idempotency means for eigenvalues</a></li>
  <li><a href="#projection-onto-the-intercept" id="toc-projection-onto-the-intercept" class="nav-link" data-scroll-target="#projection-onto-the-intercept"><span class="header-section-number">7.2</span> Projection onto the intercept</a></li>
  </ul></li>
  <li><a href="#the-annihilator-matrix" id="toc-the-annihilator-matrix" class="nav-link" data-scroll-target="#the-annihilator-matrix"><span class="header-section-number">8</span> The annihilator matrix</a></li>
  <li><a href="#application-regression-to-the-mean" id="toc-application-regression-to-the-mean" class="nav-link" data-scroll-target="#application-regression-to-the-mean"><span class="header-section-number">9</span> Application: regression to the mean</a></li>
  <li><a href="#residuals-vs.-disturbances" id="toc-residuals-vs.-disturbances" class="nav-link" data-scroll-target="#residuals-vs.-disturbances"><span class="header-section-number">10</span> Residuals vs.&nbsp;disturbances</a></li>
  <li><a href="#estimating-sigma2-the-trace-trick" id="toc-estimating-sigma2-the-trace-trick" class="nav-link" data-scroll-target="#estimating-sigma2-the-trace-trick"><span class="header-section-number">11</span> Estimating <span class="math inline">\(\sigma^2\)</span>: the trace trick</a></li>
  <li><a href="#variance-of-hatbeta-building-s_e2xx-1" id="toc-variance-of-hatbeta-building-s_e2xx-1" class="nav-link" data-scroll-target="#variance-of-hatbeta-building-s_e2xx-1"><span class="header-section-number">12</span> Variance of <span class="math inline">\(\hat\beta\)</span>: building <span class="math inline">\(s_e^2(X'X)^{-1}\)</span></a>
  <ul class="collapse">
  <li><a href="#why-xx-1-determines-precision" id="toc-why-xx-1-determines-precision" class="nav-link" data-scroll-target="#why-xx-1-determines-precision"><span class="header-section-number">12.1</span> Why <span class="math inline">\((X'X)^{-1}\)</span> determines precision</a></li>
  </ul></li>
  <li><a href="#application-the-prestige-regression" id="toc-application-the-prestige-regression" class="nav-link" data-scroll-target="#application-the-prestige-regression"><span class="header-section-number">13</span> Application: the Prestige regression</a></li>
  <li><a href="#anova-as-inner-products" id="toc-anova-as-inner-products" class="nav-link" data-scroll-target="#anova-as-inner-products"><span class="header-section-number">14</span> ANOVA as inner products</a></li>
  <li><a href="#r2" id="toc-r2" class="nav-link" data-scroll-target="#r2"><span class="header-section-number">15</span> <span class="math inline">\(R^2\)</span></a></li>
  <li><a href="#naming-conventions-a-warning" id="toc-naming-conventions-a-warning" class="nav-link" data-scroll-target="#naming-conventions-a-warning"><span class="header-section-number">16</span> Naming conventions: a warning</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">17</span> Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">3. Multivariate OLS</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<p class="subtitle lead">Deriving and computing the OLS estimator</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(carData)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>tr <span class="ot">&lt;-</span> <span class="cf">function</span>(M) <span class="fu">sum</span>(<span class="fu">diag</span>(M))  <span class="co"># R has no built-in trace</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>The OLS estimator <span class="math inline">\(\hat\beta = (X'X)^{-1}X'y\)</span> is a matrix formula. Every piece of it — the transpose, the product, the inverse — has a direct R function. This chapter builds OLS from those building blocks, first geometrically in two dimensions, then in full matrix form with real data.</p>
<p><strong>Questions this chapter answers:</strong></p>
<ol type="1">
<li>What R functions implement matrix operations, and how does <code>crossprod()</code> relate to the normal equations?</li>
<li>What is the geometry of OLS — why is regression a projection?</li>
<li>How do we derive <span class="math inline">\(\hat\beta = (X'X)^{-1}X'y\)</span> from the minimization of SSE?</li>
<li>How do standard errors arise from <span class="math inline">\(s_e^2(X'X)^{-1}\)</span>, and what makes them precise or imprecise?</li>
</ol>
<section id="rs-matrix-toolkit" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="rs-matrix-toolkit"><span class="header-section-number">1</span> R’s matrix toolkit</h2>
<p>Before deriving anything, here are the operations we’ll use throughout.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">3</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>A</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]    2    1
[2,]    1    3</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Transpose: t()</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">t</span>(A)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]    2    1
[2,]    1    3</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Matrix multiply: %*%  (not * which is element-wise)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>A <span class="sc">%*%</span> B</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]    2    0
[2,]    1    5</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Inverse: solve()</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">solve</span>(A)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]  0.6 -0.2
[2,] -0.2  0.4</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>A <span class="sc">%*%</span> <span class="fu">solve</span>(A)  <span class="co"># identity</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1] [,2]
[1,]  1.00e+00    0
[2,] -1.11e-16    1</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Trace: sum(diag())</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">tr</span>(A)   <span class="co"># sum of diagonal elements</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Eigendecomposition: eigen()</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">eigen</span>(A)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>eigen() decomposition
$values
[1] 3.62 1.38

$vectors
      [,1]   [,2]
[1,] 0.526 -0.851
[2,] 0.851  0.526</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Determinant: det()</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">det</span>(A)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Cross product shortcuts</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>x_vec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>y_vec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">manual =</span> <span class="fu">sum</span>(x_vec <span class="sc">*</span> y_vec),</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">crossprod =</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(x_vec, y_vec)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>   manual crossprod 
       32        32 </code></pre>
</div>
</div>
<p><code>crossprod(X)</code> computes <span class="math inline">\(X'X\)</span> faster than <code>t(X) %*% X</code>, and <code>crossprod(X, y)</code> computes <span class="math inline">\(X'y\)</span>. We’ll use these constantly.</p>
</section>
<section id="geometry-projection-in-two-dimensions" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="geometry-projection-in-two-dimensions"><span class="header-section-number">2</span> Geometry: projection in two dimensions</h2>
<p>You’re used to plotting data with variables on the axes — one axis for <span class="math inline">\(X\)</span>, one for <span class="math inline">\(Y\)</span>, and each point is an observation. The geometric view of regression flips this: each axis is an <em>observation</em>, and each variable is a <em>vector</em>. A variable with <span class="math inline">\(n\)</span> observations is a vector in <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
<p>Why think this way? Because regression asks: among all scalar multiples of <span class="math inline">\(\mathbf{x}\)</span> (all predictions of the form <span class="math inline">\(b\mathbf{x}\)</span>), which one is closest to <span class="math inline">\(\mathbf{y}\)</span>? That’s a projection — dropping a perpendicular from <span class="math inline">\(\mathbf{y}\)</span> onto the line spanned by <span class="math inline">\(\mathbf{x}\)</span>.</p>
<p>With just two observations, we can see this on a page. Suppose we survey two students: we record how long each spent on homework (<span class="math inline">\(\mathbf{h}\)</span>) and how long reading the textbook (<span class="math inline">\(\mathbf{t}\)</span>). Each variable is a 2-vector, and we can plot both in <span class="math inline">\(\mathbb{R}^2\)</span>:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Student 1: 3 hrs homework, 2.5 hrs reading</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Student 2: 5 hrs homework, 2 hrs reading</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">5</span>)    <span class="co"># outcome: homework time</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>tt <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">2.5</span>, <span class="dv">2</span>)  <span class="co"># predictor: reading time</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>We want to predict <span class="math inline">\(\mathbf{h}\)</span> using <span class="math inline">\(\mathbf{t}\)</span>: find <span class="math inline">\(b\)</span> so that <span class="math inline">\(b\mathbf{t}\)</span> is as close to <span class="math inline">\(\mathbf{h}\)</span> as possible. Geometrically, <span class="math inline">\(b\mathbf{t}\)</span> must lie on the line through <span class="math inline">\(\mathbf{t}\)</span> (the dotted line in the plot below), and the best choice is the one where the “miss” — the residual — is perpendicular to that line.</p>
<p>The <strong>vector projection</strong> of <span class="math inline">\(\mathbf{h}\)</span> onto <span class="math inline">\(\mathbf{t}\)</span> solves this:</p>
<p><span class="math display">\[\hat{\mathbf{h}} = \frac{\mathbf{t} \cdot \mathbf{h}}{\mathbf{t} \cdot \mathbf{t}} \mathbf{t}\]</span></p>
<p>The scalar <span class="math inline">\(b = \frac{\mathbf{t} \cdot \mathbf{h}}{\mathbf{t} \cdot \mathbf{t}}\)</span> minimizes <span class="math inline">\(\|\mathbf{h} - b\mathbf{t}\|^2\)</span> — the sum of squared errors. This is the least squares solution, derived purely from geometry.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The projection coefficient</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(tt, h) <span class="sc">/</span> <span class="fu">crossprod</span>(tt))</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>b</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.71</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The projected vector (fitted values)</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>h_hat <span class="ot">&lt;-</span> b <span class="sc">*</span> tt</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>h_hat</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4.27 3.41</code></pre>
</div>
</div>
<p>And this is exactly what <code>lm()</code> computes when we regress <span class="math inline">\(\mathbf{h}\)</span> on <span class="math inline">\(\mathbf{t}\)</span> without an intercept:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS without intercept gives the same b</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(h <span class="sc">~</span> tt <span class="sc">-</span> <span class="dv">1</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>  tt 
1.71 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitted values = the projection</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">projection =</span> h_hat, <span class="at">fitted =</span> <span class="fu">fitted</span>(<span class="fu">lm</span>(h <span class="sc">~</span> tt <span class="sc">-</span> <span class="dv">1</span>)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>  projection fitted
1       4.27   4.27
2       3.41   3.41</code></pre>
</div>
</div>
<p>The residual <span class="math inline">\(\mathbf{e} = \mathbf{h} - \hat{\mathbf{h}}\)</span> is orthogonal to <span class="math inline">\(\mathbf{t}\)</span> — their dot product is zero:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>e_vec <span class="ot">&lt;-</span> h <span class="sc">-</span> h_hat</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(tt, e_vec))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -4.44e-16</code></pre>
</div>
</div>
<p>This orthogonality is the geometric content of the normal equations <span class="math inline">\(X'e = 0\)</span>. Here’s the full picture:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>df_arrows <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x0 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, h_hat[<span class="dv">1</span>]),</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y0 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, h_hat[<span class="dv">2</span>]),</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">c</span>(h[<span class="dv">1</span>], tt[<span class="dv">1</span>], h_hat[<span class="dv">1</span>], h[<span class="dv">1</span>]),</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">y1 =</span> <span class="fu">c</span>(h[<span class="dv">2</span>], tt[<span class="dv">2</span>], h_hat[<span class="dv">2</span>], h[<span class="dv">2</span>]),</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">label =</span> <span class="fu">c</span>(<span class="st">"h (outcome)"</span>, <span class="st">"t (regressor)"</span>, <span class="st">"h-hat (fitted)"</span>, <span class="st">"e (residual)"</span>),</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">color =</span> <span class="fu">c</span>(<span class="st">"black"</span>, <span class="st">"gray50"</span>, <span class="st">"forestgreen"</span>, <span class="st">"tomato"</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>slope_t <span class="ot">&lt;-</span> tt[<span class="dv">2</span>] <span class="sc">/</span> tt[<span class="dv">1</span>]</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> slope_t, <span class="at">linetype =</span> <span class="st">"dotted"</span>, <span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">data =</span> df_arrows,</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>               <span class="fu">aes</span>(<span class="at">x =</span> x0, <span class="at">y =</span> y0, <span class="at">xend =</span> x1, <span class="at">yend =</span> y1, <span class="at">color =</span> label),</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>               <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">length =</span> <span class="fu">unit</span>(<span class="fl">0.15</span>, <span class="st">"inches"</span>)),</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>               <span class="at">linewidth =</span> <span class="fl">1.1</span>) <span class="sc">+</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"h (outcome)"</span> <span class="ot">=</span> <span class="st">"black"</span>,</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"t (regressor)"</span> <span class="ot">=</span> <span class="st">"gray50"</span>,</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"h-hat (fitted)"</span> <span class="ot">=</span> <span class="st">"forestgreen"</span>,</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"e (residual)"</span> <span class="ot">=</span> <span class="st">"tomato"</span>),</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>                     <span class="at">name =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_fixed</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">5</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">6</span>)) <span class="sc">+</span></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Observation 1"</span>, <span class="at">y =</span> <span class="st">"Observation 2"</span>,</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"OLS finds the closest point on the line of t to h"</span>) <span class="sc">+</span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch03-ols_files/figure-html/geometry-plot-1.png" class="img-fluid figure-img" width="480"></p>
<figcaption>OLS finds the closest point on the line of t to h</figcaption>
</figure>
</div>
</div>
</div>
<p>The green vector (<span class="math inline">\(\hat{\mathbf{h}}\)</span>) is the best prediction in the “column space” of <span class="math inline">\(\mathbf{t}\)</span>, and the red vector (<span class="math inline">\(\mathbf{e}\)</span>) is the part of <span class="math inline">\(\mathbf{h}\)</span> that <span class="math inline">\(\mathbf{t}\)</span> cannot explain. With <span class="math inline">\(n = 100\)</span> observations, these vectors live in <span class="math inline">\(\mathbb{R}^{100}\)</span> and we can’t draw them — but the geometry is identical. With multiple regressors, the “line” becomes a plane (or hyperplane), and the projection lands on the closest point in that plane.</p>
</section>
<section id="building-the-design-matrix" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="building-the-design-matrix"><span class="header-section-number">3</span> Building the design matrix</h2>
<p>The model <span class="math inline">\(y = X\beta + e\)</span> stacks <span class="math inline">\(n\)</span> observations into a matrix. Each row of <span class="math inline">\(X\)</span> is one observation; each column is one variable. The first column is typically all ones (the intercept).</p>
<p>We’ll use the Canadian Prestige dataset: the Pineo-Porter prestige score of occupations, predicted by average education (years) and average income (dollars) of workers in each occupation.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Prestige)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(Prestige)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="dv">3</span>  <span class="co"># intercept + education + income</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, Prestige<span class="sc">$</span>education, Prestige<span class="sc">$</span>income)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> Prestige<span class="sc">$</span>prestige</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(X)   <span class="co"># n x K</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 102   3</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(X)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]  [,3]
[1,]    1 13.1 12351
[2,]    1 12.3 25879
[3,]    1 12.8  9271
[4,]    1 11.4  8865
[5,]    1 14.6  8403
[6,]    1 15.6 11030</code></pre>
</div>
</div>
<p>The two fundamental products in OLS are <span class="math inline">\(X'X\)</span> (a <span class="math inline">\(K \times K\)</span> matrix) and <span class="math inline">\(X'y\)</span> (a <span class="math inline">\(K \times 1\)</span> vector):</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>XtX <span class="ot">&lt;-</span> <span class="fu">crossprod</span>(X)       <span class="co"># K x K: t(X) %*% X</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>XtX</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>       [,1]    [,2]     [,3]
[1,]    102    1095 6.93e+05
[2,]   1095   12513 8.12e+06
[3,] 693386 8121410 6.53e+09</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>Xty <span class="ot">&lt;-</span> <span class="fu">crossprod</span>(X, y)    <span class="co"># K x 1: t(X) %*% y</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>Xty</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>         [,1]
[1,]     4777
[2,]    55326
[3,] 37748108</code></pre>
</div>
</div>
<p><span class="math inline">\(X'X\)</span> encodes the relationships among the regressors. The diagonal holds <span class="math inline">\(\sum X_k^2\)</span> for each variable; the off-diagonals hold <span class="math inline">\(\sum X_j X_k\)</span>. Dividing by <span class="math inline">\(n\)</span> gives the sample second-moment matrix.</p>
</section>
<section id="bivariate-ols-the-formula-connection" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="bivariate-ols-the-formula-connection"><span class="header-section-number">4</span> Bivariate OLS: the formula connection</h2>
<p>Before the matrix derivation, recall the bivariate OLS formula: <span class="math inline">\(\hat\beta_1 = \text{Cov}(X, Y)/\text{Var}(X)\)</span>. This is the sample analogue of the BLP coefficient from Chapter 2. Let’s verify it matches the matrix formula using just education as a predictor:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>educ <span class="ot">&lt;-</span> Prestige<span class="sc">$</span>education</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Formula approach</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>beta1_formula <span class="ot">&lt;-</span> <span class="fu">cov</span>(educ, y) <span class="sc">/</span> <span class="fu">var</span>(educ)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>beta0_formula <span class="ot">&lt;-</span> <span class="fu">mean</span>(y) <span class="sc">-</span> beta1_formula <span class="sc">*</span> <span class="fu">mean</span>(educ)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Matrix approach (2x2 system)</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>X_biv <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, educ)</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>beta_biv <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X_biv), <span class="fu">crossprod</span>(X_biv, y))</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="co"># lm() approach</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>beta_lm <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(prestige <span class="sc">~</span> education, <span class="at">data =</span> Prestige))</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">formula =</span> <span class="fu">c</span>(beta0_formula, beta1_formula),</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">matrix =</span> beta_biv,</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">lm =</span> beta_lm)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>     formula            lm
      -10.73 -10.73 -10.73
educ    5.36   5.36   5.36</code></pre>
</div>
</div>
<p>All three give the same answer. The matrix formula <span class="math inline">\(\hat\beta = (X'X)^{-1}X'y\)</span> generalizes the bivariate <span class="math inline">\(\text{Cov}/\text{Var}\)</span> formula to any number of regressors.</p>
</section>
<section id="sec-ols-derivation" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="sec-ols-derivation"><span class="header-section-number">5</span> Deriving OLS with matrix calculus</h2>
<p>The sum of squared errors in matrix form is:</p>
<p><span id="eq-ols"><span class="math display">\[\text{SSE}(\beta) = (y - X\beta)'(y - X\beta) = \underbrace{y'y}_{\text{constant}} - \underbrace{2y'X\beta}_{\text{linear}} + \underbrace{\beta'X'X\beta}_{\text{quadratic}} \tag{1}\]</span></span></p>
<p>Let’s build each piece in R and verify the expansion:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>beta_test <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.001</span>)  <span class="co"># an arbitrary beta to test</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Direct computation</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>sse_direct <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(y <span class="sc">-</span> X <span class="sc">%*%</span> beta_test))</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Expanded form</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>piece1 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(y))                         <span class="co"># y'y</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>piece2 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="dv">2</span> <span class="sc">*</span> <span class="fu">crossprod</span>(y, X <span class="sc">%*%</span> beta_test))    <span class="co"># 2y'Xbeta</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>piece3 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">t</span>(beta_test) <span class="sc">%*%</span> XtX <span class="sc">%*%</span> beta_test)  <span class="co"># beta'X'Xbeta</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">direct =</span> sse_direct, <span class="at">expanded =</span> piece1 <span class="sc">-</span> piece2 <span class="sc">+</span> piece3)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>  direct expanded 
  102760   102760 </code></pre>
</div>
</div>
<p>Setting <span class="math inline">\(\partial \text{SSE}/\partial \beta = -2X'y + 2X'X\hat\beta = 0\)</span> gives the <strong>normal equations</strong>:</p>
<p><span id="eq-normal-equations"><span class="math display">\[X'X\hat\beta = X'y \tag{2}\]</span></span></p>
<p>Solving with <code>solve()</code>:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># solve(A, b) solves the system Ax = b — better than solve(A) %*% b</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>beta_hat <span class="ot">&lt;-</span> <span class="fu">solve</span>(XtX, Xty)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>beta_hat</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>         [,1]
[1,] -6.84778
[2,]  4.13744
[3,]  0.00136</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># lm() gives the same thing</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income, <span class="at">data =</span> Prestige))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)   education      income 
   -6.84778     4.13744     0.00136 </code></pre>
</div>
</div>
<p>Note: <code>solve(A, b)</code> is preferred over <code>solve(A) %*% b</code> — it avoids computing the full inverse, which is slower and less numerically stable.</p>
<div id="thm-ols" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (The OLS Estimator)</strong></span> The OLS estimator <span class="math inline">\(\hat\beta = (X'X)^{-1}X'y\)</span> is the unique minimizer of <span class="math inline">\(\text{SSE}(\beta) = (y - X\beta)'(y - X\beta)\)</span> when <span class="math inline">\(X'X\)</span> is positive definite.</p>
</div>
<section id="the-second-order-condition" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="the-second-order-condition"><span class="header-section-number">5.1</span> The second-order condition</h3>
<p>The second derivative of <span class="math inline">\(\text{SSE}\)</span> is <span class="math inline">\(2X'X\)</span>. This is a minimum when <span class="math inline">\(X'X\)</span> is positive definite — all eigenvalues are positive:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">eigen</span>(XtX)<span class="sc">$</span>values</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6.53e+09 2.44e+03 5.83e+00</code></pre>
</div>
</div>
<p>All positive, confirming positive definiteness. If any eigenvalue were zero, <span class="math inline">\(X'X\)</span> would be singular and <code>solve()</code> would fail.</p>
</section>
</section>
<section id="what-collinearity-does-to-xx" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="what-collinearity-does-to-xx"><span class="header-section-number">6</span> What collinearity does to <span class="math inline">\(X'X\)</span></h2>
<p>When a column of <span class="math inline">\(X\)</span> is a linear combination of others, <span class="math inline">\(X'X\)</span> loses rank:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a redundant column: income2 = 2 * income</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>X_bad <span class="ot">&lt;-</span> <span class="fu">cbind</span>(X, <span class="dv">2</span> <span class="sc">*</span> Prestige<span class="sc">$</span>income)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>XtX_bad <span class="ot">&lt;-</span> <span class="fu">crossprod</span>(X_bad)</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="fu">det</span>(XtX_bad)          <span class="co"># essentially zero</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">eigen</span>(XtX_bad)<span class="sc">$</span>values  <span class="co"># last eigenvalue collapses</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.27e+10 2.44e+03 5.83e+00 4.55e-13</code></pre>
</div>
</div>
<p>In practice, <em>near</em>-collinearity (very small but nonzero eigenvalues) inflates standard errors without crashing <code>solve()</code>. The <strong>condition number</strong> — ratio of largest to smallest eigenvalue — measures how close to singular:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>evals <span class="ot">&lt;-</span> <span class="fu">eigen</span>(XtX)<span class="sc">$</span>values</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">largest =</span> evals[<span class="dv">1</span>], <span class="at">smallest =</span> evals[K], <span class="at">condition =</span> evals[<span class="dv">1</span>] <span class="sc">/</span> evals[K])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>  largest  smallest condition 
 6.53e+09  5.83e+00  1.12e+09 </code></pre>
</div>
</div>
<p>R’s <code>lm()</code> handles exact collinearity by dropping the redundant column:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> <span class="fu">I</span>(<span class="dv">2</span> <span class="sc">*</span> income), <span class="at">data =</span> Prestige))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>  (Intercept)     education        income I(2 * income) 
     -6.84778       4.13744       0.00136            NA </code></pre>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Near-Collinearity Inflates Standard Errors
</div>
</div>
<div class="callout-body-container callout-body">
<p>When columns of <span class="math inline">\(X\)</span> are nearly linearly dependent, <span class="math inline">\(X'X\)</span> has a near-zero eigenvalue, making <span class="math inline">\((X'X)^{-1}\)</span> very large. This inflates the variance of <span class="math inline">\(\hat\beta\)</span> without causing <code>solve()</code> to fail — standard errors balloon silently. Check the condition number of <span class="math inline">\(X'X\)</span> to detect this.</p>
</div>
</div>
</section>
<section id="sec-projection-matrix" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="sec-projection-matrix"><span class="header-section-number">7</span> The projection matrix</h2>
<p>The projection matrix <span class="math inline">\(P = X(X'X)^{-1}X'\)</span> maps any <span class="math inline">\(n\)</span>-vector onto the column space of <span class="math inline">\(X\)</span>. In two dimensions (our earlier example), it projected <span class="math inline">\(\mathbf{h}\)</span> onto the line of <span class="math inline">\(\mathbf{t}\)</span>. With <span class="math inline">\(K = 3\)</span> regressors, it projects <span class="math inline">\(\mathbf{y}\)</span> onto a 3-dimensional subspace of <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> X <span class="sc">%*%</span> <span class="fu">solve</span>(XtX) <span class="sc">%*%</span> <span class="fu">t</span>(X)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(P)  <span class="co"># n x n</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 102 102</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income, <span class="at">data =</span> Prestige)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="def-projection-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 (Projection (Hat) Matrix)</strong></span> The projection matrix <span class="math inline">\(P = X(X'X)^{-1}X'\)</span> maps any <span class="math inline">\(n\)</span>-vector onto the column space of <span class="math inline">\(X\)</span>. It is symmetric (<span class="math inline">\(P' = P\)</span>) and idempotent (<span class="math inline">\(P^2 = P\)</span>), with eigenvalues in <span class="math inline">\(\{0, 1\}\)</span> and <span class="math inline">\(\text{tr}(P) = K\)</span>.</p>
</div>
<p>Every property of <span class="math inline">\(P\)</span> corresponds to a matrix operation:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P*y = fitted values</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.vector</span>(P <span class="sc">%*%</span> y), <span class="fu">as.numeric</span>(<span class="fu">fitted</span>(mod)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Symmetric: t(P) = P</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">t</span>(P), P)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Idempotent: P %*% P = P (projecting twice = projecting once)</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(P <span class="sc">%*%</span> P, P)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P*X = X (X is already in its own column space)</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(P <span class="sc">%*%</span> X, X, <span class="at">check.attributes =</span> <span class="cn">FALSE</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
<section id="what-idempotency-means-for-eigenvalues" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="what-idempotency-means-for-eigenvalues"><span class="header-section-number">7.1</span> What idempotency means for eigenvalues</h3>
<p>If <span class="math inline">\(Pv = \lambda v\)</span>, then <span class="math inline">\(P^2 v = \lambda^2 v\)</span>. But <span class="math inline">\(P^2 = P\)</span>, so <span class="math inline">\(\lambda^2 = \lambda\)</span>, which means <span class="math inline">\(\lambda \in \{0, 1\}\)</span>:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>eig_P <span class="ot">&lt;-</span> <span class="fu">eigen</span>(P)<span class="sc">$</span>values</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">round</span>(eig_P, <span class="dv">10</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
 0  1 
99  3 </code></pre>
</div>
</div>
<p><span class="math inline">\(K\)</span> eigenvalues equal 1 (the column space of <span class="math inline">\(X\)</span>) and <span class="math inline">\(n - K\)</span> equal 0 (the null space). The trace counts the 1s:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">trace_P =</span> <span class="fu">tr</span>(P), <span class="at">K =</span> K)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>trace_P       K 
      3       3 </code></pre>
</div>
</div>
</section>
<section id="projection-onto-the-intercept" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="projection-onto-the-intercept"><span class="header-section-number">7.2</span> Projection onto the intercept</h3>
<p>The simplest projection is onto a column of ones: <span class="math inline">\(P_1 = \mathbf{1}(\mathbf{1}'\mathbf{1})^{-1}\mathbf{1}' = \frac{1}{n}\mathbf{1}\mathbf{1}'\)</span>. This projects every observation onto the sample mean:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>ones <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, n)</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>P1 <span class="ot">&lt;-</span> <span class="fu">outer</span>(ones, ones) <span class="sc">/</span> n  <span class="co"># outer product: 1*1' / n</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="co"># P1 * y = sample mean for every observation</span></span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.vector</span>(P1 <span class="sc">%*%</span> y), <span class="fu">rep</span>(<span class="fu">mean</span>(y), n))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
<p>Every additional regressor refines this baseline: the full <span class="math inline">\(P\)</span> starts from the mean and adds the directions explained by the other columns of <span class="math inline">\(X\)</span>.</p>
</section>
</section>
<section id="the-annihilator-matrix" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="the-annihilator-matrix"><span class="header-section-number">8</span> The annihilator matrix</h2>
<p>The annihilator <span class="math inline">\(M = I_n - P\)</span> projects onto the orthogonal complement — the part of <span class="math inline">\(y\)</span> that <span class="math inline">\(X\)</span> cannot explain:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>M <span class="ot">&lt;-</span> <span class="fu">diag</span>(n) <span class="sc">-</span> P</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="co"># M*y = residuals</span></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.vector</span>(M <span class="sc">%*%</span> y), <span class="fu">as.numeric</span>(<span class="fu">resid</span>(mod)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Idempotent and symmetric</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(M <span class="sc">%*%</span> M, M)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">t</span>(M), M)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># M annihilates X: M*X = 0</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">abs</span>(M <span class="sc">%*%</span> X))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4.82e-11</code></pre>
</div>
</div>
<div id="def-annihilator" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2 (Annihilator Matrix)</strong></span> The annihilator <span class="math inline">\(M = I_n - P\)</span> projects onto the orthogonal complement of the column space of <span class="math inline">\(X\)</span>. It satisfies <span class="math inline">\(MX = 0\)</span> (annihilates <span class="math inline">\(X\)</span>), is idempotent and symmetric, and has <span class="math inline">\(\text{tr}(M) = n - K\)</span>.</p>
</div>
<p>Eigenvalues are complementary to <span class="math inline">\(P\)</span>: <span class="math inline">\(n - K\)</span> ones and <span class="math inline">\(K\)</span> zeros:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">trace_M =</span> <span class="fu">tr</span>(M), <span class="at">n_minus_K =</span> n <span class="sc">-</span> K)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>  trace_M n_minus_K 
       99        99 </code></pre>
</div>
</div>
<p>The <strong>demeaning matrix</strong> <span class="math inline">\(M_1 = I - P_1\)</span> is a special case — it subtracts the mean:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb85"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>M1 <span class="ot">&lt;-</span> <span class="fu">diag</span>(n) <span class="sc">-</span> P1</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.vector</span>(M1 <span class="sc">%*%</span> y), <span class="fu">as.numeric</span>(y <span class="sc">-</span> <span class="fu">mean</span>(y)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
</section>
<section id="application-regression-to-the-mean" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="application-regression-to-the-mean"><span class="header-section-number">9</span> Application: regression to the mean</h2>
<p>Here’s a classic application of bivariate OLS. Galton noticed that children of unusually tall parents tend to be shorter than their parents — and children of unusually short parents tend to be taller. This “regression to the mean” is not a causal mechanism; it’s a consequence of the BLP slope being less than 1 when the correlation is less than 1.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb87"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate parent-child heights (jointly normal)</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">307</span>)</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>n_ht <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.5</span>   <span class="co"># correlation between parent and child height</span></span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>heights <span class="ot">&lt;-</span> <span class="fu">mvrnorm</span>(n_ht, <span class="at">mu =</span> <span class="fu">c</span>(<span class="dv">68</span>, <span class="dv">68</span>),</span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a>                   <span class="at">Sigma =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">9</span>, rho <span class="sc">*</span> <span class="dv">9</span>, rho <span class="sc">*</span> <span class="dv">9</span>, <span class="dv">9</span>), <span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>parent_ht <span class="ot">&lt;-</span> heights[, <span class="dv">1</span>]</span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>child_ht <span class="ot">&lt;-</span> heights[, <span class="dv">2</span>]</span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS by matrix formula</span></span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a>X_ht <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, parent_ht)</span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a>beta_ht <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X_ht), <span class="fu">crossprod</span>(X_ht, child_ht))</span>
<span id="cb87-15"><a href="#cb87-15" aria-hidden="true" tabindex="-1"></a>beta_ht</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>            [,1]
          37.065
parent_ht  0.456</code></pre>
</div>
</div>
<p>The slope is <span class="math inline">\(\hat\beta_1 \approx\)</span> 0.46, less than 1. So a parent who is 1 inch above average has a child who is only about 0.46 inches above average — regression toward the mean.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb89"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>df_ht <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">parent =</span> parent_ht, <span class="at">child =</span> child_ht)</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_ht, <span class="fu">aes</span>(parent, child)) <span class="sc">+</span></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.15</span>, <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"steelblue"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">74</span>, <span class="at">y =</span> <span class="fl">74.5</span>, <span class="at">label =</span> <span class="st">"slope = 1 (no regression)"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Parent height (in)"</span>, <span class="at">y =</span> <span class="st">"Child height (in)"</span>,</span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Regression to the mean"</span>,</span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">paste0</span>(<span class="st">"Slope = "</span>, <span class="fu">round</span>(beta_ht[<span class="dv">2</span>], <span class="dv">2</span>),</span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a>                         <span class="st">" &lt; 1: children of tall parents are less extreme"</span>)) <span class="sc">+</span></span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch03-ols_files/figure-html/regression-to-mean-plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The tallest parents (above the 95th percentile) have children who are closer to the mean:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>tall <span class="ot">&lt;-</span> parent_ht <span class="sc">&gt;</span> <span class="fu">quantile</span>(parent_ht, <span class="fl">0.95</span>)</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">parent_mean =</span> <span class="fu">mean</span>(parent_ht[tall]),</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">child_mean =</span> <span class="fu">mean</span>(child_ht[tall]),</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">difference =</span> <span class="fu">mean</span>(parent_ht[tall]) <span class="sc">-</span> <span class="fu">mean</span>(child_ht[tall]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>parent_mean  child_mean  difference 
      74.19       71.15        3.04 </code></pre>
</div>
</div>
</section>
<section id="residuals-vs.-disturbances" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="residuals-vs.-disturbances"><span class="header-section-number">10</span> Residuals vs.&nbsp;disturbances</h2>
<p>The true model is <span class="math inline">\(y = X\beta + e\)</span> where <span class="math inline">\(e\)</span> is unobservable. The residuals <span class="math inline">\(\hat{e} = My\)</span> relate to the disturbances through:</p>
<p><span class="math display">\[\hat{e} = My = M(X\beta + e) = \underbrace{MX}_{= 0}\beta + Me = Me\]</span></p>
<p>Let’s simulate to see this. We know <span class="math inline">\(\beta\)</span> and <span class="math inline">\(e\)</span> because we generate the data:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb93"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">307</span>)</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>n_sim <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>K_sim <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>X_sim <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, <span class="fu">rnorm</span>(n_sim))</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>beta_true <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>e_true <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_sim, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>y_sim <span class="ot">&lt;-</span> X_sim <span class="sc">%*%</span> beta_true <span class="sc">+</span> e_true</span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Build M for this design</span></span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>P_sim <span class="ot">&lt;-</span> X_sim <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X_sim)) <span class="sc">%*%</span> <span class="fu">t</span>(X_sim)</span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a>M_sim <span class="ot">&lt;-</span> <span class="fu">diag</span>(n_sim) <span class="sc">-</span> P_sim</span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Residuals = M * disturbances</span></span>
<span id="cb93-14"><a href="#cb93-14" aria-hidden="true" tabindex="-1"></a>e_hat <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(M_sim <span class="sc">%*%</span> y_sim)</span>
<span id="cb93-15"><a href="#cb93-15" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(e_hat, <span class="fu">as.vector</span>(M_sim <span class="sc">%*%</span> e_true))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Residuals have smaller variance — M zeroes out K dimensions</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">var_disturbances =</span> <span class="fu">var</span>(e_true), <span class="at">var_residuals =</span> <span class="fu">var</span>(e_hat))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>var_disturbances    var_residuals 
             4.5              4.5 </code></pre>
</div>
</div>
</section>
<section id="estimating-sigma2-the-trace-trick" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="estimating-sigma2-the-trace-trick"><span class="header-section-number">11</span> Estimating <span class="math inline">\(\sigma^2\)</span>: the trace trick</h2>
<p>The natural estimator <span class="math inline">\(\hat\sigma^2 = \hat{e}'\hat{e}/n\)</span> is biased downward because <span class="math inline">\(\hat{e}'\hat{e} = e'Me \leq e'e\)</span> (<span class="math inline">\(M\)</span> is positive semi-definite). The unbiased estimator divides by <span class="math inline">\(n - K\)</span>.</p>
<p>The proof is a chain of matrix operations. Every step translates to R:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb97"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: e'Me is a scalar = its own trace</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>scalar_form <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">t</span>(e_true) <span class="sc">%*%</span> M_sim <span class="sc">%*%</span> e_true)</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>trace_form <span class="ot">&lt;-</span> <span class="fu">tr</span>(M_sim <span class="sc">%*%</span> <span class="fu">tcrossprod</span>(e_true))  <span class="co"># tr(M * ee')</span></span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">scalar =</span> scalar_form, <span class="at">trace =</span> trace_form)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>scalar  trace 
   445    445 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb99"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: E[ee'] = sigma^2 * I, so E[tr(Mee')] = sigma^2 * tr(M)</span></span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="co"># tr(M) = n - K, so E[e'hat * e'hat] = sigma^2 * (n - K)</span></span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">trace_M =</span> <span class="fu">tr</span>(M_sim), <span class="at">n_minus_K =</span> n_sim <span class="sc">-</span> K_sim)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>  trace_M n_minus_K 
       98        98 </code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>The <span class="math inline">\(n - K\)</span> Divisor
</div>
</div>
<div class="callout-body-container callout-body">
<p>The unbiased variance estimator divides by <span class="math inline">\(n - K\)</span> (not <span class="math inline">\(n\)</span>) because the residuals live in an <span class="math inline">\((n - K)\)</span>-dimensional subspace. The <span class="math inline">\(K\)</span> “lost” dimensions are consumed by estimating <span class="math inline">\(\hat\beta\)</span>. This is the matrix version of Bessel’s correction.</p>
</div>
</div>
<p>This is why the unbiased estimator is <span class="math inline">\(s_e^2 = \hat{e}'\hat{e}/(n-K)\)</span>:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb101"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Back to the Prestige data</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>e_hat_prestige <span class="ot">&lt;-</span> <span class="fu">resid</span>(mod)</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>sigma2_biased <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(e_hat_prestige)) <span class="sc">/</span> n</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>sigma2_unbiased <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(e_hat_prestige)) <span class="sc">/</span> (n <span class="sc">-</span> K)</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">biased =</span> sigma2_biased,</span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">unbiased =</span> sigma2_unbiased,</span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">R_sigma2 =</span> <span class="fu">sigma</span>(mod)<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>  biased unbiased R_sigma2 
    59.2     61.0     61.0 </code></pre>
</div>
</div>
<p>The underestimation shows up in the eigenvalues of <span class="math inline">\(M\)</span>: <span class="math inline">\(n - K\)</span> eigenvalues are 1, and <span class="math inline">\(K\)</span> are 0. The residuals live in an <span class="math inline">\((n-K)\)</span>-dimensional subspace:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb103"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>eig_M <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">eigen</span>(M)<span class="sc">$</span>values, <span class="dv">10</span>)</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">eigenvalues_equal_1 =</span> <span class="fu">sum</span>(eig_M <span class="sc">==</span> <span class="dv">1</span>),</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">eigenvalues_equal_0 =</span> <span class="fu">sum</span>(eig_M <span class="sc">==</span> <span class="dv">0</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>eigenvalues_equal_1 eigenvalues_equal_0 
                 99                   3 </code></pre>
</div>
</div>
</section>
<section id="variance-of-hatbeta-building-s_e2xx-1" class="level2" data-number="12">
<h2 data-number="12" class="anchored" data-anchor-id="variance-of-hatbeta-building-s_e2xx-1"><span class="header-section-number">12</span> Variance of <span class="math inline">\(\hat\beta\)</span>: building <span class="math inline">\(s_e^2(X'X)^{-1}\)</span></h2>
<p>Under homoskedasticity, <span class="math inline">\(\text{Var}(\hat\beta|X) = \sigma^2(X'X)^{-1}\)</span>. Each piece is a matrix operation:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb105"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: (X'X)^{-1}</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>XtX_inv <span class="ot">&lt;-</span> <span class="fu">solve</span>(XtX)</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>XtX_inv</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]      [,2]      [,3]
[1,]  1.70e-01 -1.64e-02  2.35e-06
[2,] -1.64e-02  2.00e-03 -7.41e-07
[3,]  2.35e-06 -7.41e-07  8.24e-10</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb107"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: multiply by s_e^2</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>vcov_manual <span class="ot">&lt;-</span> <span class="fu">sigma</span>(mod)<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> XtX_inv</span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: compare to R</span></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(vcov_manual, <span class="fu">vcov</span>(mod), <span class="at">check.attributes =</span> <span class="cn">FALSE</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
<p>Standard errors are the square roots of the diagonal:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb109"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>se_manual <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(vcov_manual))</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>se_R <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">summary</span>(mod))[, <span class="st">"Std. Error"</span>]</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">manual =</span> se_manual, <span class="at">R =</span> se_R)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>              manual        R
(Intercept) 3.218977 3.218977
education   0.348912 0.348912
income      0.000224 0.000224</code></pre>
</div>
</div>
<section id="why-xx-1-determines-precision" class="level3" data-number="12.1">
<h3 data-number="12.1" class="anchored" data-anchor-id="why-xx-1-determines-precision"><span class="header-section-number">12.1</span> Why <span class="math inline">\((X'X)^{-1}\)</span> determines precision</h3>
<p>The eigenvalues of <span class="math inline">\((X'X)^{-1}\)</span> are the reciprocals of those of <span class="math inline">\(X'X\)</span>. Large eigenvalues of <span class="math inline">\(X'X\)</span> (strong signal) become small eigenvalues of <span class="math inline">\((X'X)^{-1}\)</span> (precise estimates). Near-collinearity creates a tiny eigenvalue in <span class="math inline">\(X'X\)</span>, which inflates variance:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb111"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>eig_XtX <span class="ot">&lt;-</span> <span class="fu">eigen</span>(XtX)<span class="sc">$</span>values</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a>eig_inv <span class="ot">&lt;-</span> <span class="fu">eigen</span>(XtX_inv)<span class="sc">$</span>values</span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">XtX =</span> eig_XtX, <span class="at">XtX_inv =</span> eig_inv, <span class="at">product =</span> eig_XtX <span class="sc">*</span> eig_inv)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>          XtX  XtX_inv  product
[1,] 6.53e+09 1.71e-01 1.12e+09
[2,] 2.44e+03 4.10e-04 1.00e+00
[3,] 5.83e+00 1.53e-10 8.93e-10</code></pre>
</div>
</div>
<p>The products are all 1: the eigenvalues invert exactly.</p>
</section>
</section>
<section id="application-the-prestige-regression" class="level2" data-number="13">
<h2 data-number="13" class="anchored" data-anchor-id="application-the-prestige-regression"><span class="header-section-number">13</span> Application: the Prestige regression</h2>
<p>Let’s interpret the full regression. Education and income both predict occupational prestige:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb113"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = prestige ~ education + income, data = Prestige)

Residuals:
    Min      1Q  Median      3Q     Max 
-19.404  -5.331   0.015   4.980  17.689 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -6.847779   3.218977   -2.13    0.036 *  
education    4.137444   0.348912   11.86  &lt; 2e-16 ***
income       0.001361   0.000224    6.07  2.4e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 7.81 on 99 degrees of freedom
Multiple R-squared:  0.798, Adjusted R-squared:  0.794 
F-statistic:  196 on 2 and 99 DF,  p-value: &lt;2e-16</code></pre>
</div>
</div>
<p>The coefficient on education (4.1) says: holding income constant, one additional year of average education is associated with about 4.1 points more prestige. The coefficient on income (0.001) is small in magnitude because income is in dollars — a $1,000 increase predicts about 1.4 points.</p>
<p>Let’s see which occupations the model fits well and poorly, using the projection and annihilator:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb115"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>Prestige<span class="sc">$</span>fitted <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(P <span class="sc">%*%</span> y)</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>Prestige<span class="sc">$</span>resid <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(M <span class="sc">%*%</span> y)</span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Largest positive residuals: more prestige than education+income predict</span></span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Prestige[<span class="fu">order</span>(<span class="sc">-</span>Prestige<span class="sc">$</span>resid), <span class="fu">c</span>(<span class="st">"education"</span>, <span class="st">"income"</span>, <span class="st">"prestige"</span>, <span class="st">"fitted"</span>, <span class="st">"resid"</span>)], <span class="dv">5</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>                    education income prestige fitted resid
farmers                  6.84   3643     44.1   26.4  17.7
electronic.workers       8.76   3942     50.8   34.8  16.0
physio.therapsts        13.62   5092     72.1   56.4  15.7
medical.technicians     12.79   5180     67.5   53.1  14.4
nurses                  12.46   4614     64.7   51.0  13.7</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb117"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Largest negative residuals: less prestige than predicted</span></span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Prestige[<span class="fu">order</span>(Prestige<span class="sc">$</span>resid), <span class="fu">c</span>(<span class="st">"education"</span>, <span class="st">"income"</span>, <span class="st">"prestige"</span>, <span class="st">"fitted"</span>, <span class="st">"resid"</span>)], <span class="dv">5</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>                          education income prestige fitted resid
newsboys                       9.62    918     14.8   34.2 -19.4
collectors                    11.20   4741     29.4   45.9 -16.5
file.clerks                   12.09   3016     32.7   47.3 -14.6
service.station.attendant      9.93   2370     23.3   37.5 -14.2
bartenders                     8.50   3930     20.2   33.7 -13.5</code></pre>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb119"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(Prestige, <span class="fu">aes</span>(fitted, resid)) <span class="sc">+</span></span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb119-4"><a href="#cb119-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="at">data =</span> Prestige[<span class="fu">abs</span>(Prestige<span class="sc">$</span>resid) <span class="sc">&gt;</span> <span class="dv">15</span>, ],</span>
<span id="cb119-5"><a href="#cb119-5" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">rownames</span>(Prestige)[<span class="fu">abs</span>(Prestige<span class="sc">$</span>resid) <span class="sc">&gt;</span> <span class="dv">15</span>]),</span>
<span id="cb119-6"><a href="#cb119-6" aria-hidden="true" tabindex="-1"></a>            <span class="at">hjust =</span> <span class="sc">-</span><span class="fl">0.1</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb119-7"><a href="#cb119-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Fitted values (Py)"</span>, <span class="at">y =</span> <span class="st">"Residuals (My)"</span>,</span>
<span id="cb119-8"><a href="#cb119-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Prestige: fitted vs. residuals"</span>) <span class="sc">+</span></span>
<span id="cb119-9"><a href="#cb119-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch03-ols_files/figure-html/prestige-residual-plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="anova-as-inner-products" class="level2" data-number="14">
<h2 data-number="14" class="anchored" data-anchor-id="anova-as-inner-products"><span class="header-section-number">14</span> ANOVA as inner products</h2>
<p>The decomposition <span class="math inline">\(y = \hat{y} + \hat{e}\)</span> is orthogonal. In matrix terms, <span class="math inline">\(\hat{y}'\hat{e} = (Py)'(My) = y'PMy = 0\)</span>:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb120"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(<span class="fu">fitted</span>(mod), <span class="fu">resid</span>(mod)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -1.07e-13</code></pre>
</div>
</div>
<p>After centering, the inner products give sums of squares:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb122"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SST = ||M1 * y||^2  (total variation around the mean)</span></span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>SST <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(M1 <span class="sc">%*%</span> y))</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a><span class="co"># SSR = ||(P - P1) * y||^2  (variation explained by regressors beyond the mean)</span></span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a>SSR <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(<span class="fu">fitted</span>(mod) <span class="sc">-</span> <span class="fu">mean</span>(y)))</span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-7"><a href="#cb122-7" aria-hidden="true" tabindex="-1"></a><span class="co"># SSE = ||M * y||^2  (unexplained variation)</span></span>
<span id="cb122-8"><a href="#cb122-8" aria-hidden="true" tabindex="-1"></a>SSE <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(<span class="fu">resid</span>(mod)))</span>
<span id="cb122-9"><a href="#cb122-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-10"><a href="#cb122-10" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">SST =</span> SST, <span class="at">SSR_plus_SSE =</span> SSR <span class="sc">+</span> SSE)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>         SST SSR_plus_SSE 
       29895        29895 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb124"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cross term is zero when X includes a constant</span></span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a><span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(<span class="fu">fitted</span>(mod) <span class="sc">-</span> <span class="fu">mean</span>(y), <span class="fu">resid</span>(mod)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 8.74e-13</code></pre>
</div>
</div>
</section>
<section id="r2" class="level2" data-number="15">
<h2 data-number="15" class="anchored" data-anchor-id="r2"><span class="header-section-number">15</span> <span class="math inline">\(R^2\)</span></h2>
<p><span class="math inline">\(R^2 = \text{SSR}/\text{SST} = 1 - \text{SSE}/\text{SST}\)</span>:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb126"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">R2 =</span> SSR <span class="sc">/</span> SST,</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">R2_alt =</span> <span class="dv">1</span> <span class="sc">-</span> SSE <span class="sc">/</span> SST,</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">R_reports =</span> <span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>       R2    R2_alt R_reports 
    0.798     0.798     0.798 </code></pre>
</div>
</div>
<p>Adding regressors can only increase <span class="math inline">\(R^2\)</span>, even if the variable is noise. The adjusted <span class="math inline">\(R^2\)</span> penalizes for <span class="math inline">\(K\)</span>:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb128"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>Prestige<span class="sc">$</span>noise <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a>mod_noise <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> noise, <span class="at">data =</span> Prestige)</span>
<span id="cb128-4"><a href="#cb128-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-5"><a href="#cb128-5" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">R2_original =</span> <span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared,</span>
<span id="cb128-6"><a href="#cb128-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">R2_with_noise =</span> <span class="fu">summary</span>(mod_noise)<span class="sc">$</span>r.squared,</span>
<span id="cb128-7"><a href="#cb128-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">adj_R2_original =</span> <span class="fu">summary</span>(mod)<span class="sc">$</span>adj.r.squared,</span>
<span id="cb128-8"><a href="#cb128-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">adj_R2_with_noise =</span> <span class="fu">summary</span>(mod_noise)<span class="sc">$</span>adj.r.squared)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>      R2_original     R2_with_noise   adj_R2_original adj_R2_with_noise 
            0.798             0.799             0.794             0.792 </code></pre>
</div>
</div>
<p>Raw <span class="math inline">\(R^2\)</span> ticks up; adjusted <span class="math inline">\(R^2\)</span> drops — correctly penalizing the useless variable.</p>
<p><span class="math inline">\(R^2\)</span> measures descriptive fit, not causal validity. Typical values: cross-sectional micro data <span class="math inline">\(\approx 0.2\)</span>–<span class="math inline">\(0.4\)</span>, aggregate time series <span class="math inline">\(\approx 0.7\)</span>–<span class="math inline">\(0.9\)</span>.</p>
</section>
<section id="naming-conventions-a-warning" class="level2" data-number="16">
<h2 data-number="16" class="anchored" data-anchor-id="naming-conventions-a-warning"><span class="header-section-number">16</span> Naming conventions: a warning</h2>
<p>Different textbooks use SSE and SSR with opposite meanings. In this course (following Hansen), SSR is “regression” (explained) and SSE is “error” (unexplained). Some texts reverse these. The math is always <span class="math inline">\(\text{SST} = \text{explained} + \text{unexplained}\)</span>.</p>
</section>
<section id="summary" class="level2" data-number="17">
<h2 data-number="17" class="anchored" data-anchor-id="summary"><span class="header-section-number">17</span> Summary</h2>
<p>The OLS estimator is a sequence of matrix operations:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 13%">
<col style="width: 59%">
</colgroup>
<thead>
<tr class="header">
<th>Math</th>
<th>R</th>
<th>What it does</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(X'X\)</span></td>
<td><code>crossprod(X)</code></td>
<td>Gram matrix of regressors</td>
</tr>
<tr class="even">
<td><span class="math inline">\((X'X)^{-1}\)</span></td>
<td><code>solve(crossprod(X))</code></td>
<td>Inverse</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\hat\beta = (X'X)^{-1}X'y\)</span></td>
<td><code>solve(crossprod(X), crossprod(X, y))</code></td>
<td>OLS coefficients</td>
</tr>
<tr class="even">
<td><span class="math inline">\(P = X(X'X)^{-1}X'\)</span></td>
<td><code>X %*% solve(crossprod(X)) %*% t(X)</code></td>
<td>Projection (hat matrix)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(M = I - P\)</span></td>
<td><code>diag(n) - P</code></td>
<td>Annihilator</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\text{tr}(M)\)</span></td>
<td><code>sum(diag(M))</code></td>
<td>Degrees of freedom (<span class="math inline">\(n - K\)</span>)</td>
</tr>
<tr class="odd">
<td>eigenvalues of <span class="math inline">\(P\)</span></td>
<td><code>eigen(P)$values</code></td>
<td>All 0 or 1</td>
</tr>
<tr class="even">
<td><span class="math inline">\(s_e^2(X'X)^{-1}\)</span></td>
<td><code>sigma(mod)^2 * solve(crossprod(X))</code></td>
<td>Variance-covariance of <span class="math inline">\(\hat\beta\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\text{SE}(\hat\beta_k)\)</span></td>
<td><code>sqrt(diag(vcov(mod)))</code></td>
<td>Standard errors</td>
</tr>
</tbody>
</table>
<p>Key facts:</p>
<ul>
<li>OLS is <strong>projection</strong>: <span class="math inline">\(\hat{y} = Py\)</span> is the closest point to <span class="math inline">\(y\)</span> in the column space of <span class="math inline">\(X\)</span>, and <span class="math inline">\(\hat{e} = My\)</span> is the orthogonal residual.</li>
<li><span class="math inline">\(P\)</span> and <span class="math inline">\(M\)</span> are <strong>symmetric</strong> and <strong>idempotent</strong>, with eigenvalues in <span class="math inline">\(\{0, 1\}\)</span>.</li>
<li><span class="math inline">\(\text{tr}(P) = K\)</span> and <span class="math inline">\(\text{tr}(M) = n - K\)</span> count dimensions.</li>
<li>The <strong>trace trick</strong> proves <span class="math inline">\(s_e^2\)</span> is unbiased: <span class="math inline">\(\mathbb{E}[e'Me] = \sigma^2 \text{tr}(M) = \sigma^2(n-K)\)</span>.</li>
<li>Eigenvalues of <span class="math inline">\((X'X)^{-1}\)</span> are reciprocals of those of <span class="math inline">\(X'X\)</span>: near-collinearity inflates variance.</li>
<li><strong>Regression to the mean</strong> is a consequence of <span class="math inline">\(\hat\beta_1 &lt; 1\)</span> when <span class="math inline">\(|\rho| &lt; 1\)</span>.</li>
</ul>
<p>Next: <a href="./ch04-sensitivity.html">Sensitivity and Leverage</a> — the Frisch-Waugh-Lovell theorem, partial <span class="math inline">\(R^2\)</span>, and influential observations.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/UChicago-pol-methods\.github\.io\/EstimationI\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb130" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "3. Multivariate OLS"</span></span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Deriving and computing the OLS estimator"</span></span>
<span id="cb130-4"><a href="#cb130-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb130-5"><a href="#cb130-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-8"><a href="#cb130-8" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-9"><a href="#cb130-9" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup</span></span>
<span id="cb130-10"><a href="#cb130-10" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb130-11"><a href="#cb130-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb130-12"><a href="#cb130-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(carData)</span>
<span id="cb130-13"><a href="#cb130-13" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb130-14"><a href="#cb130-14" aria-hidden="true" tabindex="-1"></a>tr <span class="ot">&lt;-</span> <span class="cf">function</span>(M) <span class="fu">sum</span>(<span class="fu">diag</span>(M))  <span class="co"># R has no built-in trace</span></span>
<span id="cb130-15"><a href="#cb130-15" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-16"><a href="#cb130-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-17"><a href="#cb130-17" aria-hidden="true" tabindex="-1"></a>The OLS estimator $\hat\beta = (X'X)^{-1}X'y$ is a matrix formula. Every piece of it — the transpose, the product, the inverse — has a direct R function. This chapter builds OLS from those building blocks, first geometrically in two dimensions, then in full matrix form with real data.</span>
<span id="cb130-18"><a href="#cb130-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-19"><a href="#cb130-19" aria-hidden="true" tabindex="-1"></a>**Questions this chapter answers:**</span>
<span id="cb130-20"><a href="#cb130-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-21"><a href="#cb130-21" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>What R functions implement matrix operations, and how does <span class="in">`crossprod()`</span> relate to the normal equations?</span>
<span id="cb130-22"><a href="#cb130-22" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>What is the geometry of OLS — why is regression a projection?</span>
<span id="cb130-23"><a href="#cb130-23" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>How do we derive $\hat\beta = (X'X)^{-1}X'y$ from the minimization of SSE?</span>
<span id="cb130-24"><a href="#cb130-24" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>How do standard errors arise from $s_e^2(X'X)^{-1}$, and what makes them precise or imprecise?</span>
<span id="cb130-25"><a href="#cb130-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-26"><a href="#cb130-26" aria-hidden="true" tabindex="-1"></a><span class="fu">## R's matrix toolkit</span></span>
<span id="cb130-27"><a href="#cb130-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-28"><a href="#cb130-28" aria-hidden="true" tabindex="-1"></a>Before deriving anything, here are the operations we'll use throughout.</span>
<span id="cb130-29"><a href="#cb130-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-32"><a href="#cb130-32" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-33"><a href="#cb130-33" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: matrix-toolkit</span></span>
<span id="cb130-34"><a href="#cb130-34" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">3</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb130-35"><a href="#cb130-35" aria-hidden="true" tabindex="-1"></a>A</span>
<span id="cb130-36"><a href="#cb130-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-37"><a href="#cb130-37" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Transpose: t()</span></span>
<span id="cb130-38"><a href="#cb130-38" aria-hidden="true" tabindex="-1"></a><span class="fu">t</span>(A)</span>
<span id="cb130-39"><a href="#cb130-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-40"><a href="#cb130-40" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Matrix multiply: %*%  (not * which is element-wise)</span></span>
<span id="cb130-41"><a href="#cb130-41" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb130-42"><a href="#cb130-42" aria-hidden="true" tabindex="-1"></a>A <span class="sc">%*%</span> B</span>
<span id="cb130-43"><a href="#cb130-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-44"><a href="#cb130-44" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Inverse: solve()</span></span>
<span id="cb130-45"><a href="#cb130-45" aria-hidden="true" tabindex="-1"></a><span class="fu">solve</span>(A)</span>
<span id="cb130-46"><a href="#cb130-46" aria-hidden="true" tabindex="-1"></a>A <span class="sc">%*%</span> <span class="fu">solve</span>(A)  <span class="co"># identity</span></span>
<span id="cb130-47"><a href="#cb130-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-48"><a href="#cb130-48" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Trace: sum(diag())</span></span>
<span id="cb130-49"><a href="#cb130-49" aria-hidden="true" tabindex="-1"></a><span class="fu">tr</span>(A)   <span class="co"># sum of diagonal elements</span></span>
<span id="cb130-50"><a href="#cb130-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-51"><a href="#cb130-51" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Eigendecomposition: eigen()</span></span>
<span id="cb130-52"><a href="#cb130-52" aria-hidden="true" tabindex="-1"></a><span class="fu">eigen</span>(A)</span>
<span id="cb130-53"><a href="#cb130-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-54"><a href="#cb130-54" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Determinant: det()</span></span>
<span id="cb130-55"><a href="#cb130-55" aria-hidden="true" tabindex="-1"></a><span class="fu">det</span>(A)</span>
<span id="cb130-56"><a href="#cb130-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-57"><a href="#cb130-57" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Cross product shortcuts</span></span>
<span id="cb130-58"><a href="#cb130-58" aria-hidden="true" tabindex="-1"></a>x_vec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb130-59"><a href="#cb130-59" aria-hidden="true" tabindex="-1"></a>y_vec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>)</span>
<span id="cb130-60"><a href="#cb130-60" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">manual =</span> <span class="fu">sum</span>(x_vec <span class="sc">*</span> y_vec),</span>
<span id="cb130-61"><a href="#cb130-61" aria-hidden="true" tabindex="-1"></a>  <span class="at">crossprod =</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(x_vec, y_vec)))</span>
<span id="cb130-62"><a href="#cb130-62" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-63"><a href="#cb130-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-64"><a href="#cb130-64" aria-hidden="true" tabindex="-1"></a><span class="in">`crossprod(X)`</span> computes $X'X$ faster than <span class="in">`t(X) %*% X`</span>, and <span class="in">`crossprod(X, y)`</span> computes $X'y$. We'll use these constantly.</span>
<span id="cb130-65"><a href="#cb130-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-66"><a href="#cb130-66" aria-hidden="true" tabindex="-1"></a><span class="fu">## Geometry: projection in two dimensions</span></span>
<span id="cb130-67"><a href="#cb130-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-68"><a href="#cb130-68" aria-hidden="true" tabindex="-1"></a>You're used to plotting data with variables on the axes — one axis for $X$, one for $Y$, and each point is an observation. The geometric view of regression flips this: each axis is an *observation*, and each variable is a *vector*. A variable with $n$ observations is a vector in $\mathbb{R}^n$.</span>
<span id="cb130-69"><a href="#cb130-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-70"><a href="#cb130-70" aria-hidden="true" tabindex="-1"></a>Why think this way? Because regression asks: among all scalar multiples of $\mathbf{x}$ (all predictions of the form $b\mathbf{x}$), which one is closest to $\mathbf{y}$? That's a projection — dropping a perpendicular from $\mathbf{y}$ onto the line spanned by $\mathbf{x}$.</span>
<span id="cb130-71"><a href="#cb130-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-72"><a href="#cb130-72" aria-hidden="true" tabindex="-1"></a>With just two observations, we can see this on a page. Suppose we survey two students: we record how long each spent on homework ($\mathbf{h}$) and how long reading the textbook ($\mathbf{t}$). Each variable is a 2-vector, and we can plot both in $\mathbb{R}^2$:</span>
<span id="cb130-73"><a href="#cb130-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-76"><a href="#cb130-76" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-77"><a href="#cb130-77" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: two-vectors</span></span>
<span id="cb130-78"><a href="#cb130-78" aria-hidden="true" tabindex="-1"></a><span class="co"># Student 1: 3 hrs homework, 2.5 hrs reading</span></span>
<span id="cb130-79"><a href="#cb130-79" aria-hidden="true" tabindex="-1"></a><span class="co"># Student 2: 5 hrs homework, 2 hrs reading</span></span>
<span id="cb130-80"><a href="#cb130-80" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">5</span>)    <span class="co"># outcome: homework time</span></span>
<span id="cb130-81"><a href="#cb130-81" aria-hidden="true" tabindex="-1"></a>tt <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">2.5</span>, <span class="dv">2</span>)  <span class="co"># predictor: reading time</span></span>
<span id="cb130-82"><a href="#cb130-82" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-83"><a href="#cb130-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-84"><a href="#cb130-84" aria-hidden="true" tabindex="-1"></a>We want to predict $\mathbf{h}$ using $\mathbf{t}$: find $b$ so that $b\mathbf{t}$ is as close to $\mathbf{h}$ as possible. Geometrically, $b\mathbf{t}$ must lie on the line through $\mathbf{t}$ (the dotted line in the plot below), and the best choice is the one where the "miss" — the residual — is perpendicular to that line.</span>
<span id="cb130-85"><a href="#cb130-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-86"><a href="#cb130-86" aria-hidden="true" tabindex="-1"></a>The **vector projection** of $\mathbf{h}$ onto $\mathbf{t}$ solves this:</span>
<span id="cb130-87"><a href="#cb130-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-88"><a href="#cb130-88" aria-hidden="true" tabindex="-1"></a>$$\hat{\mathbf{h}} = \frac{\mathbf{t} \cdot \mathbf{h}}{\mathbf{t} \cdot \mathbf{t}} \mathbf{t}$$</span>
<span id="cb130-89"><a href="#cb130-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-90"><a href="#cb130-90" aria-hidden="true" tabindex="-1"></a>The scalar $b = \frac{\mathbf{t} \cdot \mathbf{h}}{\mathbf{t} \cdot \mathbf{t}}$ minimizes $<span class="sc">\|</span>\mathbf{h} - b\mathbf{t}<span class="sc">\|</span>^2$ — the sum of squared errors. This is the least squares solution, derived purely from geometry.</span>
<span id="cb130-91"><a href="#cb130-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-94"><a href="#cb130-94" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-95"><a href="#cb130-95" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: projection-by-hand</span></span>
<span id="cb130-96"><a href="#cb130-96" aria-hidden="true" tabindex="-1"></a><span class="co"># The projection coefficient</span></span>
<span id="cb130-97"><a href="#cb130-97" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(tt, h) <span class="sc">/</span> <span class="fu">crossprod</span>(tt))</span>
<span id="cb130-98"><a href="#cb130-98" aria-hidden="true" tabindex="-1"></a>b</span>
<span id="cb130-99"><a href="#cb130-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-100"><a href="#cb130-100" aria-hidden="true" tabindex="-1"></a><span class="co"># The projected vector (fitted values)</span></span>
<span id="cb130-101"><a href="#cb130-101" aria-hidden="true" tabindex="-1"></a>h_hat <span class="ot">&lt;-</span> b <span class="sc">*</span> tt</span>
<span id="cb130-102"><a href="#cb130-102" aria-hidden="true" tabindex="-1"></a>h_hat</span>
<span id="cb130-103"><a href="#cb130-103" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-104"><a href="#cb130-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-105"><a href="#cb130-105" aria-hidden="true" tabindex="-1"></a>And this is exactly what <span class="in">`lm()`</span> computes when we regress $\mathbf{h}$ on $\mathbf{t}$ without an intercept:</span>
<span id="cb130-106"><a href="#cb130-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-109"><a href="#cb130-109" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-110"><a href="#cb130-110" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: projection-equals-ols</span></span>
<span id="cb130-111"><a href="#cb130-111" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS without intercept gives the same b</span></span>
<span id="cb130-112"><a href="#cb130-112" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(h <span class="sc">~</span> tt <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb130-113"><a href="#cb130-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-114"><a href="#cb130-114" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitted values = the projection</span></span>
<span id="cb130-115"><a href="#cb130-115" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">projection =</span> h_hat, <span class="at">fitted =</span> <span class="fu">fitted</span>(<span class="fu">lm</span>(h <span class="sc">~</span> tt <span class="sc">-</span> <span class="dv">1</span>)))</span>
<span id="cb130-116"><a href="#cb130-116" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-117"><a href="#cb130-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-118"><a href="#cb130-118" aria-hidden="true" tabindex="-1"></a>The residual $\mathbf{e} = \mathbf{h} - \hat{\mathbf{h}}$ is orthogonal to $\mathbf{t}$ — their dot product is zero:</span>
<span id="cb130-119"><a href="#cb130-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-122"><a href="#cb130-122" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-123"><a href="#cb130-123" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: residual-orthogonal</span></span>
<span id="cb130-124"><a href="#cb130-124" aria-hidden="true" tabindex="-1"></a>e_vec <span class="ot">&lt;-</span> h <span class="sc">-</span> h_hat</span>
<span id="cb130-125"><a href="#cb130-125" aria-hidden="true" tabindex="-1"></a><span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(tt, e_vec))</span>
<span id="cb130-126"><a href="#cb130-126" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-127"><a href="#cb130-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-128"><a href="#cb130-128" aria-hidden="true" tabindex="-1"></a>This orthogonality is the geometric content of the normal equations $X'e = 0$. Here's the full picture:</span>
<span id="cb130-129"><a href="#cb130-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-132"><a href="#cb130-132" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-133"><a href="#cb130-133" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: geometry-plot</span></span>
<span id="cb130-134"><a href="#cb130-134" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "OLS finds the closest point on the line of t to h"</span></span>
<span id="cb130-135"><a href="#cb130-135" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 5</span></span>
<span id="cb130-136"><a href="#cb130-136" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb130-137"><a href="#cb130-137" aria-hidden="true" tabindex="-1"></a>df_arrows <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb130-138"><a href="#cb130-138" aria-hidden="true" tabindex="-1"></a>  <span class="at">x0 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, h_hat[<span class="dv">1</span>]),</span>
<span id="cb130-139"><a href="#cb130-139" aria-hidden="true" tabindex="-1"></a>  <span class="at">y0 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, h_hat[<span class="dv">2</span>]),</span>
<span id="cb130-140"><a href="#cb130-140" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">c</span>(h[<span class="dv">1</span>], tt[<span class="dv">1</span>], h_hat[<span class="dv">1</span>], h[<span class="dv">1</span>]),</span>
<span id="cb130-141"><a href="#cb130-141" aria-hidden="true" tabindex="-1"></a>  <span class="at">y1 =</span> <span class="fu">c</span>(h[<span class="dv">2</span>], tt[<span class="dv">2</span>], h_hat[<span class="dv">2</span>], h[<span class="dv">2</span>]),</span>
<span id="cb130-142"><a href="#cb130-142" aria-hidden="true" tabindex="-1"></a>  <span class="at">label =</span> <span class="fu">c</span>(<span class="st">"h (outcome)"</span>, <span class="st">"t (regressor)"</span>, <span class="st">"h-hat (fitted)"</span>, <span class="st">"e (residual)"</span>),</span>
<span id="cb130-143"><a href="#cb130-143" aria-hidden="true" tabindex="-1"></a>  <span class="at">color =</span> <span class="fu">c</span>(<span class="st">"black"</span>, <span class="st">"gray50"</span>, <span class="st">"forestgreen"</span>, <span class="st">"tomato"</span>)</span>
<span id="cb130-144"><a href="#cb130-144" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb130-145"><a href="#cb130-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-146"><a href="#cb130-146" aria-hidden="true" tabindex="-1"></a>slope_t <span class="ot">&lt;-</span> tt[<span class="dv">2</span>] <span class="sc">/</span> tt[<span class="dv">1</span>]</span>
<span id="cb130-147"><a href="#cb130-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-148"><a href="#cb130-148" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb130-149"><a href="#cb130-149" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> slope_t, <span class="at">linetype =</span> <span class="st">"dotted"</span>, <span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb130-150"><a href="#cb130-150" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">data =</span> df_arrows,</span>
<span id="cb130-151"><a href="#cb130-151" aria-hidden="true" tabindex="-1"></a>               <span class="fu">aes</span>(<span class="at">x =</span> x0, <span class="at">y =</span> y0, <span class="at">xend =</span> x1, <span class="at">yend =</span> y1, <span class="at">color =</span> label),</span>
<span id="cb130-152"><a href="#cb130-152" aria-hidden="true" tabindex="-1"></a>               <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">length =</span> <span class="fu">unit</span>(<span class="fl">0.15</span>, <span class="st">"inches"</span>)),</span>
<span id="cb130-153"><a href="#cb130-153" aria-hidden="true" tabindex="-1"></a>               <span class="at">linewidth =</span> <span class="fl">1.1</span>) <span class="sc">+</span></span>
<span id="cb130-154"><a href="#cb130-154" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"h (outcome)"</span> <span class="ot">=</span> <span class="st">"black"</span>,</span>
<span id="cb130-155"><a href="#cb130-155" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"t (regressor)"</span> <span class="ot">=</span> <span class="st">"gray50"</span>,</span>
<span id="cb130-156"><a href="#cb130-156" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"h-hat (fitted)"</span> <span class="ot">=</span> <span class="st">"forestgreen"</span>,</span>
<span id="cb130-157"><a href="#cb130-157" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"e (residual)"</span> <span class="ot">=</span> <span class="st">"tomato"</span>),</span>
<span id="cb130-158"><a href="#cb130-158" aria-hidden="true" tabindex="-1"></a>                     <span class="at">name =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb130-159"><a href="#cb130-159" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_fixed</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">5</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">6</span>)) <span class="sc">+</span></span>
<span id="cb130-160"><a href="#cb130-160" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Observation 1"</span>, <span class="at">y =</span> <span class="st">"Observation 2"</span>,</span>
<span id="cb130-161"><a href="#cb130-161" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"OLS finds the closest point on the line of t to h"</span>) <span class="sc">+</span></span>
<span id="cb130-162"><a href="#cb130-162" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb130-163"><a href="#cb130-163" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-164"><a href="#cb130-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-165"><a href="#cb130-165" aria-hidden="true" tabindex="-1"></a>The green vector ($\hat{\mathbf{h}}$) is the best prediction in the "column space" of $\mathbf{t}$, and the red vector ($\mathbf{e}$) is the part of $\mathbf{h}$ that $\mathbf{t}$ cannot explain. With $n = 100$ observations, these vectors live in $\mathbb{R}^{100}$ and we can't draw them — but the geometry is identical. With multiple regressors, the "line" becomes a plane (or hyperplane), and the projection lands on the closest point in that plane.</span>
<span id="cb130-166"><a href="#cb130-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-167"><a href="#cb130-167" aria-hidden="true" tabindex="-1"></a><span class="fu">## Building the design matrix</span></span>
<span id="cb130-168"><a href="#cb130-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-169"><a href="#cb130-169" aria-hidden="true" tabindex="-1"></a>The model $y = X\beta + e$ stacks $n$ observations into a matrix. Each row of $X$ is one observation; each column is one variable. The first column is typically all ones (the intercept).</span>
<span id="cb130-170"><a href="#cb130-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-171"><a href="#cb130-171" aria-hidden="true" tabindex="-1"></a>We'll use the Canadian Prestige dataset: the Pineo-Porter prestige score of occupations, predicted by average education (years) and average income (dollars) of workers in each occupation.</span>
<span id="cb130-172"><a href="#cb130-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-175"><a href="#cb130-175" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-176"><a href="#cb130-176" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: design-matrix</span></span>
<span id="cb130-177"><a href="#cb130-177" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Prestige)</span>
<span id="cb130-178"><a href="#cb130-178" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(Prestige)</span>
<span id="cb130-179"><a href="#cb130-179" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="dv">3</span>  <span class="co"># intercept + education + income</span></span>
<span id="cb130-180"><a href="#cb130-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-181"><a href="#cb130-181" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, Prestige<span class="sc">$</span>education, Prestige<span class="sc">$</span>income)</span>
<span id="cb130-182"><a href="#cb130-182" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> Prestige<span class="sc">$</span>prestige</span>
<span id="cb130-183"><a href="#cb130-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-184"><a href="#cb130-184" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(X)   <span class="co"># n x K</span></span>
<span id="cb130-185"><a href="#cb130-185" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(X)</span>
<span id="cb130-186"><a href="#cb130-186" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-187"><a href="#cb130-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-188"><a href="#cb130-188" aria-hidden="true" tabindex="-1"></a>The two fundamental products in OLS are $X'X$ (a $K \times K$ matrix) and $X'y$ (a $K \times 1$ vector):</span>
<span id="cb130-189"><a href="#cb130-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-192"><a href="#cb130-192" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-193"><a href="#cb130-193" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: xtx-xty</span></span>
<span id="cb130-194"><a href="#cb130-194" aria-hidden="true" tabindex="-1"></a>XtX <span class="ot">&lt;-</span> <span class="fu">crossprod</span>(X)       <span class="co"># K x K: t(X) %*% X</span></span>
<span id="cb130-195"><a href="#cb130-195" aria-hidden="true" tabindex="-1"></a>XtX</span>
<span id="cb130-196"><a href="#cb130-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-197"><a href="#cb130-197" aria-hidden="true" tabindex="-1"></a>Xty <span class="ot">&lt;-</span> <span class="fu">crossprod</span>(X, y)    <span class="co"># K x 1: t(X) %*% y</span></span>
<span id="cb130-198"><a href="#cb130-198" aria-hidden="true" tabindex="-1"></a>Xty</span>
<span id="cb130-199"><a href="#cb130-199" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-200"><a href="#cb130-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-201"><a href="#cb130-201" aria-hidden="true" tabindex="-1"></a>$X'X$ encodes the relationships among the regressors. The diagonal holds $\sum X_k^2$ for each variable; the off-diagonals hold $\sum X_j X_k$. Dividing by $n$ gives the sample second-moment matrix.</span>
<span id="cb130-202"><a href="#cb130-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-203"><a href="#cb130-203" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bivariate OLS: the formula connection</span></span>
<span id="cb130-204"><a href="#cb130-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-205"><a href="#cb130-205" aria-hidden="true" tabindex="-1"></a>Before the matrix derivation, recall the bivariate OLS formula: $\hat\beta_1 = \text{Cov}(X, Y)/\text{Var}(X)$. This is the sample analogue of the BLP coefficient from Chapter 2. Let's verify it matches the matrix formula using just education as a predictor:</span>
<span id="cb130-206"><a href="#cb130-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-209"><a href="#cb130-209" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-210"><a href="#cb130-210" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: bivariate-by-hand</span></span>
<span id="cb130-211"><a href="#cb130-211" aria-hidden="true" tabindex="-1"></a>educ <span class="ot">&lt;-</span> Prestige<span class="sc">$</span>education</span>
<span id="cb130-212"><a href="#cb130-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-213"><a href="#cb130-213" aria-hidden="true" tabindex="-1"></a><span class="co"># Formula approach</span></span>
<span id="cb130-214"><a href="#cb130-214" aria-hidden="true" tabindex="-1"></a>beta1_formula <span class="ot">&lt;-</span> <span class="fu">cov</span>(educ, y) <span class="sc">/</span> <span class="fu">var</span>(educ)</span>
<span id="cb130-215"><a href="#cb130-215" aria-hidden="true" tabindex="-1"></a>beta0_formula <span class="ot">&lt;-</span> <span class="fu">mean</span>(y) <span class="sc">-</span> beta1_formula <span class="sc">*</span> <span class="fu">mean</span>(educ)</span>
<span id="cb130-216"><a href="#cb130-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-217"><a href="#cb130-217" aria-hidden="true" tabindex="-1"></a><span class="co"># Matrix approach (2x2 system)</span></span>
<span id="cb130-218"><a href="#cb130-218" aria-hidden="true" tabindex="-1"></a>X_biv <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, educ)</span>
<span id="cb130-219"><a href="#cb130-219" aria-hidden="true" tabindex="-1"></a>beta_biv <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X_biv), <span class="fu">crossprod</span>(X_biv, y))</span>
<span id="cb130-220"><a href="#cb130-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-221"><a href="#cb130-221" aria-hidden="true" tabindex="-1"></a><span class="co"># lm() approach</span></span>
<span id="cb130-222"><a href="#cb130-222" aria-hidden="true" tabindex="-1"></a>beta_lm <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(prestige <span class="sc">~</span> education, <span class="at">data =</span> Prestige))</span>
<span id="cb130-223"><a href="#cb130-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-224"><a href="#cb130-224" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">formula =</span> <span class="fu">c</span>(beta0_formula, beta1_formula),</span>
<span id="cb130-225"><a href="#cb130-225" aria-hidden="true" tabindex="-1"></a>      <span class="at">matrix =</span> beta_biv,</span>
<span id="cb130-226"><a href="#cb130-226" aria-hidden="true" tabindex="-1"></a>      <span class="at">lm =</span> beta_lm)</span>
<span id="cb130-227"><a href="#cb130-227" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-228"><a href="#cb130-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-229"><a href="#cb130-229" aria-hidden="true" tabindex="-1"></a>All three give the same answer. The matrix formula $\hat\beta = (X'X)^{-1}X'y$ generalizes the bivariate $\text{Cov}/\text{Var}$ formula to any number of regressors.</span>
<span id="cb130-230"><a href="#cb130-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-231"><a href="#cb130-231" aria-hidden="true" tabindex="-1"></a><span class="fu">## Deriving OLS with matrix calculus {#sec-ols-derivation}</span></span>
<span id="cb130-232"><a href="#cb130-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-233"><a href="#cb130-233" aria-hidden="true" tabindex="-1"></a>The sum of squared errors in matrix form is:</span>
<span id="cb130-234"><a href="#cb130-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-235"><a href="#cb130-235" aria-hidden="true" tabindex="-1"></a>$$\text{SSE}(\beta) = (y - X\beta)'(y - X\beta) = \underbrace{y'y}_{\text{constant}} - \underbrace{2y'X\beta}_{\text{linear}} + \underbrace{\beta'X'X\beta}_{\text{quadratic}}$$ {#eq-ols}</span>
<span id="cb130-236"><a href="#cb130-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-237"><a href="#cb130-237" aria-hidden="true" tabindex="-1"></a>Let's build each piece in R and verify the expansion:</span>
<span id="cb130-238"><a href="#cb130-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-241"><a href="#cb130-241" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-242"><a href="#cb130-242" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: sse-expansion</span></span>
<span id="cb130-243"><a href="#cb130-243" aria-hidden="true" tabindex="-1"></a>beta_test <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.001</span>)  <span class="co"># an arbitrary beta to test</span></span>
<span id="cb130-244"><a href="#cb130-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-245"><a href="#cb130-245" aria-hidden="true" tabindex="-1"></a><span class="co"># Direct computation</span></span>
<span id="cb130-246"><a href="#cb130-246" aria-hidden="true" tabindex="-1"></a>sse_direct <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(y <span class="sc">-</span> X <span class="sc">%*%</span> beta_test))</span>
<span id="cb130-247"><a href="#cb130-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-248"><a href="#cb130-248" aria-hidden="true" tabindex="-1"></a><span class="co"># Expanded form</span></span>
<span id="cb130-249"><a href="#cb130-249" aria-hidden="true" tabindex="-1"></a>piece1 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(y))                         <span class="co"># y'y</span></span>
<span id="cb130-250"><a href="#cb130-250" aria-hidden="true" tabindex="-1"></a>piece2 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="dv">2</span> <span class="sc">*</span> <span class="fu">crossprod</span>(y, X <span class="sc">%*%</span> beta_test))    <span class="co"># 2y'Xbeta</span></span>
<span id="cb130-251"><a href="#cb130-251" aria-hidden="true" tabindex="-1"></a>piece3 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">t</span>(beta_test) <span class="sc">%*%</span> XtX <span class="sc">%*%</span> beta_test)  <span class="co"># beta'X'Xbeta</span></span>
<span id="cb130-252"><a href="#cb130-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-253"><a href="#cb130-253" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">direct =</span> sse_direct, <span class="at">expanded =</span> piece1 <span class="sc">-</span> piece2 <span class="sc">+</span> piece3)</span>
<span id="cb130-254"><a href="#cb130-254" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-255"><a href="#cb130-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-256"><a href="#cb130-256" aria-hidden="true" tabindex="-1"></a>Setting $\partial \text{SSE}/\partial \beta = -2X'y + 2X'X\hat\beta = 0$ gives the **normal equations**:</span>
<span id="cb130-257"><a href="#cb130-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-258"><a href="#cb130-258" aria-hidden="true" tabindex="-1"></a>$$X'X\hat\beta = X'y$$ {#eq-normal-equations}</span>
<span id="cb130-259"><a href="#cb130-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-260"><a href="#cb130-260" aria-hidden="true" tabindex="-1"></a>Solving with <span class="in">`solve()`</span>:</span>
<span id="cb130-261"><a href="#cb130-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-264"><a href="#cb130-264" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-265"><a href="#cb130-265" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: ols-solve</span></span>
<span id="cb130-266"><a href="#cb130-266" aria-hidden="true" tabindex="-1"></a><span class="co"># solve(A, b) solves the system Ax = b — better than solve(A) %*% b</span></span>
<span id="cb130-267"><a href="#cb130-267" aria-hidden="true" tabindex="-1"></a>beta_hat <span class="ot">&lt;-</span> <span class="fu">solve</span>(XtX, Xty)</span>
<span id="cb130-268"><a href="#cb130-268" aria-hidden="true" tabindex="-1"></a>beta_hat</span>
<span id="cb130-269"><a href="#cb130-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-270"><a href="#cb130-270" aria-hidden="true" tabindex="-1"></a><span class="co"># lm() gives the same thing</span></span>
<span id="cb130-271"><a href="#cb130-271" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income, <span class="at">data =</span> Prestige))</span>
<span id="cb130-272"><a href="#cb130-272" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-273"><a href="#cb130-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-274"><a href="#cb130-274" aria-hidden="true" tabindex="-1"></a>Note: <span class="in">`solve(A, b)`</span> is preferred over <span class="in">`solve(A) %*% b`</span> — it avoids computing the full inverse, which is slower and less numerically stable.</span>
<span id="cb130-275"><a href="#cb130-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-276"><a href="#cb130-276" aria-hidden="true" tabindex="-1"></a>::: {#thm-ols}</span>
<span id="cb130-277"><a href="#cb130-277" aria-hidden="true" tabindex="-1"></a><span class="fu">## The OLS Estimator</span></span>
<span id="cb130-278"><a href="#cb130-278" aria-hidden="true" tabindex="-1"></a>The OLS estimator $\hat\beta = (X'X)^{-1}X'y$ is the unique minimizer of $\text{SSE}(\beta) = (y - X\beta)'(y - X\beta)$ when $X'X$ is positive definite.</span>
<span id="cb130-279"><a href="#cb130-279" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb130-280"><a href="#cb130-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-281"><a href="#cb130-281" aria-hidden="true" tabindex="-1"></a><span class="fu">### The second-order condition</span></span>
<span id="cb130-282"><a href="#cb130-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-283"><a href="#cb130-283" aria-hidden="true" tabindex="-1"></a>The second derivative of $\text{SSE}$ is $2X'X$. This is a minimum when $X'X$ is positive definite — all eigenvalues are positive:</span>
<span id="cb130-284"><a href="#cb130-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-287"><a href="#cb130-287" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-288"><a href="#cb130-288" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: second-order</span></span>
<span id="cb130-289"><a href="#cb130-289" aria-hidden="true" tabindex="-1"></a><span class="fu">eigen</span>(XtX)<span class="sc">$</span>values</span>
<span id="cb130-290"><a href="#cb130-290" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-291"><a href="#cb130-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-292"><a href="#cb130-292" aria-hidden="true" tabindex="-1"></a>All positive, confirming positive definiteness. If any eigenvalue were zero, $X'X$ would be singular and <span class="in">`solve()`</span> would fail.</span>
<span id="cb130-293"><a href="#cb130-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-294"><a href="#cb130-294" aria-hidden="true" tabindex="-1"></a><span class="fu">## What collinearity does to $X'X$</span></span>
<span id="cb130-295"><a href="#cb130-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-296"><a href="#cb130-296" aria-hidden="true" tabindex="-1"></a>When a column of $X$ is a linear combination of others, $X'X$ loses rank:</span>
<span id="cb130-297"><a href="#cb130-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-300"><a href="#cb130-300" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-301"><a href="#cb130-301" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: collinearity</span></span>
<span id="cb130-302"><a href="#cb130-302" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a redundant column: income2 = 2 * income</span></span>
<span id="cb130-303"><a href="#cb130-303" aria-hidden="true" tabindex="-1"></a>X_bad <span class="ot">&lt;-</span> <span class="fu">cbind</span>(X, <span class="dv">2</span> <span class="sc">*</span> Prestige<span class="sc">$</span>income)</span>
<span id="cb130-304"><a href="#cb130-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-305"><a href="#cb130-305" aria-hidden="true" tabindex="-1"></a>XtX_bad <span class="ot">&lt;-</span> <span class="fu">crossprod</span>(X_bad)</span>
<span id="cb130-306"><a href="#cb130-306" aria-hidden="true" tabindex="-1"></a><span class="fu">det</span>(XtX_bad)          <span class="co"># essentially zero</span></span>
<span id="cb130-307"><a href="#cb130-307" aria-hidden="true" tabindex="-1"></a><span class="fu">eigen</span>(XtX_bad)<span class="sc">$</span>values  <span class="co"># last eigenvalue collapses</span></span>
<span id="cb130-308"><a href="#cb130-308" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-309"><a href="#cb130-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-310"><a href="#cb130-310" aria-hidden="true" tabindex="-1"></a>In practice, *near*-collinearity (very small but nonzero eigenvalues) inflates standard errors without crashing `solve()`. The **condition number** — ratio of largest to smallest eigenvalue — measures how close to singular:</span>
<span id="cb130-311"><a href="#cb130-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-314"><a href="#cb130-314" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-315"><a href="#cb130-315" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: condition-number</span></span>
<span id="cb130-316"><a href="#cb130-316" aria-hidden="true" tabindex="-1"></a>evals <span class="ot">&lt;-</span> <span class="fu">eigen</span>(XtX)<span class="sc">$</span>values</span>
<span id="cb130-317"><a href="#cb130-317" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">largest =</span> evals[<span class="dv">1</span>], <span class="at">smallest =</span> evals[K], <span class="at">condition =</span> evals[<span class="dv">1</span>] <span class="sc">/</span> evals[K])</span>
<span id="cb130-318"><a href="#cb130-318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-319"><a href="#cb130-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-320"><a href="#cb130-320" aria-hidden="true" tabindex="-1"></a>R's <span class="in">`lm()`</span> handles exact collinearity by dropping the redundant column:</span>
<span id="cb130-321"><a href="#cb130-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-324"><a href="#cb130-324" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-325"><a href="#cb130-325" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: lm-collinearity</span></span>
<span id="cb130-326"><a href="#cb130-326" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> <span class="fu">I</span>(<span class="dv">2</span> <span class="sc">*</span> income), <span class="at">data =</span> Prestige))</span>
<span id="cb130-327"><a href="#cb130-327" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-328"><a href="#cb130-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-329"><a href="#cb130-329" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb130-330"><a href="#cb130-330" aria-hidden="true" tabindex="-1"></a><span class="fu">## Near-Collinearity Inflates Standard Errors</span></span>
<span id="cb130-331"><a href="#cb130-331" aria-hidden="true" tabindex="-1"></a>When columns of $X$ are nearly linearly dependent, $X'X$ has a near-zero eigenvalue, making $(X'X)^{-1}$ very large. This inflates the variance of $\hat\beta$ without causing <span class="in">`solve()`</span> to fail — standard errors balloon silently. Check the condition number of $X'X$ to detect this.</span>
<span id="cb130-332"><a href="#cb130-332" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb130-333"><a href="#cb130-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-334"><a href="#cb130-334" aria-hidden="true" tabindex="-1"></a><span class="fu">## The projection matrix {#sec-projection-matrix}</span></span>
<span id="cb130-335"><a href="#cb130-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-336"><a href="#cb130-336" aria-hidden="true" tabindex="-1"></a>The projection matrix $P = X(X'X)^{-1}X'$ maps any $n$-vector onto the column space of $X$. In two dimensions (our earlier example), it projected $\mathbf{h}$ onto the line of $\mathbf{t}$. With $K = 3$ regressors, it projects $\mathbf{y}$ onto a 3-dimensional subspace of $\mathbb{R}^n$.</span>
<span id="cb130-337"><a href="#cb130-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-340"><a href="#cb130-340" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-341"><a href="#cb130-341" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: projection-matrix</span></span>
<span id="cb130-342"><a href="#cb130-342" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> X <span class="sc">%*%</span> <span class="fu">solve</span>(XtX) <span class="sc">%*%</span> <span class="fu">t</span>(X)</span>
<span id="cb130-343"><a href="#cb130-343" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(P)  <span class="co"># n x n</span></span>
<span id="cb130-344"><a href="#cb130-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-345"><a href="#cb130-345" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income, <span class="at">data =</span> Prestige)</span>
<span id="cb130-346"><a href="#cb130-346" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-347"><a href="#cb130-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-348"><a href="#cb130-348" aria-hidden="true" tabindex="-1"></a>::: {#def-projection-matrix}</span>
<span id="cb130-349"><a href="#cb130-349" aria-hidden="true" tabindex="-1"></a><span class="fu">## Projection (Hat) Matrix</span></span>
<span id="cb130-350"><a href="#cb130-350" aria-hidden="true" tabindex="-1"></a>The projection matrix $P = X(X'X)^{-1}X'$ maps any $n$-vector onto the column space of $X$. It is symmetric ($P' = P$) and idempotent ($P^2 = P$), with eigenvalues in $<span class="sc">\{</span>0, 1<span class="sc">\}</span>$ and $\text{tr}(P) = K$.</span>
<span id="cb130-351"><a href="#cb130-351" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb130-352"><a href="#cb130-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-353"><a href="#cb130-353" aria-hidden="true" tabindex="-1"></a>Every property of $P$ corresponds to a matrix operation:</span>
<span id="cb130-354"><a href="#cb130-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-357"><a href="#cb130-357" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-358"><a href="#cb130-358" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: projection-properties</span></span>
<span id="cb130-359"><a href="#cb130-359" aria-hidden="true" tabindex="-1"></a><span class="co"># P*y = fitted values</span></span>
<span id="cb130-360"><a href="#cb130-360" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.vector</span>(P <span class="sc">%*%</span> y), <span class="fu">as.numeric</span>(<span class="fu">fitted</span>(mod)))</span>
<span id="cb130-361"><a href="#cb130-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-362"><a href="#cb130-362" aria-hidden="true" tabindex="-1"></a><span class="co"># Symmetric: t(P) = P</span></span>
<span id="cb130-363"><a href="#cb130-363" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">t</span>(P), P)</span>
<span id="cb130-364"><a href="#cb130-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-365"><a href="#cb130-365" aria-hidden="true" tabindex="-1"></a><span class="co"># Idempotent: P %*% P = P (projecting twice = projecting once)</span></span>
<span id="cb130-366"><a href="#cb130-366" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(P <span class="sc">%*%</span> P, P)</span>
<span id="cb130-367"><a href="#cb130-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-368"><a href="#cb130-368" aria-hidden="true" tabindex="-1"></a><span class="co"># P*X = X (X is already in its own column space)</span></span>
<span id="cb130-369"><a href="#cb130-369" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(P <span class="sc">%*%</span> X, X, <span class="at">check.attributes =</span> <span class="cn">FALSE</span>)</span>
<span id="cb130-370"><a href="#cb130-370" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-371"><a href="#cb130-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-372"><a href="#cb130-372" aria-hidden="true" tabindex="-1"></a><span class="fu">### What idempotency means for eigenvalues</span></span>
<span id="cb130-373"><a href="#cb130-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-374"><a href="#cb130-374" aria-hidden="true" tabindex="-1"></a>If $Pv = \lambda v$, then $P^2 v = \lambda^2 v$. But $P^2 = P$, so $\lambda^2 = \lambda$, which means $\lambda \in <span class="sc">\{</span>0, 1<span class="sc">\}</span>$:</span>
<span id="cb130-375"><a href="#cb130-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-378"><a href="#cb130-378" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-379"><a href="#cb130-379" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: projection-eigenvalues</span></span>
<span id="cb130-380"><a href="#cb130-380" aria-hidden="true" tabindex="-1"></a>eig_P <span class="ot">&lt;-</span> <span class="fu">eigen</span>(P)<span class="sc">$</span>values</span>
<span id="cb130-381"><a href="#cb130-381" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">round</span>(eig_P, <span class="dv">10</span>))</span>
<span id="cb130-382"><a href="#cb130-382" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-383"><a href="#cb130-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-384"><a href="#cb130-384" aria-hidden="true" tabindex="-1"></a>$K$ eigenvalues equal 1 (the column space of $X$) and $n - K$ equal 0 (the null space). The trace counts the 1s:</span>
<span id="cb130-385"><a href="#cb130-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-388"><a href="#cb130-388" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-389"><a href="#cb130-389" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: projection-trace</span></span>
<span id="cb130-390"><a href="#cb130-390" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">trace_P =</span> <span class="fu">tr</span>(P), <span class="at">K =</span> K)</span>
<span id="cb130-391"><a href="#cb130-391" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-392"><a href="#cb130-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-393"><a href="#cb130-393" aria-hidden="true" tabindex="-1"></a><span class="fu">### Projection onto the intercept</span></span>
<span id="cb130-394"><a href="#cb130-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-395"><a href="#cb130-395" aria-hidden="true" tabindex="-1"></a>The simplest projection is onto a column of ones: $P_1 = \mathbf{1}(\mathbf{1}'\mathbf{1})^{-1}\mathbf{1}' = \frac{1}{n}\mathbf{1}\mathbf{1}'$. This projects every observation onto the sample mean:</span>
<span id="cb130-396"><a href="#cb130-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-399"><a href="#cb130-399" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-400"><a href="#cb130-400" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: intercept-projection</span></span>
<span id="cb130-401"><a href="#cb130-401" aria-hidden="true" tabindex="-1"></a>ones <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, n)</span>
<span id="cb130-402"><a href="#cb130-402" aria-hidden="true" tabindex="-1"></a>P1 <span class="ot">&lt;-</span> <span class="fu">outer</span>(ones, ones) <span class="sc">/</span> n  <span class="co"># outer product: 1*1' / n</span></span>
<span id="cb130-403"><a href="#cb130-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-404"><a href="#cb130-404" aria-hidden="true" tabindex="-1"></a><span class="co"># P1 * y = sample mean for every observation</span></span>
<span id="cb130-405"><a href="#cb130-405" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.vector</span>(P1 <span class="sc">%*%</span> y), <span class="fu">rep</span>(<span class="fu">mean</span>(y), n))</span>
<span id="cb130-406"><a href="#cb130-406" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-407"><a href="#cb130-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-408"><a href="#cb130-408" aria-hidden="true" tabindex="-1"></a>Every additional regressor refines this baseline: the full $P$ starts from the mean and adds the directions explained by the other columns of $X$.</span>
<span id="cb130-409"><a href="#cb130-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-410"><a href="#cb130-410" aria-hidden="true" tabindex="-1"></a><span class="fu">## The annihilator matrix</span></span>
<span id="cb130-411"><a href="#cb130-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-412"><a href="#cb130-412" aria-hidden="true" tabindex="-1"></a>The annihilator $M = I_n - P$ projects onto the orthogonal complement — the part of $y$ that $X$ cannot explain:</span>
<span id="cb130-413"><a href="#cb130-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-416"><a href="#cb130-416" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-417"><a href="#cb130-417" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: annihilator-matrix</span></span>
<span id="cb130-418"><a href="#cb130-418" aria-hidden="true" tabindex="-1"></a>M <span class="ot">&lt;-</span> <span class="fu">diag</span>(n) <span class="sc">-</span> P</span>
<span id="cb130-419"><a href="#cb130-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-420"><a href="#cb130-420" aria-hidden="true" tabindex="-1"></a><span class="co"># M*y = residuals</span></span>
<span id="cb130-421"><a href="#cb130-421" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.vector</span>(M <span class="sc">%*%</span> y), <span class="fu">as.numeric</span>(<span class="fu">resid</span>(mod)))</span>
<span id="cb130-422"><a href="#cb130-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-423"><a href="#cb130-423" aria-hidden="true" tabindex="-1"></a><span class="co"># Idempotent and symmetric</span></span>
<span id="cb130-424"><a href="#cb130-424" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(M <span class="sc">%*%</span> M, M)</span>
<span id="cb130-425"><a href="#cb130-425" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">t</span>(M), M)</span>
<span id="cb130-426"><a href="#cb130-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-427"><a href="#cb130-427" aria-hidden="true" tabindex="-1"></a><span class="co"># M annihilates X: M*X = 0</span></span>
<span id="cb130-428"><a href="#cb130-428" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">abs</span>(M <span class="sc">%*%</span> X))</span>
<span id="cb130-429"><a href="#cb130-429" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-430"><a href="#cb130-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-431"><a href="#cb130-431" aria-hidden="true" tabindex="-1"></a>::: {#def-annihilator}</span>
<span id="cb130-432"><a href="#cb130-432" aria-hidden="true" tabindex="-1"></a><span class="fu">## Annihilator Matrix</span></span>
<span id="cb130-433"><a href="#cb130-433" aria-hidden="true" tabindex="-1"></a>The annihilator $M = I_n - P$ projects onto the orthogonal complement of the column space of $X$. It satisfies $MX = 0$ (annihilates $X$), is idempotent and symmetric, and has $\text{tr}(M) = n - K$.</span>
<span id="cb130-434"><a href="#cb130-434" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb130-435"><a href="#cb130-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-436"><a href="#cb130-436" aria-hidden="true" tabindex="-1"></a>Eigenvalues are complementary to $P$: $n - K$ ones and $K$ zeros:</span>
<span id="cb130-437"><a href="#cb130-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-440"><a href="#cb130-440" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-441"><a href="#cb130-441" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: annihilator-eigenvalues</span></span>
<span id="cb130-442"><a href="#cb130-442" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">trace_M =</span> <span class="fu">tr</span>(M), <span class="at">n_minus_K =</span> n <span class="sc">-</span> K)</span>
<span id="cb130-443"><a href="#cb130-443" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-444"><a href="#cb130-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-445"><a href="#cb130-445" aria-hidden="true" tabindex="-1"></a>The **demeaning matrix** $M_1 = I - P_1$ is a special case — it subtracts the mean:</span>
<span id="cb130-446"><a href="#cb130-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-449"><a href="#cb130-449" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-450"><a href="#cb130-450" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: demeaning</span></span>
<span id="cb130-451"><a href="#cb130-451" aria-hidden="true" tabindex="-1"></a>M1 <span class="ot">&lt;-</span> <span class="fu">diag</span>(n) <span class="sc">-</span> P1</span>
<span id="cb130-452"><a href="#cb130-452" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.vector</span>(M1 <span class="sc">%*%</span> y), <span class="fu">as.numeric</span>(y <span class="sc">-</span> <span class="fu">mean</span>(y)))</span>
<span id="cb130-453"><a href="#cb130-453" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-454"><a href="#cb130-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-455"><a href="#cb130-455" aria-hidden="true" tabindex="-1"></a><span class="fu">## Application: regression to the mean</span></span>
<span id="cb130-456"><a href="#cb130-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-457"><a href="#cb130-457" aria-hidden="true" tabindex="-1"></a>Here's a classic application of bivariate OLS. Galton noticed that children of unusually tall parents tend to be shorter than their parents — and children of unusually short parents tend to be taller. This "regression to the mean" is not a causal mechanism; it's a consequence of the BLP slope being less than 1 when the correlation is less than 1.</span>
<span id="cb130-458"><a href="#cb130-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-461"><a href="#cb130-461" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-462"><a href="#cb130-462" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: regression-to-mean</span></span>
<span id="cb130-463"><a href="#cb130-463" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate parent-child heights (jointly normal)</span></span>
<span id="cb130-464"><a href="#cb130-464" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">307</span>)</span>
<span id="cb130-465"><a href="#cb130-465" aria-hidden="true" tabindex="-1"></a>n_ht <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb130-466"><a href="#cb130-466" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.5</span>   <span class="co"># correlation between parent and child height</span></span>
<span id="cb130-467"><a href="#cb130-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-468"><a href="#cb130-468" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb130-469"><a href="#cb130-469" aria-hidden="true" tabindex="-1"></a>heights <span class="ot">&lt;-</span> <span class="fu">mvrnorm</span>(n_ht, <span class="at">mu =</span> <span class="fu">c</span>(<span class="dv">68</span>, <span class="dv">68</span>),</span>
<span id="cb130-470"><a href="#cb130-470" aria-hidden="true" tabindex="-1"></a>                   <span class="at">Sigma =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">9</span>, rho <span class="sc">*</span> <span class="dv">9</span>, rho <span class="sc">*</span> <span class="dv">9</span>, <span class="dv">9</span>), <span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb130-471"><a href="#cb130-471" aria-hidden="true" tabindex="-1"></a>parent_ht <span class="ot">&lt;-</span> heights[, <span class="dv">1</span>]</span>
<span id="cb130-472"><a href="#cb130-472" aria-hidden="true" tabindex="-1"></a>child_ht <span class="ot">&lt;-</span> heights[, <span class="dv">2</span>]</span>
<span id="cb130-473"><a href="#cb130-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-474"><a href="#cb130-474" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS by matrix formula</span></span>
<span id="cb130-475"><a href="#cb130-475" aria-hidden="true" tabindex="-1"></a>X_ht <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, parent_ht)</span>
<span id="cb130-476"><a href="#cb130-476" aria-hidden="true" tabindex="-1"></a>beta_ht <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X_ht), <span class="fu">crossprod</span>(X_ht, child_ht))</span>
<span id="cb130-477"><a href="#cb130-477" aria-hidden="true" tabindex="-1"></a>beta_ht</span>
<span id="cb130-478"><a href="#cb130-478" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-479"><a href="#cb130-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-480"><a href="#cb130-480" aria-hidden="true" tabindex="-1"></a>The slope is $\hat\beta_1 \approx$ <span class="in">`r round(beta_ht[2], 2)`</span>, less than 1. So a parent who is 1 inch above average has a child who is only about <span class="in">`r round(beta_ht[2], 2)`</span> inches above average — regression toward the mean.</span>
<span id="cb130-481"><a href="#cb130-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-484"><a href="#cb130-484" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-485"><a href="#cb130-485" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: regression-to-mean-plot</span></span>
<span id="cb130-486"><a href="#cb130-486" aria-hidden="true" tabindex="-1"></a>df_ht <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">parent =</span> parent_ht, <span class="at">child =</span> child_ht)</span>
<span id="cb130-487"><a href="#cb130-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-488"><a href="#cb130-488" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_ht, <span class="fu">aes</span>(parent, child)) <span class="sc">+</span></span>
<span id="cb130-489"><a href="#cb130-489" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.15</span>, <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb130-490"><a href="#cb130-490" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"steelblue"</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb130-491"><a href="#cb130-491" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb130-492"><a href="#cb130-492" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">74</span>, <span class="at">y =</span> <span class="fl">74.5</span>, <span class="at">label =</span> <span class="st">"slope = 1 (no regression)"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb130-493"><a href="#cb130-493" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Parent height (in)"</span>, <span class="at">y =</span> <span class="st">"Child height (in)"</span>,</span>
<span id="cb130-494"><a href="#cb130-494" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Regression to the mean"</span>,</span>
<span id="cb130-495"><a href="#cb130-495" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">paste0</span>(<span class="st">"Slope = "</span>, <span class="fu">round</span>(beta_ht[<span class="dv">2</span>], <span class="dv">2</span>),</span>
<span id="cb130-496"><a href="#cb130-496" aria-hidden="true" tabindex="-1"></a>                         <span class="st">" &lt; 1: children of tall parents are less extreme"</span>)) <span class="sc">+</span></span>
<span id="cb130-497"><a href="#cb130-497" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb130-498"><a href="#cb130-498" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-499"><a href="#cb130-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-500"><a href="#cb130-500" aria-hidden="true" tabindex="-1"></a>The tallest parents (above the 95th percentile) have children who are closer to the mean:</span>
<span id="cb130-501"><a href="#cb130-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-504"><a href="#cb130-504" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-505"><a href="#cb130-505" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tall-parents</span></span>
<span id="cb130-506"><a href="#cb130-506" aria-hidden="true" tabindex="-1"></a>tall <span class="ot">&lt;-</span> parent_ht <span class="sc">&gt;</span> <span class="fu">quantile</span>(parent_ht, <span class="fl">0.95</span>)</span>
<span id="cb130-507"><a href="#cb130-507" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">parent_mean =</span> <span class="fu">mean</span>(parent_ht[tall]),</span>
<span id="cb130-508"><a href="#cb130-508" aria-hidden="true" tabindex="-1"></a>  <span class="at">child_mean =</span> <span class="fu">mean</span>(child_ht[tall]),</span>
<span id="cb130-509"><a href="#cb130-509" aria-hidden="true" tabindex="-1"></a>  <span class="at">difference =</span> <span class="fu">mean</span>(parent_ht[tall]) <span class="sc">-</span> <span class="fu">mean</span>(child_ht[tall]))</span>
<span id="cb130-510"><a href="#cb130-510" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-511"><a href="#cb130-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-512"><a href="#cb130-512" aria-hidden="true" tabindex="-1"></a><span class="fu">## Residuals vs. disturbances</span></span>
<span id="cb130-513"><a href="#cb130-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-514"><a href="#cb130-514" aria-hidden="true" tabindex="-1"></a>The true model is $y = X\beta + e$ where $e$ is unobservable. The residuals $\hat{e} = My$ relate to the disturbances through:</span>
<span id="cb130-515"><a href="#cb130-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-516"><a href="#cb130-516" aria-hidden="true" tabindex="-1"></a>$$\hat{e} = My = M(X\beta + e) = \underbrace{MX}_{= 0}\beta + Me = Me$$</span>
<span id="cb130-517"><a href="#cb130-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-518"><a href="#cb130-518" aria-hidden="true" tabindex="-1"></a>Let's simulate to see this. We know $\beta$ and $e$ because we generate the data:</span>
<span id="cb130-519"><a href="#cb130-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-522"><a href="#cb130-522" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-523"><a href="#cb130-523" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: resid-vs-disturbance</span></span>
<span id="cb130-524"><a href="#cb130-524" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">307</span>)</span>
<span id="cb130-525"><a href="#cb130-525" aria-hidden="true" tabindex="-1"></a>n_sim <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb130-526"><a href="#cb130-526" aria-hidden="true" tabindex="-1"></a>K_sim <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb130-527"><a href="#cb130-527" aria-hidden="true" tabindex="-1"></a>X_sim <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, <span class="fu">rnorm</span>(n_sim))</span>
<span id="cb130-528"><a href="#cb130-528" aria-hidden="true" tabindex="-1"></a>beta_true <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb130-529"><a href="#cb130-529" aria-hidden="true" tabindex="-1"></a>e_true <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_sim, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb130-530"><a href="#cb130-530" aria-hidden="true" tabindex="-1"></a>y_sim <span class="ot">&lt;-</span> X_sim <span class="sc">%*%</span> beta_true <span class="sc">+</span> e_true</span>
<span id="cb130-531"><a href="#cb130-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-532"><a href="#cb130-532" aria-hidden="true" tabindex="-1"></a><span class="co"># Build M for this design</span></span>
<span id="cb130-533"><a href="#cb130-533" aria-hidden="true" tabindex="-1"></a>P_sim <span class="ot">&lt;-</span> X_sim <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X_sim)) <span class="sc">%*%</span> <span class="fu">t</span>(X_sim)</span>
<span id="cb130-534"><a href="#cb130-534" aria-hidden="true" tabindex="-1"></a>M_sim <span class="ot">&lt;-</span> <span class="fu">diag</span>(n_sim) <span class="sc">-</span> P_sim</span>
<span id="cb130-535"><a href="#cb130-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-536"><a href="#cb130-536" aria-hidden="true" tabindex="-1"></a><span class="co"># Residuals = M * disturbances</span></span>
<span id="cb130-537"><a href="#cb130-537" aria-hidden="true" tabindex="-1"></a>e_hat <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(M_sim <span class="sc">%*%</span> y_sim)</span>
<span id="cb130-538"><a href="#cb130-538" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(e_hat, <span class="fu">as.vector</span>(M_sim <span class="sc">%*%</span> e_true))</span>
<span id="cb130-539"><a href="#cb130-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-540"><a href="#cb130-540" aria-hidden="true" tabindex="-1"></a><span class="co"># Residuals have smaller variance — M zeroes out K dimensions</span></span>
<span id="cb130-541"><a href="#cb130-541" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">var_disturbances =</span> <span class="fu">var</span>(e_true), <span class="at">var_residuals =</span> <span class="fu">var</span>(e_hat))</span>
<span id="cb130-542"><a href="#cb130-542" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-543"><a href="#cb130-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-544"><a href="#cb130-544" aria-hidden="true" tabindex="-1"></a><span class="fu">## Estimating $\sigma^2$: the trace trick</span></span>
<span id="cb130-545"><a href="#cb130-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-546"><a href="#cb130-546" aria-hidden="true" tabindex="-1"></a>The natural estimator $\hat\sigma^2 = \hat{e}'\hat{e}/n$ is biased downward because $\hat{e}'\hat{e} = e'Me \leq e'e$ ($M$ is positive semi-definite). The unbiased estimator divides by $n - K$.</span>
<span id="cb130-547"><a href="#cb130-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-548"><a href="#cb130-548" aria-hidden="true" tabindex="-1"></a>The proof is a chain of matrix operations. Every step translates to R:</span>
<span id="cb130-549"><a href="#cb130-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-552"><a href="#cb130-552" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-553"><a href="#cb130-553" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: trace-trick</span></span>
<span id="cb130-554"><a href="#cb130-554" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: e'Me is a scalar = its own trace</span></span>
<span id="cb130-555"><a href="#cb130-555" aria-hidden="true" tabindex="-1"></a>scalar_form <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">t</span>(e_true) <span class="sc">%*%</span> M_sim <span class="sc">%*%</span> e_true)</span>
<span id="cb130-556"><a href="#cb130-556" aria-hidden="true" tabindex="-1"></a>trace_form <span class="ot">&lt;-</span> <span class="fu">tr</span>(M_sim <span class="sc">%*%</span> <span class="fu">tcrossprod</span>(e_true))  <span class="co"># tr(M * ee')</span></span>
<span id="cb130-557"><a href="#cb130-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-558"><a href="#cb130-558" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">scalar =</span> scalar_form, <span class="at">trace =</span> trace_form)</span>
<span id="cb130-559"><a href="#cb130-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-560"><a href="#cb130-560" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: E[ee'] = sigma^2 * I, so E[tr(Mee')] = sigma^2 * tr(M)</span></span>
<span id="cb130-561"><a href="#cb130-561" aria-hidden="true" tabindex="-1"></a><span class="co"># tr(M) = n - K, so E[e'hat * e'hat] = sigma^2 * (n - K)</span></span>
<span id="cb130-562"><a href="#cb130-562" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">trace_M =</span> <span class="fu">tr</span>(M_sim), <span class="at">n_minus_K =</span> n_sim <span class="sc">-</span> K_sim)</span>
<span id="cb130-563"><a href="#cb130-563" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-564"><a href="#cb130-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-565"><a href="#cb130-565" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb130-566"><a href="#cb130-566" aria-hidden="true" tabindex="-1"></a><span class="fu">## The $n - K$ Divisor</span></span>
<span id="cb130-567"><a href="#cb130-567" aria-hidden="true" tabindex="-1"></a>The unbiased variance estimator divides by $n - K$ (not $n$) because the residuals live in an $(n - K)$-dimensional subspace. The $K$ "lost" dimensions are consumed by estimating $\hat\beta$. This is the matrix version of Bessel's correction.</span>
<span id="cb130-568"><a href="#cb130-568" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb130-569"><a href="#cb130-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-570"><a href="#cb130-570" aria-hidden="true" tabindex="-1"></a>This is why the unbiased estimator is $s_e^2 = \hat{e}'\hat{e}/(n-K)$:</span>
<span id="cb130-571"><a href="#cb130-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-574"><a href="#cb130-574" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-575"><a href="#cb130-575" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: error-variance</span></span>
<span id="cb130-576"><a href="#cb130-576" aria-hidden="true" tabindex="-1"></a><span class="co"># Back to the Prestige data</span></span>
<span id="cb130-577"><a href="#cb130-577" aria-hidden="true" tabindex="-1"></a>e_hat_prestige <span class="ot">&lt;-</span> <span class="fu">resid</span>(mod)</span>
<span id="cb130-578"><a href="#cb130-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-579"><a href="#cb130-579" aria-hidden="true" tabindex="-1"></a>sigma2_biased <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(e_hat_prestige)) <span class="sc">/</span> n</span>
<span id="cb130-580"><a href="#cb130-580" aria-hidden="true" tabindex="-1"></a>sigma2_unbiased <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(e_hat_prestige)) <span class="sc">/</span> (n <span class="sc">-</span> K)</span>
<span id="cb130-581"><a href="#cb130-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-582"><a href="#cb130-582" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">biased =</span> sigma2_biased,</span>
<span id="cb130-583"><a href="#cb130-583" aria-hidden="true" tabindex="-1"></a>  <span class="at">unbiased =</span> sigma2_unbiased,</span>
<span id="cb130-584"><a href="#cb130-584" aria-hidden="true" tabindex="-1"></a>  <span class="at">R_sigma2 =</span> <span class="fu">sigma</span>(mod)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb130-585"><a href="#cb130-585" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-586"><a href="#cb130-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-587"><a href="#cb130-587" aria-hidden="true" tabindex="-1"></a>The underestimation shows up in the eigenvalues of $M$: $n - K$ eigenvalues are 1, and $K$ are 0. The residuals live in an $(n-K)$-dimensional subspace:</span>
<span id="cb130-588"><a href="#cb130-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-591"><a href="#cb130-591" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-592"><a href="#cb130-592" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: m-eigenvalues</span></span>
<span id="cb130-593"><a href="#cb130-593" aria-hidden="true" tabindex="-1"></a>eig_M <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">eigen</span>(M)<span class="sc">$</span>values, <span class="dv">10</span>)</span>
<span id="cb130-594"><a href="#cb130-594" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">eigenvalues_equal_1 =</span> <span class="fu">sum</span>(eig_M <span class="sc">==</span> <span class="dv">1</span>),</span>
<span id="cb130-595"><a href="#cb130-595" aria-hidden="true" tabindex="-1"></a>  <span class="at">eigenvalues_equal_0 =</span> <span class="fu">sum</span>(eig_M <span class="sc">==</span> <span class="dv">0</span>))</span>
<span id="cb130-596"><a href="#cb130-596" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-597"><a href="#cb130-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-598"><a href="#cb130-598" aria-hidden="true" tabindex="-1"></a><span class="fu">## Variance of $\hat\beta$: building $s_e^2(X'X)^{-1}$</span></span>
<span id="cb130-599"><a href="#cb130-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-600"><a href="#cb130-600" aria-hidden="true" tabindex="-1"></a>Under homoskedasticity, $\text{Var}(\hat\beta|X) = \sigma^2(X'X)^{-1}$. Each piece is a matrix operation:</span>
<span id="cb130-601"><a href="#cb130-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-604"><a href="#cb130-604" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-605"><a href="#cb130-605" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: vcov-construction</span></span>
<span id="cb130-606"><a href="#cb130-606" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: (X'X)^{-1}</span></span>
<span id="cb130-607"><a href="#cb130-607" aria-hidden="true" tabindex="-1"></a>XtX_inv <span class="ot">&lt;-</span> <span class="fu">solve</span>(XtX)</span>
<span id="cb130-608"><a href="#cb130-608" aria-hidden="true" tabindex="-1"></a>XtX_inv</span>
<span id="cb130-609"><a href="#cb130-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-610"><a href="#cb130-610" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: multiply by s_e^2</span></span>
<span id="cb130-611"><a href="#cb130-611" aria-hidden="true" tabindex="-1"></a>vcov_manual <span class="ot">&lt;-</span> <span class="fu">sigma</span>(mod)<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> XtX_inv</span>
<span id="cb130-612"><a href="#cb130-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-613"><a href="#cb130-613" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: compare to R</span></span>
<span id="cb130-614"><a href="#cb130-614" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(vcov_manual, <span class="fu">vcov</span>(mod), <span class="at">check.attributes =</span> <span class="cn">FALSE</span>)</span>
<span id="cb130-615"><a href="#cb130-615" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-616"><a href="#cb130-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-617"><a href="#cb130-617" aria-hidden="true" tabindex="-1"></a>Standard errors are the square roots of the diagonal:</span>
<span id="cb130-618"><a href="#cb130-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-621"><a href="#cb130-621" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-622"><a href="#cb130-622" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: standard-errors</span></span>
<span id="cb130-623"><a href="#cb130-623" aria-hidden="true" tabindex="-1"></a>se_manual <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(vcov_manual))</span>
<span id="cb130-624"><a href="#cb130-624" aria-hidden="true" tabindex="-1"></a>se_R <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">summary</span>(mod))[, <span class="st">"Std. Error"</span>]</span>
<span id="cb130-625"><a href="#cb130-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-626"><a href="#cb130-626" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">manual =</span> se_manual, <span class="at">R =</span> se_R)</span>
<span id="cb130-627"><a href="#cb130-627" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-628"><a href="#cb130-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-629"><a href="#cb130-629" aria-hidden="true" tabindex="-1"></a><span class="fu">### Why $(X'X)^{-1}$ determines precision</span></span>
<span id="cb130-630"><a href="#cb130-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-631"><a href="#cb130-631" aria-hidden="true" tabindex="-1"></a>The eigenvalues of $(X'X)^{-1}$ are the reciprocals of those of $X'X$. Large eigenvalues of $X'X$ (strong signal) become small eigenvalues of $(X'X)^{-1}$ (precise estimates). Near-collinearity creates a tiny eigenvalue in $X'X$, which inflates variance:</span>
<span id="cb130-632"><a href="#cb130-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-635"><a href="#cb130-635" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-636"><a href="#cb130-636" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: xtx-inv-eigenvalues</span></span>
<span id="cb130-637"><a href="#cb130-637" aria-hidden="true" tabindex="-1"></a>eig_XtX <span class="ot">&lt;-</span> <span class="fu">eigen</span>(XtX)<span class="sc">$</span>values</span>
<span id="cb130-638"><a href="#cb130-638" aria-hidden="true" tabindex="-1"></a>eig_inv <span class="ot">&lt;-</span> <span class="fu">eigen</span>(XtX_inv)<span class="sc">$</span>values</span>
<span id="cb130-639"><a href="#cb130-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-640"><a href="#cb130-640" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">XtX =</span> eig_XtX, <span class="at">XtX_inv =</span> eig_inv, <span class="at">product =</span> eig_XtX <span class="sc">*</span> eig_inv)</span>
<span id="cb130-641"><a href="#cb130-641" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-642"><a href="#cb130-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-643"><a href="#cb130-643" aria-hidden="true" tabindex="-1"></a>The products are all 1: the eigenvalues invert exactly.</span>
<span id="cb130-644"><a href="#cb130-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-645"><a href="#cb130-645" aria-hidden="true" tabindex="-1"></a><span class="fu">## Application: the Prestige regression</span></span>
<span id="cb130-646"><a href="#cb130-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-647"><a href="#cb130-647" aria-hidden="true" tabindex="-1"></a>Let's interpret the full regression. Education and income both predict occupational prestige:</span>
<span id="cb130-648"><a href="#cb130-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-651"><a href="#cb130-651" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-652"><a href="#cb130-652" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: prestige-application</span></span>
<span id="cb130-653"><a href="#cb130-653" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb130-654"><a href="#cb130-654" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-655"><a href="#cb130-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-656"><a href="#cb130-656" aria-hidden="true" tabindex="-1"></a>The coefficient on education (<span class="in">`r round(coef(mod)[2], 1)`</span>) says: holding income constant, one additional year of average education is associated with about <span class="in">`r round(coef(mod)[2], 1)`</span> points more prestige. The coefficient on income (<span class="in">`r round(coef(mod)[3], 4)`</span>) is small in magnitude because income is in dollars — a \$1,000 increase predicts about <span class="in">`r round(coef(mod)[3] * 1000, 1)`</span> points.</span>
<span id="cb130-657"><a href="#cb130-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-658"><a href="#cb130-658" aria-hidden="true" tabindex="-1"></a>Let's see which occupations the model fits well and poorly, using the projection and annihilator:</span>
<span id="cb130-659"><a href="#cb130-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-662"><a href="#cb130-662" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-663"><a href="#cb130-663" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: prestige-residuals</span></span>
<span id="cb130-664"><a href="#cb130-664" aria-hidden="true" tabindex="-1"></a>Prestige<span class="sc">$</span>fitted <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(P <span class="sc">%*%</span> y)</span>
<span id="cb130-665"><a href="#cb130-665" aria-hidden="true" tabindex="-1"></a>Prestige<span class="sc">$</span>resid <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(M <span class="sc">%*%</span> y)</span>
<span id="cb130-666"><a href="#cb130-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-667"><a href="#cb130-667" aria-hidden="true" tabindex="-1"></a><span class="co"># Largest positive residuals: more prestige than education+income predict</span></span>
<span id="cb130-668"><a href="#cb130-668" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Prestige[<span class="fu">order</span>(<span class="sc">-</span>Prestige<span class="sc">$</span>resid), <span class="fu">c</span>(<span class="st">"education"</span>, <span class="st">"income"</span>, <span class="st">"prestige"</span>, <span class="st">"fitted"</span>, <span class="st">"resid"</span>)], <span class="dv">5</span>)</span>
<span id="cb130-669"><a href="#cb130-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-670"><a href="#cb130-670" aria-hidden="true" tabindex="-1"></a><span class="co"># Largest negative residuals: less prestige than predicted</span></span>
<span id="cb130-671"><a href="#cb130-671" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Prestige[<span class="fu">order</span>(Prestige<span class="sc">$</span>resid), <span class="fu">c</span>(<span class="st">"education"</span>, <span class="st">"income"</span>, <span class="st">"prestige"</span>, <span class="st">"fitted"</span>, <span class="st">"resid"</span>)], <span class="dv">5</span>)</span>
<span id="cb130-672"><a href="#cb130-672" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-673"><a href="#cb130-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-676"><a href="#cb130-676" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-677"><a href="#cb130-677" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: prestige-residual-plot</span></span>
<span id="cb130-678"><a href="#cb130-678" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(Prestige, <span class="fu">aes</span>(fitted, resid)) <span class="sc">+</span></span>
<span id="cb130-679"><a href="#cb130-679" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb130-680"><a href="#cb130-680" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb130-681"><a href="#cb130-681" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="at">data =</span> Prestige[<span class="fu">abs</span>(Prestige<span class="sc">$</span>resid) <span class="sc">&gt;</span> <span class="dv">15</span>, ],</span>
<span id="cb130-682"><a href="#cb130-682" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">rownames</span>(Prestige)[<span class="fu">abs</span>(Prestige<span class="sc">$</span>resid) <span class="sc">&gt;</span> <span class="dv">15</span>]),</span>
<span id="cb130-683"><a href="#cb130-683" aria-hidden="true" tabindex="-1"></a>            <span class="at">hjust =</span> <span class="sc">-</span><span class="fl">0.1</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb130-684"><a href="#cb130-684" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Fitted values (Py)"</span>, <span class="at">y =</span> <span class="st">"Residuals (My)"</span>,</span>
<span id="cb130-685"><a href="#cb130-685" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Prestige: fitted vs. residuals"</span>) <span class="sc">+</span></span>
<span id="cb130-686"><a href="#cb130-686" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb130-687"><a href="#cb130-687" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-688"><a href="#cb130-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-689"><a href="#cb130-689" aria-hidden="true" tabindex="-1"></a><span class="fu">## ANOVA as inner products</span></span>
<span id="cb130-690"><a href="#cb130-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-691"><a href="#cb130-691" aria-hidden="true" tabindex="-1"></a>The decomposition $y = \hat{y} + \hat{e}$ is orthogonal. In matrix terms, $\hat{y}'\hat{e} = (Py)'(My) = y'PMy = 0$:</span>
<span id="cb130-692"><a href="#cb130-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-695"><a href="#cb130-695" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-696"><a href="#cb130-696" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: orthogonality</span></span>
<span id="cb130-697"><a href="#cb130-697" aria-hidden="true" tabindex="-1"></a><span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(<span class="fu">fitted</span>(mod), <span class="fu">resid</span>(mod)))</span>
<span id="cb130-698"><a href="#cb130-698" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-699"><a href="#cb130-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-700"><a href="#cb130-700" aria-hidden="true" tabindex="-1"></a>After centering, the inner products give sums of squares:</span>
<span id="cb130-701"><a href="#cb130-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-704"><a href="#cb130-704" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-705"><a href="#cb130-705" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: anova-decomposition</span></span>
<span id="cb130-706"><a href="#cb130-706" aria-hidden="true" tabindex="-1"></a><span class="co"># SST = ||M1 * y||^2  (total variation around the mean)</span></span>
<span id="cb130-707"><a href="#cb130-707" aria-hidden="true" tabindex="-1"></a>SST <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(M1 <span class="sc">%*%</span> y))</span>
<span id="cb130-708"><a href="#cb130-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-709"><a href="#cb130-709" aria-hidden="true" tabindex="-1"></a><span class="co"># SSR = ||(P - P1) * y||^2  (variation explained by regressors beyond the mean)</span></span>
<span id="cb130-710"><a href="#cb130-710" aria-hidden="true" tabindex="-1"></a>SSR <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(<span class="fu">fitted</span>(mod) <span class="sc">-</span> <span class="fu">mean</span>(y)))</span>
<span id="cb130-711"><a href="#cb130-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-712"><a href="#cb130-712" aria-hidden="true" tabindex="-1"></a><span class="co"># SSE = ||M * y||^2  (unexplained variation)</span></span>
<span id="cb130-713"><a href="#cb130-713" aria-hidden="true" tabindex="-1"></a>SSE <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(<span class="fu">resid</span>(mod)))</span>
<span id="cb130-714"><a href="#cb130-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-715"><a href="#cb130-715" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">SST =</span> SST, <span class="at">SSR_plus_SSE =</span> SSR <span class="sc">+</span> SSE)</span>
<span id="cb130-716"><a href="#cb130-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-717"><a href="#cb130-717" aria-hidden="true" tabindex="-1"></a><span class="co"># Cross term is zero when X includes a constant</span></span>
<span id="cb130-718"><a href="#cb130-718" aria-hidden="true" tabindex="-1"></a><span class="fu">as.numeric</span>(<span class="fu">crossprod</span>(<span class="fu">fitted</span>(mod) <span class="sc">-</span> <span class="fu">mean</span>(y), <span class="fu">resid</span>(mod)))</span>
<span id="cb130-719"><a href="#cb130-719" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-720"><a href="#cb130-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-721"><a href="#cb130-721" aria-hidden="true" tabindex="-1"></a><span class="fu">## $R^2$</span></span>
<span id="cb130-722"><a href="#cb130-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-723"><a href="#cb130-723" aria-hidden="true" tabindex="-1"></a>$R^2 = \text{SSR}/\text{SST} = 1 - \text{SSE}/\text{SST}$:</span>
<span id="cb130-724"><a href="#cb130-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-727"><a href="#cb130-727" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-728"><a href="#cb130-728" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: r-squared</span></span>
<span id="cb130-729"><a href="#cb130-729" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">R2 =</span> SSR <span class="sc">/</span> SST,</span>
<span id="cb130-730"><a href="#cb130-730" aria-hidden="true" tabindex="-1"></a>  <span class="at">R2_alt =</span> <span class="dv">1</span> <span class="sc">-</span> SSE <span class="sc">/</span> SST,</span>
<span id="cb130-731"><a href="#cb130-731" aria-hidden="true" tabindex="-1"></a>  <span class="at">R_reports =</span> <span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared)</span>
<span id="cb130-732"><a href="#cb130-732" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-733"><a href="#cb130-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-734"><a href="#cb130-734" aria-hidden="true" tabindex="-1"></a>Adding regressors can only increase $R^2$, even if the variable is noise. The adjusted $R^2$ penalizes for $K$:</span>
<span id="cb130-735"><a href="#cb130-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-738"><a href="#cb130-738" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb130-739"><a href="#cb130-739" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: adjusted-r2</span></span>
<span id="cb130-740"><a href="#cb130-740" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb130-741"><a href="#cb130-741" aria-hidden="true" tabindex="-1"></a>Prestige<span class="sc">$</span>noise <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb130-742"><a href="#cb130-742" aria-hidden="true" tabindex="-1"></a>mod_noise <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> noise, <span class="at">data =</span> Prestige)</span>
<span id="cb130-743"><a href="#cb130-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-744"><a href="#cb130-744" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">R2_original =</span> <span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared,</span>
<span id="cb130-745"><a href="#cb130-745" aria-hidden="true" tabindex="-1"></a>  <span class="at">R2_with_noise =</span> <span class="fu">summary</span>(mod_noise)<span class="sc">$</span>r.squared,</span>
<span id="cb130-746"><a href="#cb130-746" aria-hidden="true" tabindex="-1"></a>  <span class="at">adj_R2_original =</span> <span class="fu">summary</span>(mod)<span class="sc">$</span>adj.r.squared,</span>
<span id="cb130-747"><a href="#cb130-747" aria-hidden="true" tabindex="-1"></a>  <span class="at">adj_R2_with_noise =</span> <span class="fu">summary</span>(mod_noise)<span class="sc">$</span>adj.r.squared)</span>
<span id="cb130-748"><a href="#cb130-748" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb130-749"><a href="#cb130-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-750"><a href="#cb130-750" aria-hidden="true" tabindex="-1"></a>Raw $R^2$ ticks up; adjusted $R^2$ drops — correctly penalizing the useless variable.</span>
<span id="cb130-751"><a href="#cb130-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-752"><a href="#cb130-752" aria-hidden="true" tabindex="-1"></a>$R^2$ measures descriptive fit, not causal validity. Typical values: cross-sectional micro data $\approx 0.2$--$0.4$, aggregate time series $\approx 0.7$--$0.9$.</span>
<span id="cb130-753"><a href="#cb130-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-754"><a href="#cb130-754" aria-hidden="true" tabindex="-1"></a><span class="fu">## Naming conventions: a warning</span></span>
<span id="cb130-755"><a href="#cb130-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-756"><a href="#cb130-756" aria-hidden="true" tabindex="-1"></a>Different textbooks use SSE and SSR with opposite meanings. In this course (following Hansen), SSR is "regression" (explained) and SSE is "error" (unexplained). Some texts reverse these. The math is always $\text{SST} = \text{explained} + \text{unexplained}$.</span>
<span id="cb130-757"><a href="#cb130-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-758"><a href="#cb130-758" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb130-759"><a href="#cb130-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-760"><a href="#cb130-760" aria-hidden="true" tabindex="-1"></a>The OLS estimator is a sequence of matrix operations:</span>
<span id="cb130-761"><a href="#cb130-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-762"><a href="#cb130-762" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Math <span class="pp">|</span> R <span class="pp">|</span> What it does <span class="pp">|</span></span>
<span id="cb130-763"><a href="#cb130-763" aria-hidden="true" tabindex="-1"></a><span class="pp">|------|---|-------------|</span></span>
<span id="cb130-764"><a href="#cb130-764" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $X'X$ <span class="pp">|</span> <span class="in">`crossprod(X)`</span> <span class="pp">|</span> Gram matrix of regressors <span class="pp">|</span></span>
<span id="cb130-765"><a href="#cb130-765" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $(X'X)^{-1}$ <span class="pp">|</span> <span class="in">`solve(crossprod(X))`</span> <span class="pp">|</span> Inverse <span class="pp">|</span></span>
<span id="cb130-766"><a href="#cb130-766" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $\hat\beta = (X'X)^{-1}X'y$ <span class="pp">|</span> <span class="in">`solve(crossprod(X), crossprod(X, y))`</span> <span class="pp">|</span> OLS coefficients <span class="pp">|</span></span>
<span id="cb130-767"><a href="#cb130-767" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $P = X(X'X)^{-1}X'$ <span class="pp">|</span> <span class="in">`X %*% solve(crossprod(X)) %*% t(X)`</span> <span class="pp">|</span> Projection (hat matrix) <span class="pp">|</span></span>
<span id="cb130-768"><a href="#cb130-768" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $M = I - P$ <span class="pp">|</span> <span class="in">`diag(n) - P`</span> <span class="pp">|</span> Annihilator <span class="pp">|</span></span>
<span id="cb130-769"><a href="#cb130-769" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $\text{tr}(M)$ <span class="pp">|</span> <span class="in">`sum(diag(M))`</span> <span class="pp">|</span> Degrees of freedom ($n - K$) <span class="pp">|</span></span>
<span id="cb130-770"><a href="#cb130-770" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> eigenvalues of $P$ <span class="pp">|</span> <span class="in">`eigen(P)$values`</span> <span class="pp">|</span> All 0 or 1 <span class="pp">|</span></span>
<span id="cb130-771"><a href="#cb130-771" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $s_e^2(X'X)^{-1}$ <span class="pp">|</span> <span class="in">`sigma(mod)^2 * solve(crossprod(X))`</span> <span class="pp">|</span> Variance-covariance of $\hat\beta$ <span class="pp">|</span></span>
<span id="cb130-772"><a href="#cb130-772" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $\text{SE}(\hat\beta_k)$ <span class="pp">|</span> <span class="in">`sqrt(diag(vcov(mod)))`</span> <span class="pp">|</span> Standard errors <span class="pp">|</span></span>
<span id="cb130-773"><a href="#cb130-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-774"><a href="#cb130-774" aria-hidden="true" tabindex="-1"></a>Key facts:</span>
<span id="cb130-775"><a href="#cb130-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-776"><a href="#cb130-776" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>OLS is **projection**: $\hat{y} = Py$ is the closest point to $y$ in the column space of $X$, and $\hat{e} = My$ is the orthogonal residual.</span>
<span id="cb130-777"><a href="#cb130-777" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$P$ and $M$ are **symmetric** and **idempotent**, with eigenvalues in $<span class="sc">\{</span>0, 1<span class="sc">\}</span>$.</span>
<span id="cb130-778"><a href="#cb130-778" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\text{tr}(P) = K$ and $\text{tr}(M) = n - K$ count dimensions.</span>
<span id="cb130-779"><a href="#cb130-779" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The **trace trick** proves $s_e^2$ is unbiased: $\mathbb{E}<span class="co">[</span><span class="ot">e'Me</span><span class="co">]</span> = \sigma^2 \text{tr}(M) = \sigma^2(n-K)$.</span>
<span id="cb130-780"><a href="#cb130-780" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Eigenvalues of $(X'X)^{-1}$ are reciprocals of those of $X'X$: near-collinearity inflates variance.</span>
<span id="cb130-781"><a href="#cb130-781" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Regression to the mean** is a consequence of $\hat\beta_1 &lt; 1$ when $|\rho| &lt; 1$.</span>
<span id="cb130-782"><a href="#cb130-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-783"><a href="#cb130-783" aria-hidden="true" tabindex="-1"></a>Next: <span class="co">[</span><span class="ot">Sensitivity and Leverage</span><span class="co">](ch04-sensitivity.qmd)</span> — the Frisch-Waugh-Lovell theorem, partial $R^2$, and influential observations.</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>