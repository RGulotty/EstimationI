{
  "hash": "c9ffa8a64c3d68c7c5747553dda2411e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"12. Panel Data\"\nsubtitle: \"Pooled, between, and within estimators; difference-in-differences; dynamic panels\"\n---\n\nThis chapter covers panel data methods: pooled OLS, the between and within (fixed effects) estimators, difference-in-differences, clustering, and dynamic panel GMM. We use the `plm` package for panel estimation, `panelView` for visualization, and `fixest` for fast fixed effects with flexible standard errors.\n\n**Questions this chapter answers:**\n\n1. How do `panelView` and `ggplot` help visualize treatment patterns, missingness, and outcome dynamics?\n2. What are the pooled, between, and within estimators — and when is each consistent?\n3. How does difference-in-differences identify causal effects under parallel trends?\n4. How do Arellano-Bond and system GMM handle dynamic panels with lagged dependent variables?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(plm)\nlibrary(panelView)\nlibrary(fixest)\nlibrary(sandwich)\nlibrary(lmtest)\nlibrary(estimatr)\n```\n:::\n\n\n## Visualizing panel structure with panelView\n\nBefore estimating anything, it pays to *look* at your panel. The `panelView` package visualizes treatment patterns, missingness, and outcome dynamics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the built-in datasets\ndata(panelView)\n```\n:::\n\n\n### Treatment status plots\n\nThe `turnout` dataset tracks U.S. state voter turnout and election-day registration (EDR) policy adoption---a classic staggered treatment design (see the [TWFE bias discussion](ch13-fixed-effects.qmd#sec-twfe-bias) for the problem under staggered adoption).\n\n\n::: {.cell}\n\n```{.r .cell-code}\npanelview(turnout ~ policy_edr + policy_mail_in + policy_motor,\n          data = turnout, index = c(\"abb\", \"year\"),\n          xlab = \"Year\", ylab = \"State\",\n          main = \"Election-day registration adoption by state\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fortify(data, ...): Arguments in `...` must be used.\n✖ Problematic argument:\n• position = \"identity\"\nℹ Did you misspell an argument name?\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\nℹ The deprecated feature was likely used in the panelView package.\n  Please report the issue to the authors.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: In `margin()`, the argument `t` should have length 1, not length 4.\nℹ Argument get(s) truncated to length 1.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\nℹ The deprecated feature was likely used in the panelView package.\n  Please report the issue to the authors.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ch12-panel_files/figure-html/panelview-treat-1.png){width=672}\n:::\n:::\n\n\nSorting by treatment timing reveals the staggered adoption pattern:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npanelview(turnout ~ policy_edr + policy_mail_in + policy_motor,\n          data = turnout, index = c(\"abb\", \"year\"),\n          by.timing = TRUE,\n          xlab = \"Year\", ylab = \"State\",\n          main = \"EDR adoption sorted by timing\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fortify(data, ...): Arguments in `...` must be used.\n✖ Problematic argument:\n• position = \"identity\"\nℹ Did you misspell an argument name?\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: In `margin()`, the argument `t` should have length 1, not length 4.\nℹ Argument get(s) truncated to length 1.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ch12-panel_files/figure-html/panelview-timing-1.png){width=672}\n:::\n:::\n\n\n### Missing data plots\n\nThe `capacity` dataset (country-level state capacity) has substantial missingness. `panelView` reveals the pattern:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npanelview(Capacity ~ demo + lngdp + lnpop,\n          data = capacity, index = c(\"ccode\", \"year\"),\n          type = \"miss\", axis.lab = \"off\",\n          main = \"Missing data in state capacity panel\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fortify(data, ...): Arguments in `...` must be used.\n✖ Problematic argument:\n• position = \"identity\"\nℹ Did you misspell an argument name?\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: In `margin()`, the argument `t` should have length 1, not length 4.\nℹ Argument get(s) truncated to length 1.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ch12-panel_files/figure-html/panelview-missing-1.png){width=672}\n:::\n:::\n\n\n### Outcome dynamics\n\nWe can also plot the outcome variable over time, colored by treatment status:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npanelview(turnout ~ policy_edr,\n          data = turnout, index = c(\"abb\", \"year\"),\n          type = \"outcome\",\n          main = \"Voter turnout by EDR status\",\n          ylab = \"Turnout (%)\", xlab = \"Year\")\n```\n\n::: {.cell-output-display}\n![](ch12-panel_files/figure-html/panelview-outcome-1.png){width=672}\n:::\n:::\n\n\n## Panel data basics: the Produc dataset\n\nWe use the `Produc` dataset from the `plm` package: 48 U.S. states observed from 1970--1986, with gross state product, public capital, private capital, employment, and unemployment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"Produc\", package = \"plm\")\ncat(\"States:\", length(unique(Produc$state)),\n    \" Years:\", min(Produc$year), \"-\", max(Produc$year),\n    \" Obs:\", nrow(Produc), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStates: 48  Years: 1970 - 1986  Obs: 816 \n```\n\n\n:::\n\n```{.r .cell-code}\nhead(Produc[, c(\"state\", \"year\", \"gsp\", \"pcap\", \"emp\", \"unemp\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    state year   gsp     pcap    emp unemp\n1 ALABAMA 1970 28418 15032.67 1010.5   4.7\n2 ALABAMA 1971 29375 15501.94 1021.9   5.2\n3 ALABAMA 1972 31303 15972.41 1072.3   4.7\n4 ALABAMA 1973 33430 16406.26 1135.5   3.9\n5 ALABAMA 1974 33749 16762.67 1169.8   5.5\n6 ALABAMA 1975 33604 17316.26 1155.4   7.7\n```\n\n\n:::\n:::\n\n\nWe model log gross state product as a function of log public capital, log private capital, log employment, and unemployment rate:\n\n$$\\ln(\\text{gsp})_{it} = \\beta_1 \\ln(\\text{pcap})_{it} + \\beta_2 \\ln(\\text{pc})_{it} + \\beta_3 \\ln(\\text{emp})_{it} + \\beta_4 \\text{unemp}_{it} + \\alpha_i + \\varepsilon_{it}$$\n\nThe question is whether $\\alpha_i$ (the state-specific intercept) is correlated with the regressors.\n\n### Visualizing the panel\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Log GSP over time by state\nggplot(Produc, aes(x = year, y = log(gsp), group = state)) +\n  geom_line(alpha = 0.3) +\n  labs(title = \"Log gross state product over time\",\n       x = \"Year\", y = \"log(GSP)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](ch12-panel_files/figure-html/produc-plot-1.png){width=672}\n:::\n:::\n\n\n## Pooled OLS\n\nPooled OLS ignores the panel structure entirely---it treats all $NT$ observations as independent:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npooled <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,\n              data = Produc, index = c(\"state\", \"year\"),\n              model = \"pooling\")\nsummary(pooled)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPooling Model\n\nCall:\nplm(formula = log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, \n    data = Produc, model = \"pooling\", index = c(\"state\", \"year\"))\n\nBalanced Panel: n = 48, T = 17, N = 816\n\nResiduals:\n       Min.     1st Qu.      Median     3rd Qu.        Max. \n-0.23176215 -0.06103699 -0.00010248  0.05085197  0.35111348 \n\nCoefficients:\n              Estimate Std. Error t-value  Pr(>|t|)    \n(Intercept)  1.6433023  0.0575873 28.5359 < 2.2e-16 ***\nlog(pcap)    0.1550070  0.0171538  9.0363 < 2.2e-16 ***\nlog(pc)      0.3091902  0.0102720 30.1003 < 2.2e-16 ***\nlog(emp)     0.5939349  0.0137475 43.2032 < 2.2e-16 ***\nunemp       -0.0067330  0.0014164 -4.7537 2.363e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    849.81\nResidual Sum of Squares: 6.2942\nR-Squared:      0.99259\nAdj. R-Squared: 0.99256\nF-statistic: 27171.7 on 4 and 811 DF, p-value: < 2.22e-16\n```\n\n\n:::\n:::\n\n\nPooled OLS is consistent only if the unobserved state effects $\\alpha_i$ are uncorrelated with all regressors. If wealthier states invest more in public capital (likely), pooled OLS is biased.\n\n## The between estimator\n\nThe between estimator uses only cross-sectional variation---it regresses group means $\\bar{y}_i$ on $\\bar{x}_i$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbetween_fit <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,\n                   data = Produc, index = c(\"state\", \"year\"),\n                   model = \"between\")\nsummary(between_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOneway (individual) effect Between Model\n\nCall:\nplm(formula = log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, \n    data = Produc, model = \"between\", index = c(\"state\", \"year\"))\n\nBalanced Panel: n = 48, T = 17, N = 816\nObservations used in estimation: 48\n\nResiduals:\n      Min.    1st Qu.     Median    3rd Qu.       Max. \n-0.1573844 -0.0581566 -0.0055724  0.0461581  0.2176471 \n\nCoefficients:\n              Estimate Std. Error t-value  Pr(>|t|)    \n(Intercept)  1.5894444  0.2329796  6.8222 2.329e-08 ***\nlog(pcap)    0.1793651  0.0719719  2.4922   0.01663 *  \nlog(pc)      0.3019542  0.0418215  7.2201 6.187e-09 ***\nlog(emp)     0.5761274  0.0563746 10.2196 4.446e-13 ***\nunemp       -0.0038903  0.0099084 -0.3926   0.69653    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    48.875\nResidual Sum of Squares: 0.2977\nR-Squared:      0.99391\nAdj. R-Squared: 0.99334\nF-statistic: 1754.11 on 4 and 43 DF, p-value: < 2.22e-16\n```\n\n\n:::\n:::\n\n\nThe between estimator discards all within-state time variation. It is consistent only under the random effects assumption ($\\alpha_i \\perp X_{it}$). When that assumption fails, the between estimator is biased.\n\n## The within (fixed effects) estimator {#sec-within}\n\nThe within estimator removes $\\alpha_i$ by demeaning each variable within each state:\n\n$$(\\ln\\text{gsp}_{it} - \\overline{\\ln\\text{gsp}}_i) = \\beta'(x_{it} - \\bar{x}_i) + (\\varepsilon_{it} - \\bar{\\varepsilon}_i)$$ {#eq-within}\n\n::: {#def-within}\n## Within (Fixed Effects) Estimator\nThe within estimator demeans all variables within each unit: $(y_{it} - \\bar{y}_i) = \\beta'(x_{it} - \\bar{x}_i) + (\\varepsilon_{it} - \\bar\\varepsilon_i)$. It is consistent when $\\mathbb{E}[\\varepsilon_{it}|X_{i1}, \\ldots, X_{iT}, \\alpha_i] = 0$, even if $\\alpha_i$ is correlated with $X_{it}$.\n:::\n\n::: {.callout-note}\n## Within Eliminates Time-Invariant Confounders\nThe within estimator removes all time-invariant unit characteristics $\\alpha_i$ — both observed and unobserved. This eliminates omitted variable bias from time-invariant confounders, but it also prevents estimating effects of time-invariant regressors (e.g., region, ethnicity). Use CRE/Mundlak (Chapter 13) to recover these.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwithin_fit <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,\n                  data = Produc, index = c(\"state\", \"year\"),\n                  model = \"within\")\nsummary(within_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOneway (individual) effect Within Model\n\nCall:\nplm(formula = log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, \n    data = Produc, model = \"within\", index = c(\"state\", \"year\"))\n\nBalanced Panel: n = 48, T = 17, N = 816\n\nResiduals:\n     Min.   1st Qu.    Median   3rd Qu.      Max. \n-0.120456 -0.023741 -0.002041  0.018144  0.174718 \n\nCoefficients:\n             Estimate  Std. Error t-value  Pr(>|t|)    \nlog(pcap) -0.02614965  0.02900158 -0.9017    0.3675    \nlog(pc)    0.29200693  0.02511967 11.6246 < 2.2e-16 ***\nlog(emp)   0.76815947  0.03009174 25.5273 < 2.2e-16 ***\nunemp     -0.00529774  0.00098873 -5.3582 1.114e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    18.941\nResidual Sum of Squares: 1.1112\nR-Squared:      0.94134\nAdj. R-Squared: 0.93742\nF-statistic: 3064.81 on 4 and 764 DF, p-value: < 2.22e-16\n```\n\n\n:::\n:::\n\n\n### Fixed effects by hand\n\nBy the [FWL theorem](ch04-sensitivity.qmd#thm-fwl), the within estimator is equivalent to including dummy variables for each state (LSDV), which is equivalent to the Frisch--Waugh--Lovell projection:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# LSDV approach: include state dummies\nlsdv <- lm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp + factor(state),\n           data = Produc)\n\n# Compare slope coefficients\ncat(\"plm within:  \", round(coef(within_fit), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nplm within:   -0.0261 0.292 0.7682 -0.0053 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"LSDV slopes: \", round(coef(lsdv)[2:5], 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLSDV slopes:  -0.0261 0.292 0.7682 -0.0053 \n```\n\n\n:::\n:::\n\n\n### Manual demeaning\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Demean each variable within state\ndemean <- function(x, group) x - ave(x, group)\n\nProduc$lgsp_dm  <- demean(log(Produc$gsp), Produc$state)\nProduc$lpcap_dm <- demean(log(Produc$pcap), Produc$state)\nProduc$lpc_dm   <- demean(log(Produc$pc), Produc$state)\nProduc$lemp_dm  <- demean(log(Produc$emp), Produc$state)\nProduc$unemp_dm <- demean(Produc$unemp, Produc$state)\n\ndm_fit <- lm(lgsp_dm ~ lpcap_dm + lpc_dm + lemp_dm + unemp_dm - 1, data = Produc)\ncat(\"Manual demeaning: \", round(coef(dm_fit), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nManual demeaning:  -0.0261 0.292 0.7682 -0.0053 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"plm within:       \", round(coef(within_fit), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nplm within:        -0.0261 0.292 0.7682 -0.0053 \n```\n\n\n:::\n:::\n\n\n### Comparing estimators\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef_table <- data.frame(\n  Variable = names(coef(within_fit)),\n  Pooled = round(coef(pooled)[-1], 4),\n  Between = round(coef(between_fit)[-1], 4),\n  Within = round(coef(within_fit), 4)\n)\nrownames(coef_table) <- NULL\ncoef_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Variable  Pooled Between  Within\n1 log(pcap)  0.1550  0.1794 -0.0261\n2   log(pc)  0.3092  0.3020  0.2920\n3  log(emp)  0.5939  0.5761  0.7682\n4     unemp -0.0067 -0.0039 -0.0053\n```\n\n\n:::\n:::\n\n\nThe pooled and between estimators give a large positive coefficient on public capital (`pcap`). The within estimator---which controls for unobserved state characteristics---gives a much smaller (or negative) coefficient. This is the classic omitted variable bias story: states with high unobserved productivity invest in more public capital *and* have higher GSP.\n\n### Variance decomposition\n\nThe total variation in a panel decomposes into between-group and within-group components. The pooled estimator is a matrix-weighted average of the between and within estimators:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Between variation\nx_bar <- aggregate(log(pcap) ~ state, data = Produc, mean)$`log(pcap)`\nbetween_var <- var(x_bar)\n\n# Within variation\nwithin_var <- var(demean(log(Produc$pcap), Produc$state))\n\n# Total\ntotal_var <- var(log(Produc$pcap))\n\ncat(\"Between variance:\", round(between_var, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBetween variance: 0.8945 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Within variance: \", round(within_var, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWithin variance:  0.0116 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Total variance:  \", round(total_var, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal variance:   0.8885 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Between share:   \", round(between_var / total_var * 100, 1), \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBetween share:    100.7 %\n```\n\n\n:::\n:::\n\n\nWhen the between share is large (as here), pooled OLS is heavily influenced by cross-sectional differences between states, which may be confounded by omitted variables.\n\n## Clustering and robust standard errors\n\nStandard errors from pooled OLS or even fixed effects may be wrong if errors are correlated within states (serial correlation) or across states (spatial correlation).\n\n### Cluster-robust standard errors\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Default plm standard errors (assume iid errors)\ncat(\"Default within SE:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDefault within SE:\n```\n\n\n:::\n\n```{.r .cell-code}\nround(coef(summary(within_fit))[, \"Std. Error\"], 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlog(pcap)   log(pc)  log(emp)     unemp \n   0.0290    0.0251    0.0301    0.0010 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cluster-robust SE (Arellano, 1987)\ncat(\"\\nCluster-robust SE (Arellano):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCluster-robust SE (Arellano):\n```\n\n\n:::\n\n```{.r .cell-code}\nround(sqrt(diag(vcovHC(within_fit, method = \"arellano\", type = \"HC1\"))), 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlog(pcap)   log(pc)  log(emp)     unemp \n   0.0605    0.0619    0.0819    0.0025 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Newey-West SE for serial correlation\ncat(\"\\nNewey-West SE (1 lag):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nNewey-West SE (1 lag):\n```\n\n\n:::\n\n```{.r .cell-code}\nround(sqrt(diag(vcovNW(within_fit, maxlag = 1))), 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlog(pcap)   log(pc)  log(emp)     unemp \n   0.0391    0.0376    0.0503    0.0013 \n```\n\n\n:::\n:::\n\n\n::: {.callout-warning}\n## Always Cluster Standard Errors in Panel Data\nStandard OLS errors assume independence across observations. In panel data, errors are typically correlated within units (serial correlation). Failing to cluster inflates test statistics by the Moulton factor $\\sqrt{1 + (T-1)\\rho}$, which can be substantial.\n:::\n\nUsing `fixest::feols()` provides the same estimates with more flexible standard error options:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfe_fixest <- feols(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp | state,\n                   data = Produc, panel.id = ~state + year)\n\n# Various SE types\nsummary(fe_fixest, vcov = \"iid\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOLS estimation, Dep. Var.: log(gsp)\nObservations: 816\nFixed-effects: state: 48\nStandard-errors: IID \n           Estimate Std. Error   t value   Pr(>|t|)    \nlog(pcap) -0.026150   0.029002 -0.901663 3.6752e-01    \nlog(pc)    0.292007   0.025120 11.624631  < 2.2e-16 ***\nlog(emp)   0.768159   0.030092 25.527254  < 2.2e-16 ***\nunemp     -0.005298   0.000989 -5.358151 1.1139e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.036902     Adj. R2: 0.998605\n                 Within R2: 0.941336\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fe_fixest, vcov = ~state)  # cluster by state\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOLS estimation, Dep. Var.: log(gsp)\nObservations: 816\nFixed-effects: state: 48\nStandard-errors: Clustered (state) \n           Estimate Std. Error   t value   Pr(>|t|)    \nlog(pcap) -0.026150   0.061115 -0.427878 6.7069e-01    \nlog(pc)    0.292007   0.062550  4.668409 2.5563e-05 ***\nlog(emp)   0.768159   0.082733  9.284833 3.3204e-12 ***\nunemp     -0.005298   0.002528 -2.095241 4.1564e-02 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.036902     Adj. R2: 0.998605\n                 Within R2: 0.941336\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Driscoll-Kraay SE (cross-sectional + serial dependence)\nsummary(fe_fixest, vcov = \"DK\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOLS estimation, Dep. Var.: log(gsp)\nObservations: 816\nFixed-effects: state: 48\nStandard-errors: Driscoll-Kraay (L=2) \n           Estimate Std. Error   t value   Pr(>|t|)    \nlog(pcap) -0.026150   0.061260 -0.426864 6.7517e-01    \nlog(pc)    0.292007   0.062641  4.661581 2.6059e-04 ***\nlog(emp)   0.768159   0.088195  8.709819 1.8097e-07 ***\nunemp     -0.005298   0.001588 -3.337117 4.1793e-03 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.036902     Adj. R2: 0.998605\n                 Within R2: 0.941336\n```\n\n\n:::\n:::\n\n\n### The Moulton factor\n\nWhy do clustered SEs matter? When errors are correlated within clusters, standard SEs are too small by a factor that grows with cluster size and intra-cluster correlation $\\rho$:\n\n$$\\text{Moulton factor} \\approx \\sqrt{1 + (n_g - 1)\\rho}$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Estimate intra-state error correlation from within-model residuals\ne_within <- residuals(within_fit)\npdat <- pdata.frame(Produc, index = c(\"state\", \"year\"))\nstate_ids <- as.numeric(pdat$state)\n\n# Compute average within-state residual correlation\nstates <- unique(state_ids)\ncors <- numeric(length(states))\nfor (j in seq_along(states)) {\n  e_j <- e_within[state_ids == states[j]]\n  if (length(e_j) > 1) {\n    pair_cors <- cor(e_j[-length(e_j)], e_j[-1])\n    cors[j] <- pair_cors\n  }\n}\nrho <- mean(cors, na.rm = TRUE)\nT_per_state <- nrow(Produc) / length(unique(Produc$state))\nmoulton <- sqrt(1 + (T_per_state - 1) * rho)\ncat(\"Intra-state correlation (rho):\", round(rho, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIntra-state correlation (rho): 0.697 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Average T per state:\", T_per_state, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAverage T per state: 17 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Moulton factor:\", round(moulton, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMoulton factor: 3.49 \n```\n\n\n:::\n:::\n\n\nStandard errors should be inflated by roughly this factor when clustering is ignored.\n\n## Difference-in-differences {#sec-did}\n\nDifference-in-differences (DiD) is a panel method for estimating causal effects when treatment is assigned to some units at some time. The canonical $2 \\times 2$ DiD model is:\n\n$$Y_{it} = \\alpha + \\beta \\cdot \\text{Group}_i + \\gamma \\cdot \\text{Post}_t + \\delta \\cdot (\\text{Group}_i \\times \\text{Post}_t) + \\varepsilon_{it}$$ {#eq-did}\n\n::: {#thm-did}\n## Difference-in-Differences\nThe DiD estimator $\\hat\\delta = (\\bar{Y}_{1,\\text{post}} - \\bar{Y}_{1,\\text{pre}}) - (\\bar{Y}_{0,\\text{post}} - \\bar{Y}_{0,\\text{pre}})$ identifies the ATT under the **parallel trends** assumption: absent treatment, treated and control groups would have followed the same trajectory.\n:::\n\nwhere $\\delta$ is the treatment effect, identified under the **parallel trends** assumption.\n\n### Simulated DiD example\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nN <- 100  # units\nT_periods <- 10\ntreat_time <- 6  # treatment starts at t = 6\ntreated_units <- 1:(N/2)\n\ndid_data <- expand.grid(unit = 1:N, time = 1:T_periods)\ndid_data$treated <- as.integer(did_data$unit %in% treated_units)\ndid_data$post <- as.integer(did_data$time >= treat_time)\n\n# Generate outcomes with parallel pre-trends\nalpha_i <- rep(rnorm(N, sd = 2), each = T_periods)  # unit effects\ngamma_t <- rep(0.3 * (1:T_periods), times = N)       # common trend\ndelta_true <- 1.5\n\ndid_data$y <- 5 + alpha_i + gamma_t +\n  delta_true * did_data$treated * did_data$post +\n  rnorm(N * T_periods, sd = 1)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Group means over time\ngroup_means <- aggregate(y ~ time + treated, data = did_data, mean)\ngroup_means$group <- factor(group_means$treated, labels = c(\"Control\", \"Treated\"))\n\nggplot(group_means, aes(x = time, y = y, color = group)) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 2) +\n  geom_vline(xintercept = treat_time - 0.5, linetype = \"dashed\") +\n  annotate(\"text\", x = treat_time - 0.3, y = max(group_means$y),\n           label = \"Treatment\", hjust = 1, size = 3) +\n  labs(title = \"Difference-in-differences\",\n       x = \"Time\", y = \"Outcome\", color = \"Group\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Difference-in-differences: group means over time with treatment onset](ch12-panel_files/figure-html/did-plot-1.png){width=672}\n:::\n:::\n\n\n### DiD estimation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Method 1: OLS with interaction\ndid_ols <- lm(y ~ treated * post, data = did_data)\ncat(\"DiD coefficient (OLS interaction):\", round(coef(did_ols)[\"treated:post\"], 3),\n    \" (true:\", delta_true, \")\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDiD coefficient (OLS interaction): 0.483  (true: 1.5 )\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Method 2: Two-way fixed effects (unit + time FE)\ndid_twfe <- feols(y ~ treated:post | unit + time, data = did_data)\ncat(\"DiD coefficient (TWFE):\", round(coef(did_twfe), 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDiD coefficient (TWFE): 0.483 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# With cluster-robust SEs (cluster on unit)\nsummary(did_twfe, vcov = ~unit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOLS estimation, Dep. Var.: y\nObservations: 1,000\nFixed-effects: unit: 100,  time: 10\nStandard-errors: Clustered (unit) \n             Estimate Std. Error t value Pr(>|t|)    \ntreated:post 0.483065   0.245027 1.97148  0.05146 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 2.11024     Adj. R2: 0.237228\n                Within R2: 0.003264\n```\n\n\n:::\n:::\n\n\n### Visualizing the DiD with panelView\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Treatment pattern\ndid_data$D <- did_data$treated * did_data$post\npanelview(y ~ D, data = did_data, index = c(\"unit\", \"time\"),\n          type = \"treat\",\n          main = \"Treatment pattern in DiD design\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fortify(data, ...): Arguments in `...` must be used.\n✖ Problematic argument:\n• position = \"identity\"\nℹ Did you misspell an argument name?\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: In `margin()`, the argument `t` should have length 1, not length 4.\nℹ Argument get(s) truncated to length 1.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ch12-panel_files/figure-html/did-panelview-1.png){width=672}\n:::\n:::\n\n\n## Random effects\n\nThe random effects (RE) estimator assumes $\\alpha_i \\perp X_{it}$ and estimates a GLS model with the composite error $\\nu_{it} = \\alpha_i + \\varepsilon_{it}$. The RE estimator is a weighted average of the between and within estimators:\n\n$$\\hat{\\beta}_{RE} = \\lambda \\hat{\\beta}_{W} + (1 - \\lambda) \\hat{\\beta}_{B}$$\n\nwhere $\\lambda$ depends on the ratio of within to between variance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nre_fit <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,\n              data = Produc, index = c(\"state\", \"year\"),\n              model = \"random\")\nsummary(re_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOneway (individual) effect Random Effect Model \n   (Swamy-Arora's transformation)\n\nCall:\nplm(formula = log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, \n    data = Produc, model = \"random\", index = c(\"state\", \"year\"))\n\nBalanced Panel: n = 48, T = 17, N = 816\n\nEffects:\n                   var  std.dev share\nidiosyncratic 0.001454 0.038137 0.175\nindividual    0.006838 0.082691 0.825\ntheta: 0.8888\n\nResiduals:\n      Min.    1st Qu.     Median    3rd Qu.       Max. \n-0.1067230 -0.0245520 -0.0023694  0.0217333  0.1996307 \n\nCoefficients:\n               Estimate  Std. Error z-value  Pr(>|z|)    \n(Intercept)  2.13541100  0.13346149 16.0002 < 2.2e-16 ***\nlog(pcap)    0.00443859  0.02341732  0.1895    0.8497    \nlog(pc)      0.31054843  0.01980475 15.6805 < 2.2e-16 ***\nlog(emp)     0.72967053  0.02492022 29.2803 < 2.2e-16 ***\nunemp       -0.00617247  0.00090728 -6.8033 1.023e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    29.209\nResidual Sum of Squares: 1.1879\nR-Squared:      0.95933\nAdj. R-Squared: 0.95913\nChisq: 19131.1 on 4 DF, p-value: < 2.22e-16\n```\n\n\n:::\n:::\n\n\n### Hausman test: FE vs RE\n\nThe Hausman test compares FE and RE. Under $H_0$ (RE is consistent), both estimators are consistent but RE is efficient. Under $H_1$, only FE is consistent.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nphtest(within_fit, re_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tHausman Test\n\ndata:  log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp\nchisq = 9.5254, df = 4, p-value = 0.04923\nalternative hypothesis: one model is inconsistent\n```\n\n\n:::\n:::\n\n\nA small p-value means we reject the RE assumption---the fixed effects are correlated with the regressors, so FE is preferred.\n\n### Mundlak's correlated random effects\n\nMundlak (1978) showed that we can relax the RE assumption by including the group means $\\bar{x}_i$ as additional regressors. This \"correlated random effects\" (CRE) estimator gives the same slope coefficients as FE while also estimating effects of time-invariant variables:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute state means of the regressors\nProduc$lpcap_mean <- ave(log(Produc$pcap), Produc$state)\nProduc$lpc_mean   <- ave(log(Produc$pc), Produc$state)\nProduc$lemp_mean  <- ave(log(Produc$emp), Produc$state)\nProduc$unemp_mean <- ave(Produc$unemp, Produc$state)\n\n# CRE = RE + group means\ncre_fit <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp +\n                 lpcap_mean + lpc_mean + lemp_mean + unemp_mean,\n               data = Produc, index = c(\"state\", \"year\"),\n               model = \"random\")\n\n# Compare CRE slopes to FE slopes\ncat(\"CRE slopes: \", round(coef(cre_fit)[2:5], 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCRE slopes:  -0.0261 0.292 0.7682 -0.0053 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"FE slopes:  \", round(coef(within_fit), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFE slopes:   -0.0261 0.292 0.7682 -0.0053 \n```\n\n\n:::\n:::\n\n\nThe slope coefficients on the time-varying regressors match the FE estimates, confirming the Mundlak equivalence. The coefficients on the group means capture the between-group relationships that FE removes.\n\n## Dynamic panels and Arellano--Bond GMM\n\nWhen the model includes a lagged dependent variable, fixed effects estimation is inconsistent (Nickell bias, $O(1/T)$). Arellano and Bond (1991) proposed first-differencing the equation and using lagged levels as instruments:\n\n$$\\Delta y_{it} = \\rho \\Delta y_{it-1} + \\Delta x_{it}'\\beta + \\Delta \\varepsilon_{it}$$\n\nSince $\\text{Cov}(y_{is}, \\Delta\\varepsilon_{it}) = 0$ for $s \\leq t-2$, lagged levels are valid instruments. This creates a growing set of moment conditions---naturally suited to GMM.\n\n### The EmplUK dataset\n\nWe use the `EmplUK` dataset: 140 UK firms observed over 1976--1984, with employment, wages, capital, and output.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"EmplUK\", package = \"plm\")\ncat(\"Firms:\", length(unique(EmplUK$firm)),\n    \" Years:\", min(EmplUK$year), \"-\", max(EmplUK$year),\n    \" Obs:\", nrow(EmplUK), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFirms: 140  Years: 1976 - 1984  Obs: 1031 \n```\n\n\n:::\n\n```{.r .cell-code}\nhead(EmplUK)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  firm year sector   emp    wage capital   output\n1    1 1977      7 5.041 13.1516  0.5894  95.7072\n2    1 1978      7 5.600 12.3018  0.6318  97.3569\n3    1 1979      7 5.015 12.8395  0.6771  99.6083\n4    1 1980      7 4.715 13.8039  0.6171 100.5501\n5    1 1981      7 4.093 14.2897  0.5076  99.5581\n6    1 1982      7 3.166 14.8681  0.4229  98.6151\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize the panel structure\npanelview(emp ~ wage, data = EmplUK,\n          index = c(\"firm\", \"year\"),\n          type = \"miss\", axis.lab = \"off\",\n          main = \"EmplUK panel balance\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in fortify(data, ...): Arguments in `...` must be used.\n✖ Problematic argument:\n• position = \"identity\"\nℹ Did you misspell an argument name?\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: In `margin()`, the argument `t` should have length 1, not length 4.\nℹ Argument get(s) truncated to length 1.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ch12-panel_files/figure-html/empluk-panelview-1.png){width=672}\n:::\n:::\n\n\n### Nickell bias: why FE fails with lagged DV\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nN_nick <- 100; T_nick <- 8\nrho_true <- 0.5\n\n# Simulate dynamic panel\nnick_data <- data.frame()\nfor (i in 1:N_nick) {\n  alpha_i <- rnorm(1, sd = 1)\n  y <- numeric(T_nick)\n  y[1] <- alpha_i / (1 - rho_true) + rnorm(1)\n  for (t in 2:T_nick) {\n    y[t] <- rho_true * y[t-1] + alpha_i + rnorm(1)\n  }\n  nick_data <- rbind(nick_data,\n    data.frame(id = i, time = 1:T_nick, y = y))\n}\n\n# FE estimate of rho (biased downward)\nnick_data$y_lag <- ave(nick_data$y, nick_data$id,\n                       FUN = function(x) c(NA, x[-length(x)]))\nfe_nick <- plm(y ~ y_lag, data = nick_data, index = c(\"id\", \"time\"),\n               model = \"within\", na.action = na.omit)\ncat(\"True rho:\", rho_true, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTrue rho: 0.5 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"FE estimate:\", round(coef(fe_nick), 4), \" (Nickell bias)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFE estimate: 0.2179  (Nickell bias)\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Expected bias ~ -1/T =\", round(-1/T_nick, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nExpected bias ~ -1/T = -0.125 \n```\n\n\n:::\n:::\n\n\nThe FE estimator is biased downward by approximately $-1/T$ when $T$ is small.\n\n::: {#def-nickell-bias}\n## Nickell Bias\nIn a dynamic panel $y_{it} = \\rho y_{it-1} + \\alpha_i + \\varepsilon_{it}$, fixed effects estimation is inconsistent with bias $\\approx -(\\rho + 1)/(T - 1)$. This arises because demeaning creates mechanical correlation between $\\tilde{y}_{it-1}$ and $\\tilde\\varepsilon_{it}$. The bias is severe when $T$ is small.\n:::\n\n### Arellano--Bond difference GMM\n\nThe `pgmm()` function in `plm` implements Arellano--Bond (difference GMM) and Blundell--Bond (system GMM).\n\nThe formula syntax uses `|` to separate regressors from GMM instruments:\n\n```\ny ~ regressors | GMM_instruments | standard_instruments\n```\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Arellano-Bond: Table 4, Column (b) from Arellano & Bond (1991)\nab_fit <- pgmm(\n  log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), 0:1)\n            + log(capital) + lag(log(output), 0:1)\n            | lag(log(emp), 2:99),\n  data = EmplUK,\n  effect = \"twoways\",\n  model = \"twosteps\",\n  transformation = \"d\"  # difference GMM\n)\n\nsummary(ab_fit, robust = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTwoways effects Two-steps model Difference GMM \n\nCall:\npgmm(formula = log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), \n    0:1) + log(capital) + lag(log(output), 0:1) | lag(log(emp), \n    2:99), data = EmplUK, effect = \"twoways\", model = \"twosteps\", \n    transformation = \"d\")\n\nUnbalanced Panel: n = 140, T = 7-9, N = 1031\n\nNumber of Observations Used: 611\nResiduals:\n      Min.    1st Qu.     Median       Mean    3rd Qu.       Max. \n-0.6190677 -0.0255683  0.0000000 -0.0001339  0.0332013  0.6410272 \n\nCoefficients:\n                        Estimate Std. Error z-value  Pr(>|z|)    \nlag(log(emp), 1:2)1     0.474151   0.185398  2.5575 0.0105437 *  \nlag(log(emp), 1:2)2    -0.052967   0.051749 -1.0235 0.3060506    \nlag(log(wage), 0:1)0   -0.513205   0.145565 -3.5256 0.0004225 ***\nlag(log(wage), 0:1)1    0.224640   0.141950  1.5825 0.1135279    \nlog(capital)            0.292723   0.062627  4.6741 2.953e-06 ***\nlag(log(output), 0:1)0  0.609775   0.156263  3.9022 9.530e-05 ***\nlag(log(output), 0:1)1 -0.446373   0.217302 -2.0542 0.0399605 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSargan test: chisq(25) = 30.11247 (p-value = 0.22011)\nAutocorrelation test (1): normal = -1.53845 (p-value = 0.12394)\nAutocorrelation test (2): normal = -0.2796829 (p-value = 0.77972)\nWald test for coefficients: chisq(7) = 142.0353 (p-value = < 2.22e-16)\nWald test for time dummies: chisq(6) = 16.97046 (p-value = 0.0093924)\n```\n\n\n:::\n:::\n\n\n### Diagnostic tests\n\nTwo diagnostics are essential for dynamic panel GMM:\n\n1. **Sargan/Hansen J-test**: Are the overidentifying restrictions satisfied?\n2. **AR(2) test**: Is there second-order serial correlation in the differenced residuals? (AR(1) is expected due to differencing; AR(2) would invalidate lag-2 instruments.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sargan test of overidentifying restrictions\nsargan(ab_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tSargan test\n\ndata:  log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), 0:1) + log(capital) +  ...\nchisq = 30.112, df = 25, p-value = 0.2201\nalternative hypothesis: overidentifying restrictions not valid\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Serial correlation tests\nmtest(ab_fit, order = 1)  # AR(1): expected to reject\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tArellano-Bond autocorrelation test of degree 1\n\ndata:  log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), 0:1) + log(capital) +  ...\nnormal = -2.4278, p-value = 0.01519\nalternative hypothesis: autocorrelation present\n```\n\n\n:::\n\n```{.r .cell-code}\nmtest(ab_fit, order = 2)  # AR(2): should not reject\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tArellano-Bond autocorrelation test of degree 2\n\ndata:  log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), 0:1) + log(capital) +  ...\nnormal = -0.33254, p-value = 0.7395\nalternative hypothesis: autocorrelation present\n```\n\n\n:::\n:::\n\n\nAR(1) in the differenced residuals is expected and mechanical. The key test is AR(2): failing to reject means our instruments (lags 2+) are valid.\n\n### Blundell--Bond system GMM\n\nWhen the dependent variable is highly persistent ($\\rho$ close to 1), lagged levels become weak instruments for first differences. Blundell and Bond (1998) augment the moment conditions with level equations, using lagged *differences* as instruments:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# System GMM: use transformation = \"ld\" (level + difference)\nbb_fit <- pgmm(\n  log(emp) ~ lag(log(emp), 1) + lag(log(wage), 0:1)\n            + lag(log(capital), 0:1)\n            | lag(log(emp), 2:99) + lag(log(wage), 2:99)\n              + lag(log(capital), 2:99),\n  data = EmplUK,\n  effect = \"twoways\",\n  model = \"twosteps\",\n  transformation = \"ld\"  # system GMM\n)\n\nsummary(bb_fit, robust = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTwoways effects Two-steps model System GMM \n\nCall:\npgmm(formula = log(emp) ~ lag(log(emp), 1) + lag(log(wage), 0:1) + \n    lag(log(capital), 0:1) | lag(log(emp), 2:99) + lag(log(wage), \n    2:99) + lag(log(capital), 2:99), data = EmplUK, effect = \"twoways\", \n    model = \"twosteps\", transformation = \"ld\")\n\nUnbalanced Panel: n = 140, T = 7-9, N = 1031\n\nNumber of Observations Used: 1642\nResiduals:\n      Min.    1st Qu.     Median       Mean    3rd Qu.       Max. \n-0.7528842 -0.0361094  0.0000000  0.0006606  0.0469500  0.6008115 \n\nCoefficients:\n                         Estimate Std. Error z-value  Pr(>|z|)    \nlag(log(emp), 1)         0.932214   0.026859 34.7072 < 2.2e-16 ***\nlag(log(wage), 0:1)0    -0.634477   0.118758 -5.3426 9.163e-08 ***\nlag(log(wage), 0:1)1     0.494669   0.131783  3.7537 0.0001743 ***\nlag(log(capital), 0:1)0  0.485261   0.060427  8.0305 9.705e-16 ***\nlag(log(capital), 0:1)1 -0.423223   0.064445 -6.5672 5.127e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSargan test: chisq(100) = 110.7009 (p-value = 0.21828)\nAutocorrelation test (1): normal = -6.456154 (p-value = 1.074e-10)\nAutocorrelation test (2): normal = -0.259282 (p-value = 0.79542)\nWald test for coefficients: chisq(5) = 11221.9 (p-value = < 2.22e-16)\nWald test for time dummies: chisq(7) = 13.73376 (p-value = 0.056124)\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsargan(bb_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tSargan test\n\ndata:  log(emp) ~ lag(log(emp), 1) + lag(log(wage), 0:1) + lag(log(capital),  ...\nchisq = 110.7, df = 100, p-value = 0.2183\nalternative hypothesis: overidentifying restrictions not valid\n```\n\n\n:::\n\n```{.r .cell-code}\nmtest(bb_fit, order = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tArellano-Bond autocorrelation test of degree 2\n\ndata:  log(emp) ~ lag(log(emp), 1) + lag(log(wage), 0:1) + lag(log(capital),  ...\nnormal = -0.26286, p-value = 0.7927\nalternative hypothesis: autocorrelation present\n```\n\n\n:::\n:::\n\n\n### Instrument proliferation\n\nA practical concern with `pgmm()` is that the number of GMM instruments grows quadratically with $T$. With $T = 9$ periods, using `lag(y, 2:99)` generates up to $(T-1)(T-2)/2 = 28$ instruments from a single variable. Too many instruments can overfit the endogenous variable.\n\nThe `collapse = TRUE` option reduces the instrument count:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Collapsed instrument matrix\nab_collapse <- pgmm(\n  log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), 0:1)\n            + log(capital) + lag(log(output), 0:1)\n            | lag(log(emp), 2:99),\n  data = EmplUK,\n  effect = \"twoways\",\n  model = \"twosteps\",\n  transformation = \"d\",\n  collapse = TRUE\n)\n\nsummary(ab_collapse, robust = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTwoways effects Two-steps model Difference GMM \n\nCall:\npgmm(formula = log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), \n    0:1) + log(capital) + lag(log(output), 0:1) | lag(log(emp), \n    2:99), data = EmplUK, effect = \"twoways\", model = \"twosteps\", \n    collapse = TRUE, transformation = \"d\")\n\nUnbalanced Panel: n = 140, T = 7-9, N = 1031\n\nNumber of Observations Used: 611\nResiduals:\n      Min.    1st Qu.     Median       Mean    3rd Qu.       Max. \n-0.8455637 -0.0326605  0.0000000 -0.0003799  0.0312841  0.7010278 \n\nCoefficients:\n                        Estimate Std. Error z-value Pr(>|z|)   \nlag(log(emp), 1:2)1     0.853895   0.562348  1.5184 0.128902   \nlag(log(emp), 1:2)2    -0.169886   0.123293 -1.3779 0.168232   \nlag(log(wage), 0:1)0   -0.533119   0.245948 -2.1676 0.030189 * \nlag(log(wage), 0:1)1    0.352516   0.432846  0.8144 0.415408   \nlog(capital)            0.271707   0.089921  3.0216 0.002514 **\nlag(log(output), 0:1)0  0.612855   0.242289  2.5294 0.011424 * \nlag(log(output), 0:1)1 -0.682550   0.612311 -1.1147 0.264974   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSargan test: chisq(5) = 11.62681 (p-value = 0.040275)\nAutocorrelation test (1): normal = -1.290551 (p-value = 0.19686)\nAutocorrelation test (2): normal = 0.4482577 (p-value = 0.65397)\nWald test for coefficients: chisq(7) = 134.788 (p-value = < 2.22e-16)\nWald test for time dummies: chisq(6) = 11.91947 (p-value = 0.06379)\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare coefficient on lag(log(emp), 1) across specifications\ncat(\"Full instruments:     \", round(coef(ab_fit)[\"lag(log(emp), 1:2)1\"], 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFull instruments:      0.4742 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Collapsed instruments:\", round(coef(ab_collapse)[\"lag(log(emp), 1:2)1\"], 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCollapsed instruments: 0.8539 \n```\n\n\n:::\n:::\n\n\n## Panel estimators as moment conditions\n\nEvery panel estimator we've covered is a GMM estimator with specific moment conditions:\n\n| Estimator | Moment condition | Instruments |\n|-----------|-----------------|-------------|\n| Pooled OLS | $\\mathbb{E}[X_{it} \\varepsilon_{it}] = 0$ | $X_{it}$ |\n| Within (FE) | $\\mathbb{E}[\\tilde{X}_{it} \\tilde{\\varepsilon}_{it}] = 0$ | Demeaned $\\tilde{X}_{it}$ |\n| Between | $\\mathbb{E}[\\bar{X}_i \\bar{\\varepsilon}_i] = 0$ | Group means $\\bar{X}_i$ |\n| Random effects | $\\mathbb{E}[X_{it} \\nu_{it}] = 0$, $\\mathbb{E}[\\bar{X}_i \\nu_{it}] = 0$ | Both $X_{it}$ and $\\bar{X}_i$ |\n| Arellano--Bond | $\\mathbb{E}[y_{is} \\Delta\\varepsilon_{it}] = 0,\\ s \\leq t-2$ | Lagged levels |\n| Blundell--Bond | Above + $\\mathbb{E}[\\Delta y_{is} \\varepsilon_{it}] = 0,\\ s \\leq t-1$ | + Lagged differences |\n\nThe progression from OLS to system GMM mirrors the course arc: each step adds moment conditions and addresses a new identification challenge.\n\n## Choosing a panel estimator\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nPanel Estimator Decision Guide:\n================================\n1. Is alpha_i correlated with X_it?\n   - No  --> Random Effects (more efficient)\n   - Yes --> Fixed Effects\n   - Unsure --> Run Hausman test\n\n2. Do you have a lagged dependent variable?\n   - No  --> Standard FE is fine\n   - Yes --> FE is biased (Nickell bias)\n           --> Use Arellano-Bond or System GMM\n\n3. Is the DV highly persistent (rho near 1)?\n   - No  --> Arellano-Bond (difference GMM)\n   - Yes --> Blundell-Bond (system GMM)\n\n4. Diagnostics:\n   - Always report cluster-robust SEs\n   - For GMM: check Sargan test + AR(2) test\n   - Watch for instrument proliferation\n```\n\n\n:::\n:::\n\n\n## Summary\n\n- **panelView** visualizes treatment adoption, missingness, and outcome dynamics before estimation.\n- **Pooled OLS** ignores unit effects; **between** uses only cross-sectional variation; **within (FE)** uses only time variation within units.\n- The within estimator removes time-invariant confounders but cannot estimate effects of time-invariant regressors.\n- **Cluster-robust SEs** (Arellano, Newey--West, Driscoll--Kraay) account for within-cluster error dependence. The Moulton factor quantifies the standard error inflation from ignoring clustering.\n- **Mundlak's CRE** gives FE slopes while retaining the ability to estimate effects of time-invariant variables.\n- **Hausman test** compares FE and RE; rejection means $\\alpha_i$ is correlated with $X_{it}$.\n- **Arellano--Bond** and **Blundell--Bond** use GMM for dynamic panels with lagged dependent variables, overcoming Nickell bias.\n- **Diagnostic tests**: Sargan/Hansen J-test for overidentifying restrictions; AR(2) test for instrument validity.\n- All panel estimators are special cases of GMM with different moment conditions.\n",
    "supporting": [
      "ch12-panel_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}