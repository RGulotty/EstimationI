<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>4. Sensitivity and Leverage – Estimation I: Computational Companion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8b4baf804e461d9b72633f0de59a0cac.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-3bbbbd466991e281563892c5dce73c3d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>
  MathJax = {
    tex: {
      macros: {
        E: "\\mathbb{E}",
        Var: "\\text{Var}",
        Cov: "\\text{Cov}",
        plim: "\\text{plim}",
        inprob: "\\xrightarrow{p}",
        indist: "\\xrightarrow{d}",
        bhat: "\\hat{\\boldsymbol{\\beta}}",
        N: "\\mathcal{N}",
        tr: "\\text{tr}",
        rank: "\\text{rank}",
        SE: "\\text{SE}",
        diag: "\\text{diag}"
      }
    }
  };
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Estimation I: Computational Companion</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-chapters" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Chapters</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-chapters">    
        <li>
    <a class="dropdown-item" href="./ch01-review.html">
 <span class="dropdown-text">1. Probability and Linear Algebra</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch02-cef-blp.html">
 <span class="dropdown-text">2. The CEF and Best Linear Predictor</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch03-ols.html">
 <span class="dropdown-text">3. Multivariate OLS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch04-sensitivity.html">
 <span class="dropdown-text">4. Sensitivity and Leverage</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch05-gls.html">
 <span class="dropdown-text">5. Efficiency and GLS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch06-small-sample.html">
 <span class="dropdown-text">6. Small Sample Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch07-probit.html">
 <span class="dropdown-text">7. Probit and MLE</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch08-asymptotics.html">
 <span class="dropdown-text">8. Asymptotics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch09-testing.html">
 <span class="dropdown-text">9. Hypothesis Testing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch10-iv.html">
 <span class="dropdown-text">10. Instrumental Variables and 2SLS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch11-gmm.html">
 <span class="dropdown-text">11. GMM</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch12-panel.html">
 <span class="dropdown-text">12. Panel Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch13-fixed-effects.html">
 <span class="dropdown-text">13. Fixed Effects and Modern DiD</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/UChicago-pol-methods/EstimationI"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-fwl" id="toc-sec-fwl" class="nav-link active" data-scroll-target="#sec-fwl"><span class="header-section-number">1</span> The Frisch-Waugh-Lovell theorem</a>
  <ul class="collapse">
  <li><a href="#fwl-with-matrices" id="toc-fwl-with-matrices" class="nav-link" data-scroll-target="#fwl-with-matrices"><span class="header-section-number">1.1</span> FWL with matrices</a></li>
  </ul></li>
  <li><a href="#plotting-partial-effects" id="toc-plotting-partial-effects" class="nav-link" data-scroll-target="#plotting-partial-effects"><span class="header-section-number">2</span> Plotting partial effects</a></li>
  <li><a href="#leverage-which-observations-pull-the-line" id="toc-leverage-which-observations-pull-the-line" class="nav-link" data-scroll-target="#leverage-which-observations-pull-the-line"><span class="header-section-number">3</span> Leverage: which observations pull the line?</a></li>
  <li><a href="#leave-one-out-regression" id="toc-leave-one-out-regression" class="nav-link" data-scroll-target="#leave-one-out-regression"><span class="header-section-number">4</span> Leave-one-out regression</a></li>
  <li><a href="#regression-weights-which-observations-matter-most" id="toc-regression-weights-which-observations-matter-most" class="nav-link" data-scroll-target="#regression-weights-which-observations-matter-most"><span class="header-section-number">5</span> Regression weights: which observations matter most?</a></li>
  <li><a href="#partial-r2" id="toc-partial-r2" class="nav-link" data-scroll-target="#partial-r2"><span class="header-section-number">6</span> Partial <span class="math inline">\(R^2\)</span></a></li>
  <li><a href="#sensitivity-analysis-cinelli-hazlett-2020" id="toc-sensitivity-analysis-cinelli-hazlett-2020" class="nav-link" data-scroll-target="#sensitivity-analysis-cinelli-hazlett-2020"><span class="header-section-number">7</span> Sensitivity analysis: Cinelli-Hazlett (2020)</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">8</span> Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">4. Sensitivity and Leverage</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<p class="subtitle lead">Frisch-Waugh-Lovell, partial R², and influential observations</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(carData)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>tr <span class="ot">&lt;-</span> <span class="cf">function</span>(M) <span class="fu">sum</span>(<span class="fu">diag</span>(M))</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Prestige)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>In applied work we rarely care about every regressor equally. We have a treatment or variable of interest (<span class="math inline">\(X_1\)</span>) and controls we include to avoid omitted variable bias (<span class="math inline">\(X_2\)</span>). Partitioning <span class="math inline">\(X = [X_1 \; X_2]\)</span> lets us answer three questions: What is the formula for <span class="math inline">\(\hat\beta_1\)</span> holding <span class="math inline">\(X_2\)</span> constant? What happens if we omit <span class="math inline">\(X_2\)</span>? And how sensitive is <span class="math inline">\(\hat\beta_1\)</span> to confounders we cannot observe?</p>
<p><strong>Questions this chapter answers:</strong></p>
<ol type="1">
<li>How does the Frisch-Waugh-Lovell theorem decompose a multivariate regression into residual-on-residual regressions?</li>
<li>Which observations exert the most influence on OLS estimates, and how does leverage measure this?</li>
<li>How do sensitivity analysis tools (Cinelli-Hazlett) quantify robustness to unobserved confounders?</li>
</ol>
<section id="sec-fwl" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-fwl"><span class="header-section-number">1</span> The Frisch-Waugh-Lovell theorem</h2>
<p>The FWL theorem says: the coefficient <span class="math inline">\(\hat\beta_2\)</span> from the full regression <span class="math inline">\(y = X_1\beta_1 + X_2\beta_2 + e\)</span> is identical to the coefficient from regressing the residualized outcome on the residualized treatment — after partialling out <span class="math inline">\(X_1\)</span> from both.</p>
<p>In matrix terms, let <span class="math inline">\(M_1 = I - X_1(X_1'X_1)^{-1}X_1'\)</span> be the annihilator for <span class="math inline">\(X_1\)</span>. Then:</p>
<p><span id="eq-fwl"><span class="math display">\[\hat\beta_2 = (X_2'M_1 X_2)^{-1} X_2' M_1 y \tag{1}\]</span></span></p>
<p>This is just OLS on the residuals <span class="math inline">\(M_1 y\)</span> and <span class="math inline">\(M_1 X_2\)</span> — the parts of <span class="math inline">\(y\)</span> and <span class="math inline">\(X_2\)</span> that <span class="math inline">\(X_1\)</span> cannot explain.</p>
<div id="thm-fwl" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (Frisch-Waugh-Lovell Theorem)</strong></span> The coefficient <span class="math inline">\(\hat\beta_2\)</span> from the full regression <span class="math inline">\(y = X_1\beta_1 + X_2\beta_2 + e\)</span> equals the coefficient from regressing <span class="math inline">\(M_1 y\)</span> on <span class="math inline">\(M_1 X_2\)</span>, where <span class="math inline">\(M_1 = I - X_1(X_1'X_1)^{-1}X_1'\)</span>. That is: partial out the controls from both sides, then run OLS.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>FWL as a Bridge Between Chapters
</div>
</div>
<div class="callout-body-container callout-body">
<p>The FWL theorem connects OLS geometry (Chapter 3) to applied causal inference. Partial regression plots — residualized <span class="math inline">\(Y\)</span> vs.&nbsp;residualized <span class="math inline">\(X\)</span> — visualize the multivariate coefficient in two dimensions. This same logic underlies fixed effects estimation (Chapter 12): demeaning within groups is FWL with group dummies as controls.</p>
</div>
</div>
<p>Let’s verify with the Prestige data. We’ll show that the coefficient on <code>education</code> from a regression controlling for <code>income</code> and <code>women</code> is the same as the coefficient from the residual-on-residual regression:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Full regression</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>mod_full <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Residualize both y and education against (income, women)</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>e_y <span class="ot">&lt;-</span> <span class="fu">resid</span>(<span class="fu">lm</span>(prestige <span class="sc">~</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>e_educ <span class="ot">&lt;-</span> <span class="fu">resid</span>(<span class="fu">lm</span>(education <span class="sc">~</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige))</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Regress residuals on residuals</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>mod_fwl <span class="ot">&lt;-</span> <span class="fu">lm</span>(e_y <span class="sc">~</span> e_educ)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">full_regression =</span> <span class="fu">coef</span>(mod_full)[<span class="st">"education"</span>],</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">FWL =</span> <span class="fu">coef</span>(mod_fwl)[<span class="st">"e_educ"</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>full_regression.education                FWL.e_educ 
                     4.19                      4.19 </code></pre>
</div>
</div>
<p>Identical. FWL tells us that the coefficient on education reflects only the variation in education <em>not</em> explained by income and women.</p>
<section id="fwl-with-matrices" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="fwl-with-matrices"><span class="header-section-number">1.1</span> FWL with matrices</h3>
<p>Let’s do it with the projection and annihilator matrices directly:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> Prestige<span class="sc">$</span>prestige</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(Prestige)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># X1 = controls (intercept, income, women)</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>X1 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, Prestige<span class="sc">$</span>income, Prestige<span class="sc">$</span>women)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># X2 = variable of interest (education)</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>X2 <span class="ot">&lt;-</span> Prestige<span class="sc">$</span>education</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Build the annihilator for X1</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>P1 <span class="ot">&lt;-</span> X1 <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X1)) <span class="sc">%*%</span> <span class="fu">t</span>(X1)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>M1 <span class="ot">&lt;-</span> <span class="fu">diag</span>(n) <span class="sc">-</span> P1</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co"># FWL formula: beta_2 = (X2'M1 X2)^{-1} X2'M1 y</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>beta_fwl <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">solve</span>(<span class="fu">t</span>(X2) <span class="sc">%*%</span> M1 <span class="sc">%*%</span> X2) <span class="sc">%*%</span> <span class="fu">t</span>(X2) <span class="sc">%*%</span> M1 <span class="sc">%*%</span> y)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">matrix_FWL =</span> beta_fwl, <span class="at">lm =</span> <span class="fu">coef</span>(mod_full)[<span class="st">"education"</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>  matrix_FWL lm.education 
        4.19         4.19 </code></pre>
</div>
</div>
</section>
</section>
<section id="plotting-partial-effects" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="plotting-partial-effects"><span class="header-section-number">2</span> Plotting partial effects</h2>
<p>One practical benefit of FWL: it lets us visualize relationships from a multivariate regression in two dimensions. After partialling out the controls, we can scatter the residualized <span class="math inline">\(y\)</span> against the residualized <span class="math inline">\(x\)</span> and draw the partial regression line.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>df_partial <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">educ_resid =</span> e_educ, <span class="at">prestige_resid =</span> e_y,</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>                         <span class="at">job =</span> <span class="fu">rownames</span>(Prestige))</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_partial, <span class="fu">aes</span>(educ_resid, prestige_resid)) <span class="sc">+</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"steelblue"</span>, <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="at">data =</span> df_partial[<span class="fu">abs</span>(df_partial<span class="sc">$</span>prestige_resid) <span class="sc">&gt;</span> <span class="dv">15</span>, ],</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">label =</span> job), <span class="at">hjust =</span> <span class="sc">-</span><span class="fl">0.1</span>, <span class="at">size =</span> <span class="fl">2.5</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Education residual (net of income, women)"</span>,</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Prestige residual (net of income, women)"</span>,</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Partial regression plot: education → prestige"</span>,</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">paste0</span>(<span class="st">"Slope = "</span>, <span class="fu">round</span>(<span class="fu">coef</span>(mod_fwl)[<span class="dv">2</span>], <span class="dv">2</span>),</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>                         <span class="st">" (same as the multivariate coefficient)"</span>)) <span class="sc">+</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch04-sensitivity_files/figure-html/partial-plot-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Partial regression plot: education → prestige (FWL residuals)</figcaption>
</figure>
</div>
</div>
</div>
<p>The slope of this line <em>is</em> the multivariate regression coefficient. Each point shows an occupation’s education and prestige after removing what income and gender composition predict. Ministers have high prestige residuals — more prestige than their income and gender composition would suggest.</p>
</section>
<section id="leverage-which-observations-pull-the-line" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="leverage-which-observations-pull-the-line"><span class="header-section-number">3</span> Leverage: which observations pull the line?</h2>
<p>The diagonal elements of the hat matrix <span class="math inline">\(P = X(X'X)^{-1}X'\)</span> measure <strong>leverage</strong> — how unusual each observation’s <span class="math inline">\(X\)</span> values are relative to the rest of the data. The <span class="math inline">\(i\)</span>-th leverage value is:</p>
<p><span class="math display">\[h_{ii} = X_i'(X'X)^{-1}X_i\]</span></p>
<div id="def-leverage" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 (Leverage)</strong></span> The leverage of observation <span class="math inline">\(i\)</span> is <span class="math inline">\(h_{ii} = X_i'(X'X)^{-1}X_i\)</span>, the <span class="math inline">\(i\)</span>-th diagonal element of the hat matrix <span class="math inline">\(P\)</span>. It measures how unusual the observation’s covariates are: <span class="math inline">\(K/n \leq h_{ii} \leq 1\)</span>, and <span class="math inline">\(\sum h_{ii} = K\)</span>.</p>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, Prestige<span class="sc">$</span>education, Prestige<span class="sc">$</span>income, Prestige<span class="sc">$</span>women)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> X <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X)) <span class="sc">%*%</span> <span class="fu">t</span>(X)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="fu">ncol</span>(X)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Leverage = diagonal of P</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="fu">diag</span>(P)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># hatvalues() gives the same thing</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(h, <span class="fu">as.numeric</span>(<span class="fu">hatvalues</span>(mod_full)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Label with occupation names for later use</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(h) <span class="ot">&lt;-</span> <span class="fu">rownames</span>(Prestige)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Properties: leverage is between 0 and 1, sums to K</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">min =</span> <span class="fu">min</span>(h), <span class="at">max =</span> <span class="fu">max</span>(h), <span class="at">sum =</span> <span class="fu">sum</span>(h), <span class="at">K =</span> K)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>   min    max    sum      K 
0.0104 0.3422 4.0000 4.0000 </code></pre>
</div>
</div>
<p>A regression is <strong>balanced</strong> when leverage values are roughly equal at <span class="math inline">\(K/n\)</span>. Observations far from the center of the <span class="math inline">\(X\)</span> space have high leverage — they pull the regression line toward them:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>df_lev <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">leverage =</span> h, <span class="at">job =</span> <span class="fu">rownames</span>(Prestige))</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_lev, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(job, leverage), <span class="at">y =</span> leverage)) <span class="sc">+</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> K <span class="sc">/</span> n, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"tomato"</span>) <span class="sc">+</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">10</span>, <span class="at">y =</span> K <span class="sc">/</span> n <span class="sc">+</span> <span class="fl">0.005</span>, <span class="at">label =</span> <span class="st">"K/n (balanced)"</span>,</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>           <span class="at">color =</span> <span class="st">"tomato"</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">""</span>, <span class="at">y =</span> <span class="st">"Leverage (h_ii)"</span>,</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Leverage values for Prestige regression"</span>) <span class="sc">+</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_blank</span>(), <span class="at">axis.ticks.x =</span> <span class="fu">element_blank</span>())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch04-sensitivity_files/figure-html/leverage-distribution-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Which occupations have the highest leverage?</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">sort</span>(h, <span class="at">decreasing =</span> <span class="cn">TRUE</span>), <span class="dv">5</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>     general.managers            physicians             ministers 
               0.3422                0.2435                0.1021 
              lawyers sewing.mach.operators 
               0.0988                0.0978 </code></pre>
</div>
</div>
</section>
<section id="leave-one-out-regression" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="leave-one-out-regression"><span class="header-section-number">4</span> Leave-one-out regression</h2>
<p>If we refit the model dropping observation <span class="math inline">\(i\)</span>, how much does <span class="math inline">\(\hat\beta\)</span> change? The leave-one-out coefficient is:</p>
<p><span class="math display">\[\hat\beta_{(-i)} = \hat\beta - (X'X)^{-1}X_i \tilde{e}_i\]</span></p>
<p>where <span class="math inline">\(\tilde{e}_i = \hat{e}_i / (1 - h_{ii})\)</span> is the <strong>leave-one-out residual</strong> — the ordinary residual inflated by the leverage. High leverage shrinks the ordinary residual (the observation pulls the line toward itself), so dividing by <span class="math inline">\((1 - h_{ii})\)</span> corrects for this.</p>
<div id="thm-leave-one-out" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2 (Leave-One-Out Formula)</strong></span> The leave-one-out coefficient change is <span class="math inline">\(\hat\beta_{(-i)} = \hat\beta - (X'X)^{-1}X_i \tilde{e}_i\)</span>, where <span class="math inline">\(\tilde{e}_i = \hat{e}_i / (1 - h_{ii})\)</span>. High leverage shrinks ordinary residuals; dividing by <span class="math inline">\((1 - h_{ii})\)</span> corrects for this self-influence.</p>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ordinary residuals</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>e_hat <span class="ot">&lt;-</span> <span class="fu">resid</span>(mod_full)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Leave-one-out residuals</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>e_tilde <span class="ot">&lt;-</span> e_hat <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> h)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Studentized residuals: leave-one-out residual / its standard error</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co"># rstudent() uses sigma_{(-i)}, the error variance without obs i</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>rst <span class="ot">&lt;-</span> <span class="fu">rstudent</span>(mod_full)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the first few</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">cbind</span>(<span class="at">ordinary =</span> e_hat, <span class="at">leave_one_out =</span> e_tilde, <span class="at">studentized =</span> rst))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>                    ordinary leave_one_out studentized
gov.administrators      4.58          4.71       0.590
general.managers       -9.39        -14.28      -1.485
accountants             4.69          4.78       0.601
purchasing.officers     4.22          4.28       0.540
chemists                8.15          8.55       1.065
physicists              4.47          4.73       0.584</code></pre>
</div>
</div>
<p>An observation is <strong>influential</strong> if it has both high leverage and a large residual. The change in fitted values when observation <span class="math inline">\(i\)</span> is dropped is:</p>
<p><span class="math display">\[\hat{Y}_i - \tilde{Y}_i = h_{ii} \tilde{e}_i\]</span></p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df_infl <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">leverage =</span> h, <span class="at">rstudent =</span> rst, <span class="at">job =</span> <span class="fu">rownames</span>(Prestige))</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>df_infl<span class="sc">$</span>flag <span class="ot">&lt;-</span> <span class="fu">abs</span>(rst) <span class="sc">&gt;</span> <span class="dv">2</span> <span class="sc">|</span> h <span class="sc">&gt;</span> <span class="dv">3</span> <span class="sc">*</span> K <span class="sc">/</span> n</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_infl, <span class="fu">aes</span>(leverage, rstudent)) <span class="sc">+</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color =</span> flag), <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="at">data =</span> df_infl[df_infl<span class="sc">$</span>flag, ],</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">label =</span> job), <span class="at">hjust =</span> <span class="sc">-</span><span class="fl">0.1</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">3</span> <span class="sc">*</span> K <span class="sc">/</span> n, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"FALSE"</span> <span class="ot">=</span> <span class="st">"gray50"</span>, <span class="st">"TRUE"</span> <span class="ot">=</span> <span class="st">"tomato"</span>),</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>                     <span class="at">guide =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Leverage (h_ii)"</span>, <span class="at">y =</span> <span class="st">"Studentized residual"</span>,</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Influential observations: high leverage AND large residual"</span>) <span class="sc">+</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch04-sensitivity_files/figure-html/influential-obs-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Observations in the upper-right or lower-right are candidates for investigation: they have unusual <span class="math inline">\(X\)</span> values <em>and</em> don’t fit the model well. This could indicate a data error, a different population, or a genuinely interesting case.</p>
</section>
<section id="regression-weights-which-observations-matter-most" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="regression-weights-which-observations-matter-most"><span class="header-section-number">5</span> Regression weights: which observations matter most?</h2>
<p>The FWL result reveals that OLS assigns implicit weights to observations. For a single variable of interest <span class="math inline">\(z\)</span> in a regression with controls <span class="math inline">\(X\)</span>, the coefficient is:</p>
<p><span class="math display">\[b = \frac{\sum z_i^* y_i}{\sum z_i^{*2}}\]</span></p>
<p>where <span class="math inline">\(z_i^* = (Mz)_i\)</span> is the residual from regressing <span class="math inline">\(z\)</span> on the controls. Observations where <span class="math inline">\(z_i^{*2}\)</span> is large — where the variable of interest has a lot of variation <em>not explained by controls</em> — receive the most weight.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Women's share in occupation: variable of interest</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Controls: intercept, education, income</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>z_star <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(M1 <span class="sc">%*%</span> Prestige<span class="sc">$</span>women)  <span class="co"># M1 already built above</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Regression weights</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>omega <span class="ot">&lt;-</span> z_star<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(omega) <span class="ot">&lt;-</span> <span class="fu">rownames</span>(Prestige)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Most and least weighted occupations</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Highest weight (most variation in women% net of controls):</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Highest weight (most variation in women% net of controls):</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">sort</span>(omega, <span class="at">decreasing =</span> <span class="cn">TRUE</span>), <span class="dv">5</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>              physicians         general.managers osteopaths.chiropractors 
                4.53e-26                 2.33e-26                 1.67e-26 
                 lawyers             farm.workers 
                1.57e-26                 9.39e-27 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Lowest weight (almost no unique variation):</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Lowest weight (almost no unique variation):</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">sort</span>(omega), <span class="dv">5</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code> construction.foremen          receptionsts              athletes 
             3.77e-32              1.97e-31              8.91e-31 
commercial.travellers     sales.supervisors 
             1.08e-30              1.77e-30 </code></pre>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify: weighted formula gives same coefficient as lm</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>b_weighted <span class="ot">&lt;-</span> <span class="fu">sum</span>(z_star <span class="sc">*</span> y) <span class="sc">/</span> <span class="fu">sum</span>(z_star<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">weighted_formula =</span> b_weighted, <span class="at">lm =</span> <span class="fu">coef</span>(mod_full)[<span class="st">"women"</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>weighted_formula         lm.women 
       -4.26e+14        -8.91e-03 </code></pre>
</div>
</div>
<p>Occupations like general managers and ministers — where the share of women is very different from what education and income would predict — have thousands of times more influence on the coefficient than occupations where women’s share is well-predicted by the controls.</p>
</section>
<section id="partial-r2" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="partial-r2"><span class="header-section-number">6</span> Partial <span class="math inline">\(R^2\)</span></h2>
<p>The partial <span class="math inline">\(R^2\)</span> measures how much of the <em>remaining</em> variance in <span class="math inline">\(Y\)</span> (after accounting for <span class="math inline">\(X_1\)</span>) is explained by <span class="math inline">\(X_2\)</span>:</p>
<p><span id="eq-partial-r2"><span class="math display">\[R^2_{Y \sim X_2 | X_1} = 1 - \frac{\text{RSS}(X_1, X_2)}{\text{RSS}(X_1)} = \frac{\text{RSS}(X_1) - \text{RSS}(X_1, X_2)}{\text{RSS}(X_1)} \tag{2}\]</span></span></p>
<p>For a single variable, the partial <span class="math inline">\(R^2\)</span> equals the squared partial correlation:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># RSS from controls only</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>mod_controls <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>RSS_controls <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod_controls)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co"># RSS from full model</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>RSS_full <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod_full)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Partial R^2 of education given (income, women)</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>partial_r2_educ <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> RSS_full <span class="sc">/</span> RSS_controls</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Equivalently: squared correlation of FWL residuals</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>cor_fwl <span class="ot">&lt;-</span> <span class="fu">cor</span>(e_y, e_educ)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">partial_R2 =</span> partial_r2_educ, <span class="at">squared_partial_cor =</span> cor_fwl)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>         partial_R2 squared_partial_cor 
              0.542               0.542 </code></pre>
</div>
</div>
<p>We can also compute partial <span class="math inline">\(R^2\)</span> for each variable using the matrix formula. The FWL residuals give us everything we need:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Partial R^2 for each variable</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>partial_r2 <span class="ot">&lt;-</span> <span class="cf">function</span>(mod, var_name) {</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  formula_reduced <span class="ot">&lt;-</span> <span class="fu">update</span>(<span class="fu">formula</span>(mod), <span class="fu">paste</span>(<span class="st">"~ . -"</span>, var_name))</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  mod_reduced <span class="ot">&lt;-</span> <span class="fu">lm</span>(formula_reduced, <span class="at">data =</span> Prestige)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span> <span class="sc">-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod_reduced)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">variable =</span> <span class="fu">c</span>(<span class="st">"education"</span>, <span class="st">"income"</span>, <span class="st">"women"</span>),</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">partial_R2 =</span> <span class="fu">sapply</span>(<span class="fu">c</span>(<span class="st">"education"</span>, <span class="st">"income"</span>, <span class="st">"women"</span>),</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>                       <span class="cf">function</span>(v) <span class="fu">partial_r2</span>(mod_full, v))</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>           variable partial_R2
education education   0.542079
income       income   0.185784
women         women   0.000874</code></pre>
</div>
</div>
<p>Education has a high partial <span class="math inline">\(R^2\)</span> — it explains a large share of prestige variation that income and women’s share cannot. Women’s share has a very low partial <span class="math inline">\(R^2\)</span>: once we know education and income, knowing the gender composition adds almost nothing.</p>
</section>
<section id="sensitivity-analysis-cinelli-hazlett-2020" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="sensitivity-analysis-cinelli-hazlett-2020"><span class="header-section-number">7</span> Sensitivity analysis: Cinelli-Hazlett (2020)</h2>
<p>Even after including controls, there may be <em>unobserved</em> confounders. The OVB formula from Chapter 2 says the bias from omitting a variable <span class="math inline">\(Z\)</span> is:</p>
<p><span class="math display">\[\text{bias} = \underbrace{\frac{\text{Cov}(D, Z)}{\text{Var}(D)}}_{\text{imbalance}} \times \underbrace{\frac{\text{Cov}(Z^{\perp D}, Y^{\perp D})}{\text{Var}(Z^{\perp D})}}_{\text{impact}}\]</span></p>
<p>Cinelli and Hazlett (2020) reparameterize this in terms of partial <span class="math inline">\(R^2\)</span> values, which are easier to reason about:</p>
<p><span class="math display">\[|\text{bias}| \propto \sqrt{\frac{R^2_{D \sim Z} \cdot R^2_{Y \sim Z|D}}{1 - R^2_{D \sim Z}}}\]</span></p>
<p>The key insight: a confounder must predict <em>both</em> treatment and outcome to generate meaningful bias. If either partial <span class="math inline">\(R^2\)</span> is small, the bias is small.</p>
<p>Let’s simulate and run a sensitivity analysis:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>beta_D <span class="ot">&lt;-</span> <span class="dv">2</span>; beta_Z <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>D <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(N, <span class="dv">1</span>, <span class="fl">0.5</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>Z <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> beta_D <span class="sc">*</span> D <span class="sc">+</span> beta_Z <span class="sc">*</span> Z <span class="sc">+</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Naive model (omitting Z) -- biased</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(Y <span class="sc">~</span> D))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)           D 
     0.0569      1.9519 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Full model (including Z) -- unbiased</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>model_full_sim <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> D <span class="sc">+</span> Z)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(model_full_sim)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)           D           Z 
     0.0254      1.9417      3.0600 </code></pre>
</div>
</div>
<p>The naive model overestimates the effect of <span class="math inline">\(D\)</span>. The full model recovers <span class="math inline">\(\beta_D \approx 2\)</span>. But what if there were <em>another</em> confounder we couldn’t observe? We use the observed confounder <span class="math inline">\(Z\)</span> as a benchmark:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How strong is Z as a confounder?</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Partial R^2 of Z on D</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>partial_r2_DZ <span class="ot">&lt;-</span> <span class="fu">cor</span>(D, Z)<span class="sc">^</span><span class="dv">2</span>  <span class="co"># for a single variable, partial R^2 ≈ cor^2</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Partial R^2 of Z on Y|D</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>RSS_D_only <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(<span class="fu">lm</span>(Y <span class="sc">~</span> D))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>RSS_full_sim <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(model_full_sim)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>partial_r2_YZ_D <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> RSS_full_sim <span class="sc">/</span> RSS_D_only</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">R2_D_Z =</span> partial_r2_DZ, <span class="at">R2_Y_Z_given_D =</span> partial_r2_YZ_D)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>        R2_D_Z R2_Y_Z_given_D 
      2.78e-06       9.07e-01 </code></pre>
</div>
</div>
<p>An unobserved confounder would need partial <span class="math inline">\(R^2\)</span> values at least this large with both <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span> to generate comparable bias. If the strongest observed predictor explains only a few percent of residual variation, an omitted variable would need to be far stronger to overturn the result.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The sensemakr package automates this analysis</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">requireNamespace</span>(<span class="st">"sensemakr"</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(sensemakr)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>  sens <span class="ot">&lt;-</span> <span class="fu">sensemakr</span>(model_full_sim, <span class="at">treatment =</span> <span class="st">"D"</span>,</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">benchmark_covariates =</span> <span class="st">"Z"</span>)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>(sens)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Sensitivity Analysis to Unobserved Confounding

Model Formula: Y ~ D + Z

Null hypothesis: q = 1 and reduce = TRUE 
-- This means we are considering biases that reduce the absolute value of the current estimate.
-- The null hypothesis deemed problematic is H0:tau = 0 

Unadjusted Estimates of 'D': 
  Coef. estimate: 1.94 
  Standard Error: 0.062 
  t-value (H0:tau = 0): 31.2 

Sensitivity Statistics:
  Partial R2 of treatment with outcome: 0.494 
  Robustness Value, q = 1: 0.614 
  Robustness Value, q = 1, alpha = 0.05: 0.592 

Verbal interpretation of sensitivity statistics:

-- Partial R2 of the treatment with the outcome: an extreme confounder (orthogonal to the covariates) that explains 100% of the residual variance of the outcome, would need to explain at least 49.4% of the residual variance of the treatment to fully account for the observed estimated effect.

-- Robustness Value, q = 1: unobserved confounders (orthogonal to the covariates) that explain more than 61.4% of the residual variance of both the treatment and the outcome are strong enough to bring the point estimate to 0 (a bias of 100% of the original estimate). Conversely, unobserved confounders that do not explain more than 61.4% of the residual variance of both the treatment and the outcome are not strong enough to bring the point estimate to 0.

-- Robustness Value, q = 1, alpha = 0.05: unobserved confounders (orthogonal to the covariates) that explain more than 59.2% of the residual variance of both the treatment and the outcome are strong enough to bring the estimate to a range where it is no longer 'statistically different' from 0 (a bias of 100% of the original estimate), at the significance level of alpha = 0.05. Conversely, unobserved confounders that do not explain more than 59.2% of the residual variance of both the treatment and the outcome are not strong enough to bring the estimate to a range where it is no longer 'statistically different' from 0, at the significance level of alpha = 0.05.

Bounds on omitted variable bias:

--The table below shows the maximum strength of unobserved confounders with association with the treatment and the outcome bounded by a multiple of the observed explanatory power of the chosen benchmark covariate(s).

 Bound Label R2dz.x R2yz.dx Treatment Adjusted Estimate Adjusted Se Adjusted T
        1x Z      0       1         D              1.94           0        Inf
 Adjusted Lower CI Adjusted Upper CI
              1.94              1.94</code></pre>
</div>
</div>
<p>The <strong>robustness value</strong> tells us the minimum strength an unobserved confounder must have (in terms of partial <span class="math inline">\(R^2\)</span> with both <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>) to explain away the entire estimated effect.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Sensitivity Does Not Prove Robustness
</div>
</div>
<div class="callout-body-container callout-body">
<p>A large robustness value means the result survives <em>hypothetical</em> confounders of a given strength — but it cannot rule out their existence. Sensitivity analysis quantifies what <em>would</em> be needed to overturn a finding; it does not establish that no such confounder exists.</p>
</div>
</div>
</section>
<section id="summary" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="summary"><span class="header-section-number">8</span> Summary</h2>
<ul>
<li><strong>FWL theorem</strong>: The coefficient on <span class="math inline">\(X_2\)</span> in <span class="math inline">\(y = X_1\beta_1 + X_2\beta_2 + e\)</span> equals the coefficient from regressing <span class="math inline">\(M_1 y\)</span> on <span class="math inline">\(M_1 X_2\)</span> — residualize both sides against the controls.</li>
<li><strong>Partial regression plots</strong> let us visualize multivariate relationships in 2D using FWL residuals.</li>
<li><strong>Leverage</strong> <span class="math inline">\(h_{ii} = X_i'(X'X)^{-1}X_i\)</span> measures how unusual observation <span class="math inline">\(i\)</span>’s covariates are. High leverage + large residual = influential observation.</li>
<li><strong>Leave-one-out residuals</strong> <span class="math inline">\(\tilde{e}_i = \hat{e}_i/(1-h_{ii})\)</span> correct for the self-influence of observation <span class="math inline">\(i\)</span>.</li>
<li><strong>Regression weights</strong>: OLS implicitly weights observations by <span class="math inline">\(z_i^{*2}\)</span>, the squared residual from regressing the variable of interest on controls. Observations with more unique variation in the treatment get more weight.</li>
<li><strong>Partial <span class="math inline">\(R^2\)</span></strong> measures the share of residual variance explained by a variable after accounting for other regressors.</li>
<li><strong>Sensitivity analysis</strong> (Cinelli-Hazlett): bias from an omitted confounder depends on its partial <span class="math inline">\(R^2\)</span> with both treatment and outcome. Use observed covariates as benchmarks.</li>
</ul>
<p>Next: <a href="./ch05-gls.html">Efficiency and GLS</a> — the Gauss-Markov theorem and generalized least squares.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/UChicago-pol-methods\.github\.io\/EstimationI\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb40" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "4. Sensitivity and Leverage"</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Frisch-Waugh-Lovell, partial R², and influential observations"</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(carData)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>tr <span class="ot">&lt;-</span> <span class="cf">function</span>(M) <span class="fu">sum</span>(<span class="fu">diag</span>(M))</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Prestige)</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>In applied work we rarely care about every regressor equally. We have a treatment or variable of interest ($X_1$) and controls we include to avoid omitted variable bias ($X_2$). Partitioning $X = <span class="co">[</span><span class="ot">X_1 \; X_2</span><span class="co">]</span>$ lets us answer three questions: What is the formula for $\hat\beta_1$ holding $X_2$ constant? What happens if we omit $X_2$? And how sensitive is $\hat\beta_1$ to confounders we cannot observe?</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>**Questions this chapter answers:**</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>How does the Frisch-Waugh-Lovell theorem decompose a multivariate regression into residual-on-residual regressions?</span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Which observations exert the most influence on OLS estimates, and how does leverage measure this?</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>How do sensitivity analysis tools (Cinelli-Hazlett) quantify robustness to unobserved confounders?</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Frisch-Waugh-Lovell theorem {#sec-fwl}</span></span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>The FWL theorem says: the coefficient $\hat\beta_2$ from the full regression $y = X_1\beta_1 + X_2\beta_2 + e$ is identical to the coefficient from regressing the residualized outcome on the residualized treatment — after partialling out $X_1$ from both.</span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>In matrix terms, let $M_1 = I - X_1(X_1'X_1)^{-1}X_1'$ be the annihilator for $X_1$. Then:</span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a>$$\hat\beta_2 = (X_2'M_1 X_2)^{-1} X_2' M_1 y$$ {#eq-fwl}</span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a>This is just OLS on the residuals $M_1 y$ and $M_1 X_2$ — the parts of $y$ and $X_2$ that $X_1$ cannot explain.</span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-36"><a href="#cb40-36" aria-hidden="true" tabindex="-1"></a>::: {#thm-fwl}</span>
<span id="cb40-37"><a href="#cb40-37" aria-hidden="true" tabindex="-1"></a><span class="fu">## Frisch-Waugh-Lovell Theorem</span></span>
<span id="cb40-38"><a href="#cb40-38" aria-hidden="true" tabindex="-1"></a>The coefficient $\hat\beta_2$ from the full regression $y = X_1\beta_1 + X_2\beta_2 + e$ equals the coefficient from regressing $M_1 y$ on $M_1 X_2$, where $M_1 = I - X_1(X_1'X_1)^{-1}X_1'$. That is: partial out the controls from both sides, then run OLS.</span>
<span id="cb40-39"><a href="#cb40-39" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb40-40"><a href="#cb40-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-41"><a href="#cb40-41" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb40-42"><a href="#cb40-42" aria-hidden="true" tabindex="-1"></a><span class="fu">## FWL as a Bridge Between Chapters</span></span>
<span id="cb40-43"><a href="#cb40-43" aria-hidden="true" tabindex="-1"></a>The FWL theorem connects OLS geometry (Chapter 3) to applied causal inference. Partial regression plots — residualized $Y$ vs. residualized $X$ — visualize the multivariate coefficient in two dimensions. This same logic underlies fixed effects estimation (Chapter 12): demeaning within groups is FWL with group dummies as controls.</span>
<span id="cb40-44"><a href="#cb40-44" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb40-45"><a href="#cb40-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-46"><a href="#cb40-46" aria-hidden="true" tabindex="-1"></a>Let's verify with the Prestige data. We'll show that the coefficient on <span class="in">`education`</span> from a regression controlling for <span class="in">`income`</span> and <span class="in">`women`</span> is the same as the coefficient from the residual-on-residual regression:</span>
<span id="cb40-47"><a href="#cb40-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-50"><a href="#cb40-50" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-51"><a href="#cb40-51" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fwl-verification</span></span>
<span id="cb40-52"><a href="#cb40-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Full regression</span></span>
<span id="cb40-53"><a href="#cb40-53" aria-hidden="true" tabindex="-1"></a>mod_full <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige)</span>
<span id="cb40-54"><a href="#cb40-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-55"><a href="#cb40-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Residualize both y and education against (income, women)</span></span>
<span id="cb40-56"><a href="#cb40-56" aria-hidden="true" tabindex="-1"></a>e_y <span class="ot">&lt;-</span> <span class="fu">resid</span>(<span class="fu">lm</span>(prestige <span class="sc">~</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige))</span>
<span id="cb40-57"><a href="#cb40-57" aria-hidden="true" tabindex="-1"></a>e_educ <span class="ot">&lt;-</span> <span class="fu">resid</span>(<span class="fu">lm</span>(education <span class="sc">~</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige))</span>
<span id="cb40-58"><a href="#cb40-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-59"><a href="#cb40-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Regress residuals on residuals</span></span>
<span id="cb40-60"><a href="#cb40-60" aria-hidden="true" tabindex="-1"></a>mod_fwl <span class="ot">&lt;-</span> <span class="fu">lm</span>(e_y <span class="sc">~</span> e_educ)</span>
<span id="cb40-61"><a href="#cb40-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-62"><a href="#cb40-62" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">full_regression =</span> <span class="fu">coef</span>(mod_full)[<span class="st">"education"</span>],</span>
<span id="cb40-63"><a href="#cb40-63" aria-hidden="true" tabindex="-1"></a>  <span class="at">FWL =</span> <span class="fu">coef</span>(mod_fwl)[<span class="st">"e_educ"</span>])</span>
<span id="cb40-64"><a href="#cb40-64" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-65"><a href="#cb40-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-66"><a href="#cb40-66" aria-hidden="true" tabindex="-1"></a>Identical. FWL tells us that the coefficient on education reflects only the variation in education *not* explained by income and women.</span>
<span id="cb40-67"><a href="#cb40-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-68"><a href="#cb40-68" aria-hidden="true" tabindex="-1"></a><span class="fu">### FWL with matrices</span></span>
<span id="cb40-69"><a href="#cb40-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-70"><a href="#cb40-70" aria-hidden="true" tabindex="-1"></a>Let's do it with the projection and annihilator matrices directly:</span>
<span id="cb40-71"><a href="#cb40-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-74"><a href="#cb40-74" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-75"><a href="#cb40-75" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fwl-matrices</span></span>
<span id="cb40-76"><a href="#cb40-76" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> Prestige<span class="sc">$</span>prestige</span>
<span id="cb40-77"><a href="#cb40-77" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(Prestige)</span>
<span id="cb40-78"><a href="#cb40-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-79"><a href="#cb40-79" aria-hidden="true" tabindex="-1"></a><span class="co"># X1 = controls (intercept, income, women)</span></span>
<span id="cb40-80"><a href="#cb40-80" aria-hidden="true" tabindex="-1"></a>X1 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, Prestige<span class="sc">$</span>income, Prestige<span class="sc">$</span>women)</span>
<span id="cb40-81"><a href="#cb40-81" aria-hidden="true" tabindex="-1"></a><span class="co"># X2 = variable of interest (education)</span></span>
<span id="cb40-82"><a href="#cb40-82" aria-hidden="true" tabindex="-1"></a>X2 <span class="ot">&lt;-</span> Prestige<span class="sc">$</span>education</span>
<span id="cb40-83"><a href="#cb40-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-84"><a href="#cb40-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Build the annihilator for X1</span></span>
<span id="cb40-85"><a href="#cb40-85" aria-hidden="true" tabindex="-1"></a>P1 <span class="ot">&lt;-</span> X1 <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X1)) <span class="sc">%*%</span> <span class="fu">t</span>(X1)</span>
<span id="cb40-86"><a href="#cb40-86" aria-hidden="true" tabindex="-1"></a>M1 <span class="ot">&lt;-</span> <span class="fu">diag</span>(n) <span class="sc">-</span> P1</span>
<span id="cb40-87"><a href="#cb40-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-88"><a href="#cb40-88" aria-hidden="true" tabindex="-1"></a><span class="co"># FWL formula: beta_2 = (X2'M1 X2)^{-1} X2'M1 y</span></span>
<span id="cb40-89"><a href="#cb40-89" aria-hidden="true" tabindex="-1"></a>beta_fwl <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">solve</span>(<span class="fu">t</span>(X2) <span class="sc">%*%</span> M1 <span class="sc">%*%</span> X2) <span class="sc">%*%</span> <span class="fu">t</span>(X2) <span class="sc">%*%</span> M1 <span class="sc">%*%</span> y)</span>
<span id="cb40-90"><a href="#cb40-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-91"><a href="#cb40-91" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">matrix_FWL =</span> beta_fwl, <span class="at">lm =</span> <span class="fu">coef</span>(mod_full)[<span class="st">"education"</span>])</span>
<span id="cb40-92"><a href="#cb40-92" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-93"><a href="#cb40-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-94"><a href="#cb40-94" aria-hidden="true" tabindex="-1"></a><span class="fu">## Plotting partial effects</span></span>
<span id="cb40-95"><a href="#cb40-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-96"><a href="#cb40-96" aria-hidden="true" tabindex="-1"></a>One practical benefit of FWL: it lets us visualize relationships from a multivariate regression in two dimensions. After partialling out the controls, we can scatter the residualized $y$ against the residualized $x$ and draw the partial regression line.</span>
<span id="cb40-97"><a href="#cb40-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-100"><a href="#cb40-100" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-101"><a href="#cb40-101" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: partial-plot</span></span>
<span id="cb40-102"><a href="#cb40-102" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Partial regression plot: education → prestige (FWL residuals)"</span></span>
<span id="cb40-103"><a href="#cb40-103" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb40-104"><a href="#cb40-104" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb40-105"><a href="#cb40-105" aria-hidden="true" tabindex="-1"></a>df_partial <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">educ_resid =</span> e_educ, <span class="at">prestige_resid =</span> e_y,</span>
<span id="cb40-106"><a href="#cb40-106" aria-hidden="true" tabindex="-1"></a>                         <span class="at">job =</span> <span class="fu">rownames</span>(Prestige))</span>
<span id="cb40-107"><a href="#cb40-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-108"><a href="#cb40-108" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_partial, <span class="fu">aes</span>(educ_resid, prestige_resid)) <span class="sc">+</span></span>
<span id="cb40-109"><a href="#cb40-109" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb40-110"><a href="#cb40-110" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"steelblue"</span>, <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb40-111"><a href="#cb40-111" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="at">data =</span> df_partial[<span class="fu">abs</span>(df_partial<span class="sc">$</span>prestige_resid) <span class="sc">&gt;</span> <span class="dv">15</span>, ],</span>
<span id="cb40-112"><a href="#cb40-112" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">label =</span> job), <span class="at">hjust =</span> <span class="sc">-</span><span class="fl">0.1</span>, <span class="at">size =</span> <span class="fl">2.5</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb40-113"><a href="#cb40-113" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Education residual (net of income, women)"</span>,</span>
<span id="cb40-114"><a href="#cb40-114" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Prestige residual (net of income, women)"</span>,</span>
<span id="cb40-115"><a href="#cb40-115" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Partial regression plot: education → prestige"</span>,</span>
<span id="cb40-116"><a href="#cb40-116" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">paste0</span>(<span class="st">"Slope = "</span>, <span class="fu">round</span>(<span class="fu">coef</span>(mod_fwl)[<span class="dv">2</span>], <span class="dv">2</span>),</span>
<span id="cb40-117"><a href="#cb40-117" aria-hidden="true" tabindex="-1"></a>                         <span class="st">" (same as the multivariate coefficient)"</span>)) <span class="sc">+</span></span>
<span id="cb40-118"><a href="#cb40-118" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb40-119"><a href="#cb40-119" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-120"><a href="#cb40-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-121"><a href="#cb40-121" aria-hidden="true" tabindex="-1"></a>The slope of this line *is* the multivariate regression coefficient. Each point shows an occupation's education and prestige after removing what income and gender composition predict. Ministers have high prestige residuals — more prestige than their income and gender composition would suggest.</span>
<span id="cb40-122"><a href="#cb40-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-123"><a href="#cb40-123" aria-hidden="true" tabindex="-1"></a><span class="fu">## Leverage: which observations pull the line?</span></span>
<span id="cb40-124"><a href="#cb40-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-125"><a href="#cb40-125" aria-hidden="true" tabindex="-1"></a>The diagonal elements of the hat matrix $P = X(X'X)^{-1}X'$ measure **leverage** — how unusual each observation's $X$ values are relative to the rest of the data. The $i$-th leverage value is:</span>
<span id="cb40-126"><a href="#cb40-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-127"><a href="#cb40-127" aria-hidden="true" tabindex="-1"></a>$$h_{ii} = X_i'(X'X)^{-1}X_i$$</span>
<span id="cb40-128"><a href="#cb40-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-129"><a href="#cb40-129" aria-hidden="true" tabindex="-1"></a>::: {#def-leverage}</span>
<span id="cb40-130"><a href="#cb40-130" aria-hidden="true" tabindex="-1"></a><span class="fu">## Leverage</span></span>
<span id="cb40-131"><a href="#cb40-131" aria-hidden="true" tabindex="-1"></a>The leverage of observation $i$ is $h_{ii} = X_i'(X'X)^{-1}X_i$, the $i$-th diagonal element of the hat matrix $P$. It measures how unusual the observation's covariates are: $K/n \leq h_{ii} \leq 1$, and $\sum h_{ii} = K$.</span>
<span id="cb40-132"><a href="#cb40-132" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb40-133"><a href="#cb40-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-136"><a href="#cb40-136" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-137"><a href="#cb40-137" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: leverage</span></span>
<span id="cb40-138"><a href="#cb40-138" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, Prestige<span class="sc">$</span>education, Prestige<span class="sc">$</span>income, Prestige<span class="sc">$</span>women)</span>
<span id="cb40-139"><a href="#cb40-139" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> X <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X)) <span class="sc">%*%</span> <span class="fu">t</span>(X)</span>
<span id="cb40-140"><a href="#cb40-140" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="fu">ncol</span>(X)</span>
<span id="cb40-141"><a href="#cb40-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-142"><a href="#cb40-142" aria-hidden="true" tabindex="-1"></a><span class="co"># Leverage = diagonal of P</span></span>
<span id="cb40-143"><a href="#cb40-143" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="fu">diag</span>(P)</span>
<span id="cb40-144"><a href="#cb40-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-145"><a href="#cb40-145" aria-hidden="true" tabindex="-1"></a><span class="co"># hatvalues() gives the same thing</span></span>
<span id="cb40-146"><a href="#cb40-146" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(h, <span class="fu">as.numeric</span>(<span class="fu">hatvalues</span>(mod_full)))</span>
<span id="cb40-147"><a href="#cb40-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-148"><a href="#cb40-148" aria-hidden="true" tabindex="-1"></a><span class="co"># Label with occupation names for later use</span></span>
<span id="cb40-149"><a href="#cb40-149" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(h) <span class="ot">&lt;-</span> <span class="fu">rownames</span>(Prestige)</span>
<span id="cb40-150"><a href="#cb40-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-151"><a href="#cb40-151" aria-hidden="true" tabindex="-1"></a><span class="co"># Properties: leverage is between 0 and 1, sums to K</span></span>
<span id="cb40-152"><a href="#cb40-152" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">min =</span> <span class="fu">min</span>(h), <span class="at">max =</span> <span class="fu">max</span>(h), <span class="at">sum =</span> <span class="fu">sum</span>(h), <span class="at">K =</span> K)</span>
<span id="cb40-153"><a href="#cb40-153" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-154"><a href="#cb40-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-155"><a href="#cb40-155" aria-hidden="true" tabindex="-1"></a>A regression is **balanced** when leverage values are roughly equal at $K/n$. Observations far from the center of the $X$ space have high leverage — they pull the regression line toward them:</span>
<span id="cb40-156"><a href="#cb40-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-159"><a href="#cb40-159" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-160"><a href="#cb40-160" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: leverage-distribution</span></span>
<span id="cb40-161"><a href="#cb40-161" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 6</span></span>
<span id="cb40-162"><a href="#cb40-162" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 3.5</span></span>
<span id="cb40-163"><a href="#cb40-163" aria-hidden="true" tabindex="-1"></a>df_lev <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">leverage =</span> h, <span class="at">job =</span> <span class="fu">rownames</span>(Prestige))</span>
<span id="cb40-164"><a href="#cb40-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-165"><a href="#cb40-165" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_lev, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(job, leverage), <span class="at">y =</span> leverage)) <span class="sc">+</span></span>
<span id="cb40-166"><a href="#cb40-166" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb40-167"><a href="#cb40-167" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> K <span class="sc">/</span> n, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"tomato"</span>) <span class="sc">+</span></span>
<span id="cb40-168"><a href="#cb40-168" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">10</span>, <span class="at">y =</span> K <span class="sc">/</span> n <span class="sc">+</span> <span class="fl">0.005</span>, <span class="at">label =</span> <span class="st">"K/n (balanced)"</span>,</span>
<span id="cb40-169"><a href="#cb40-169" aria-hidden="true" tabindex="-1"></a>           <span class="at">color =</span> <span class="st">"tomato"</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb40-170"><a href="#cb40-170" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">""</span>, <span class="at">y =</span> <span class="st">"Leverage (h_ii)"</span>,</span>
<span id="cb40-171"><a href="#cb40-171" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Leverage values for Prestige regression"</span>) <span class="sc">+</span></span>
<span id="cb40-172"><a href="#cb40-172" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb40-173"><a href="#cb40-173" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_blank</span>(), <span class="at">axis.ticks.x =</span> <span class="fu">element_blank</span>())</span>
<span id="cb40-174"><a href="#cb40-174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-175"><a href="#cb40-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-178"><a href="#cb40-178" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-179"><a href="#cb40-179" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: high-leverage</span></span>
<span id="cb40-180"><a href="#cb40-180" aria-hidden="true" tabindex="-1"></a><span class="co"># Which occupations have the highest leverage?</span></span>
<span id="cb40-181"><a href="#cb40-181" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">sort</span>(h, <span class="at">decreasing =</span> <span class="cn">TRUE</span>), <span class="dv">5</span>)</span>
<span id="cb40-182"><a href="#cb40-182" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-183"><a href="#cb40-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-184"><a href="#cb40-184" aria-hidden="true" tabindex="-1"></a><span class="fu">## Leave-one-out regression</span></span>
<span id="cb40-185"><a href="#cb40-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-186"><a href="#cb40-186" aria-hidden="true" tabindex="-1"></a>If we refit the model dropping observation $i$, how much does $\hat\beta$ change? The leave-one-out coefficient is:</span>
<span id="cb40-187"><a href="#cb40-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-188"><a href="#cb40-188" aria-hidden="true" tabindex="-1"></a>$$\hat\beta_{(-i)} = \hat\beta - (X'X)^{-1}X_i \tilde{e}_i$$</span>
<span id="cb40-189"><a href="#cb40-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-190"><a href="#cb40-190" aria-hidden="true" tabindex="-1"></a>where $\tilde{e}_i = \hat{e}_i / (1 - h_{ii})$ is the **leave-one-out residual** — the ordinary residual inflated by the leverage. High leverage shrinks the ordinary residual (the observation pulls the line toward itself), so dividing by $(1 - h_{ii})$ corrects for this.</span>
<span id="cb40-191"><a href="#cb40-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-192"><a href="#cb40-192" aria-hidden="true" tabindex="-1"></a>::: {#thm-leave-one-out}</span>
<span id="cb40-193"><a href="#cb40-193" aria-hidden="true" tabindex="-1"></a><span class="fu">## Leave-One-Out Formula</span></span>
<span id="cb40-194"><a href="#cb40-194" aria-hidden="true" tabindex="-1"></a>The leave-one-out coefficient change is $\hat\beta_{(-i)} = \hat\beta - (X'X)^{-1}X_i \tilde{e}_i$, where $\tilde{e}_i = \hat{e}_i / (1 - h_{ii})$. High leverage shrinks ordinary residuals; dividing by $(1 - h_{ii})$ corrects for this self-influence.</span>
<span id="cb40-195"><a href="#cb40-195" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb40-196"><a href="#cb40-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-199"><a href="#cb40-199" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-200"><a href="#cb40-200" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: leave-one-out</span></span>
<span id="cb40-201"><a href="#cb40-201" aria-hidden="true" tabindex="-1"></a><span class="co"># Ordinary residuals</span></span>
<span id="cb40-202"><a href="#cb40-202" aria-hidden="true" tabindex="-1"></a>e_hat <span class="ot">&lt;-</span> <span class="fu">resid</span>(mod_full)</span>
<span id="cb40-203"><a href="#cb40-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-204"><a href="#cb40-204" aria-hidden="true" tabindex="-1"></a><span class="co"># Leave-one-out residuals</span></span>
<span id="cb40-205"><a href="#cb40-205" aria-hidden="true" tabindex="-1"></a>e_tilde <span class="ot">&lt;-</span> e_hat <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> h)</span>
<span id="cb40-206"><a href="#cb40-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-207"><a href="#cb40-207" aria-hidden="true" tabindex="-1"></a><span class="co"># Studentized residuals: leave-one-out residual / its standard error</span></span>
<span id="cb40-208"><a href="#cb40-208" aria-hidden="true" tabindex="-1"></a><span class="co"># rstudent() uses sigma_{(-i)}, the error variance without obs i</span></span>
<span id="cb40-209"><a href="#cb40-209" aria-hidden="true" tabindex="-1"></a>rst <span class="ot">&lt;-</span> <span class="fu">rstudent</span>(mod_full)</span>
<span id="cb40-210"><a href="#cb40-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-211"><a href="#cb40-211" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the first few</span></span>
<span id="cb40-212"><a href="#cb40-212" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">cbind</span>(<span class="at">ordinary =</span> e_hat, <span class="at">leave_one_out =</span> e_tilde, <span class="at">studentized =</span> rst))</span>
<span id="cb40-213"><a href="#cb40-213" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-214"><a href="#cb40-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-215"><a href="#cb40-215" aria-hidden="true" tabindex="-1"></a>An observation is **influential** if it has both high leverage and a large residual. The change in fitted values when observation $i$ is dropped is:</span>
<span id="cb40-216"><a href="#cb40-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-217"><a href="#cb40-217" aria-hidden="true" tabindex="-1"></a>$$\hat{Y}_i - \tilde{Y}_i = h_{ii} \tilde{e}_i$$</span>
<span id="cb40-218"><a href="#cb40-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-221"><a href="#cb40-221" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-222"><a href="#cb40-222" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: influential-obs</span></span>
<span id="cb40-223"><a href="#cb40-223" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 6</span></span>
<span id="cb40-224"><a href="#cb40-224" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb40-225"><a href="#cb40-225" aria-hidden="true" tabindex="-1"></a>df_infl <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">leverage =</span> h, <span class="at">rstudent =</span> rst, <span class="at">job =</span> <span class="fu">rownames</span>(Prestige))</span>
<span id="cb40-226"><a href="#cb40-226" aria-hidden="true" tabindex="-1"></a>df_infl<span class="sc">$</span>flag <span class="ot">&lt;-</span> <span class="fu">abs</span>(rst) <span class="sc">&gt;</span> <span class="dv">2</span> <span class="sc">|</span> h <span class="sc">&gt;</span> <span class="dv">3</span> <span class="sc">*</span> K <span class="sc">/</span> n</span>
<span id="cb40-227"><a href="#cb40-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-228"><a href="#cb40-228" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_infl, <span class="fu">aes</span>(leverage, rstudent)) <span class="sc">+</span></span>
<span id="cb40-229"><a href="#cb40-229" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color =</span> flag), <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb40-230"><a href="#cb40-230" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="at">data =</span> df_infl[df_infl<span class="sc">$</span>flag, ],</span>
<span id="cb40-231"><a href="#cb40-231" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">label =</span> job), <span class="at">hjust =</span> <span class="sc">-</span><span class="fl">0.1</span>, <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb40-232"><a href="#cb40-232" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb40-233"><a href="#cb40-233" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">3</span> <span class="sc">*</span> K <span class="sc">/</span> n, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb40-234"><a href="#cb40-234" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"FALSE"</span> <span class="ot">=</span> <span class="st">"gray50"</span>, <span class="st">"TRUE"</span> <span class="ot">=</span> <span class="st">"tomato"</span>),</span>
<span id="cb40-235"><a href="#cb40-235" aria-hidden="true" tabindex="-1"></a>                     <span class="at">guide =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb40-236"><a href="#cb40-236" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Leverage (h_ii)"</span>, <span class="at">y =</span> <span class="st">"Studentized residual"</span>,</span>
<span id="cb40-237"><a href="#cb40-237" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Influential observations: high leverage AND large residual"</span>) <span class="sc">+</span></span>
<span id="cb40-238"><a href="#cb40-238" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb40-239"><a href="#cb40-239" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-240"><a href="#cb40-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-241"><a href="#cb40-241" aria-hidden="true" tabindex="-1"></a>Observations in the upper-right or lower-right are candidates for investigation: they have unusual $X$ values *and* don't fit the model well. This could indicate a data error, a different population, or a genuinely interesting case.</span>
<span id="cb40-242"><a href="#cb40-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-243"><a href="#cb40-243" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regression weights: which observations matter most?</span></span>
<span id="cb40-244"><a href="#cb40-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-245"><a href="#cb40-245" aria-hidden="true" tabindex="-1"></a>The FWL result reveals that OLS assigns implicit weights to observations. For a single variable of interest $z$ in a regression with controls $X$, the coefficient is:</span>
<span id="cb40-246"><a href="#cb40-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-247"><a href="#cb40-247" aria-hidden="true" tabindex="-1"></a>$$b = \frac{\sum z_i^* y_i}{\sum z_i^{*2}}$$</span>
<span id="cb40-248"><a href="#cb40-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-249"><a href="#cb40-249" aria-hidden="true" tabindex="-1"></a>where $z_i^* = (Mz)_i$ is the residual from regressing $z$ on the controls. Observations where $z_i^{*2}$ is large — where the variable of interest has a lot of variation *not explained by controls* — receive the most weight.</span>
<span id="cb40-250"><a href="#cb40-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-253"><a href="#cb40-253" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-254"><a href="#cb40-254" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: regression-weights</span></span>
<span id="cb40-255"><a href="#cb40-255" aria-hidden="true" tabindex="-1"></a><span class="co"># Women's share in occupation: variable of interest</span></span>
<span id="cb40-256"><a href="#cb40-256" aria-hidden="true" tabindex="-1"></a><span class="co"># Controls: intercept, education, income</span></span>
<span id="cb40-257"><a href="#cb40-257" aria-hidden="true" tabindex="-1"></a>z_star <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(M1 <span class="sc">%*%</span> Prestige<span class="sc">$</span>women)  <span class="co"># M1 already built above</span></span>
<span id="cb40-258"><a href="#cb40-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-259"><a href="#cb40-259" aria-hidden="true" tabindex="-1"></a><span class="co"># Regression weights</span></span>
<span id="cb40-260"><a href="#cb40-260" aria-hidden="true" tabindex="-1"></a>omega <span class="ot">&lt;-</span> z_star<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb40-261"><a href="#cb40-261" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(omega) <span class="ot">&lt;-</span> <span class="fu">rownames</span>(Prestige)</span>
<span id="cb40-262"><a href="#cb40-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-263"><a href="#cb40-263" aria-hidden="true" tabindex="-1"></a><span class="co"># Most and least weighted occupations</span></span>
<span id="cb40-264"><a href="#cb40-264" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Highest weight (most variation in women% net of controls):</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb40-265"><a href="#cb40-265" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">sort</span>(omega, <span class="at">decreasing =</span> <span class="cn">TRUE</span>), <span class="dv">5</span>)</span>
<span id="cb40-266"><a href="#cb40-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-267"><a href="#cb40-267" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Lowest weight (almost no unique variation):</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb40-268"><a href="#cb40-268" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">sort</span>(omega), <span class="dv">5</span>)</span>
<span id="cb40-269"><a href="#cb40-269" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-270"><a href="#cb40-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-273"><a href="#cb40-273" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-274"><a href="#cb40-274" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: weights-verify</span></span>
<span id="cb40-275"><a href="#cb40-275" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify: weighted formula gives same coefficient as lm</span></span>
<span id="cb40-276"><a href="#cb40-276" aria-hidden="true" tabindex="-1"></a>b_weighted <span class="ot">&lt;-</span> <span class="fu">sum</span>(z_star <span class="sc">*</span> y) <span class="sc">/</span> <span class="fu">sum</span>(z_star<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb40-277"><a href="#cb40-277" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">weighted_formula =</span> b_weighted, <span class="at">lm =</span> <span class="fu">coef</span>(mod_full)[<span class="st">"women"</span>])</span>
<span id="cb40-278"><a href="#cb40-278" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-279"><a href="#cb40-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-280"><a href="#cb40-280" aria-hidden="true" tabindex="-1"></a>Occupations like general managers and ministers — where the share of women is very different from what education and income would predict — have thousands of times more influence on the coefficient than occupations where women's share is well-predicted by the controls.</span>
<span id="cb40-281"><a href="#cb40-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-282"><a href="#cb40-282" aria-hidden="true" tabindex="-1"></a><span class="fu">## Partial $R^2$</span></span>
<span id="cb40-283"><a href="#cb40-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-284"><a href="#cb40-284" aria-hidden="true" tabindex="-1"></a>The partial $R^2$ measures how much of the *remaining* variance in $Y$ (after accounting for $X_1$) is explained by $X_2$:</span>
<span id="cb40-285"><a href="#cb40-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-286"><a href="#cb40-286" aria-hidden="true" tabindex="-1"></a>$$R^2_{Y \sim X_2 | X_1} = 1 - \frac{\text{RSS}(X_1, X_2)}{\text{RSS}(X_1)} = \frac{\text{RSS}(X_1) - \text{RSS}(X_1, X_2)}{\text{RSS}(X_1)}$$ {#eq-partial-r2}</span>
<span id="cb40-287"><a href="#cb40-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-288"><a href="#cb40-288" aria-hidden="true" tabindex="-1"></a>For a single variable, the partial $R^2$ equals the squared partial correlation:</span>
<span id="cb40-289"><a href="#cb40-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-292"><a href="#cb40-292" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-293"><a href="#cb40-293" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: partial-r2</span></span>
<span id="cb40-294"><a href="#cb40-294" aria-hidden="true" tabindex="-1"></a><span class="co"># RSS from controls only</span></span>
<span id="cb40-295"><a href="#cb40-295" aria-hidden="true" tabindex="-1"></a>mod_controls <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige)</span>
<span id="cb40-296"><a href="#cb40-296" aria-hidden="true" tabindex="-1"></a>RSS_controls <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod_controls)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb40-297"><a href="#cb40-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-298"><a href="#cb40-298" aria-hidden="true" tabindex="-1"></a><span class="co"># RSS from full model</span></span>
<span id="cb40-299"><a href="#cb40-299" aria-hidden="true" tabindex="-1"></a>RSS_full <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod_full)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb40-300"><a href="#cb40-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-301"><a href="#cb40-301" aria-hidden="true" tabindex="-1"></a><span class="co"># Partial R^2 of education given (income, women)</span></span>
<span id="cb40-302"><a href="#cb40-302" aria-hidden="true" tabindex="-1"></a>partial_r2_educ <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> RSS_full <span class="sc">/</span> RSS_controls</span>
<span id="cb40-303"><a href="#cb40-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-304"><a href="#cb40-304" aria-hidden="true" tabindex="-1"></a><span class="co"># Equivalently: squared correlation of FWL residuals</span></span>
<span id="cb40-305"><a href="#cb40-305" aria-hidden="true" tabindex="-1"></a>cor_fwl <span class="ot">&lt;-</span> <span class="fu">cor</span>(e_y, e_educ)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb40-306"><a href="#cb40-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-307"><a href="#cb40-307" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">partial_R2 =</span> partial_r2_educ, <span class="at">squared_partial_cor =</span> cor_fwl)</span>
<span id="cb40-308"><a href="#cb40-308" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-309"><a href="#cb40-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-310"><a href="#cb40-310" aria-hidden="true" tabindex="-1"></a>We can also compute partial $R^2$ for each variable using the matrix formula. The FWL residuals give us everything we need:</span>
<span id="cb40-311"><a href="#cb40-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-314"><a href="#cb40-314" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-315"><a href="#cb40-315" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: partial-r2-all</span></span>
<span id="cb40-316"><a href="#cb40-316" aria-hidden="true" tabindex="-1"></a><span class="co"># Partial R^2 for each variable</span></span>
<span id="cb40-317"><a href="#cb40-317" aria-hidden="true" tabindex="-1"></a>partial_r2 <span class="ot">&lt;-</span> <span class="cf">function</span>(mod, var_name) {</span>
<span id="cb40-318"><a href="#cb40-318" aria-hidden="true" tabindex="-1"></a>  formula_reduced <span class="ot">&lt;-</span> <span class="fu">update</span>(<span class="fu">formula</span>(mod), <span class="fu">paste</span>(<span class="st">"~ . -"</span>, var_name))</span>
<span id="cb40-319"><a href="#cb40-319" aria-hidden="true" tabindex="-1"></a>  mod_reduced <span class="ot">&lt;-</span> <span class="fu">lm</span>(formula_reduced, <span class="at">data =</span> Prestige)</span>
<span id="cb40-320"><a href="#cb40-320" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span> <span class="sc">-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod_reduced)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb40-321"><a href="#cb40-321" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb40-322"><a href="#cb40-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-323"><a href="#cb40-323" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(</span>
<span id="cb40-324"><a href="#cb40-324" aria-hidden="true" tabindex="-1"></a>  <span class="at">variable =</span> <span class="fu">c</span>(<span class="st">"education"</span>, <span class="st">"income"</span>, <span class="st">"women"</span>),</span>
<span id="cb40-325"><a href="#cb40-325" aria-hidden="true" tabindex="-1"></a>  <span class="at">partial_R2 =</span> <span class="fu">sapply</span>(<span class="fu">c</span>(<span class="st">"education"</span>, <span class="st">"income"</span>, <span class="st">"women"</span>),</span>
<span id="cb40-326"><a href="#cb40-326" aria-hidden="true" tabindex="-1"></a>                       <span class="cf">function</span>(v) <span class="fu">partial_r2</span>(mod_full, v))</span>
<span id="cb40-327"><a href="#cb40-327" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-328"><a href="#cb40-328" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-329"><a href="#cb40-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-330"><a href="#cb40-330" aria-hidden="true" tabindex="-1"></a>Education has a high partial $R^2$ — it explains a large share of prestige variation that income and women's share cannot. Women's share has a very low partial $R^2$: once we know education and income, knowing the gender composition adds almost nothing.</span>
<span id="cb40-331"><a href="#cb40-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-332"><a href="#cb40-332" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sensitivity analysis: Cinelli-Hazlett (2020)</span></span>
<span id="cb40-333"><a href="#cb40-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-334"><a href="#cb40-334" aria-hidden="true" tabindex="-1"></a>Even after including controls, there may be *unobserved* confounders. The OVB formula from Chapter 2 says the bias from omitting a variable $Z$ is:</span>
<span id="cb40-335"><a href="#cb40-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-336"><a href="#cb40-336" aria-hidden="true" tabindex="-1"></a>$$\text{bias} = \underbrace{\frac{\text{Cov}(D, Z)}{\text{Var}(D)}}_{\text{imbalance}} \times \underbrace{\frac{\text{Cov}(Z^{\perp D}, Y^{\perp D})}{\text{Var}(Z^{\perp D})}}_{\text{impact}}$$</span>
<span id="cb40-337"><a href="#cb40-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-338"><a href="#cb40-338" aria-hidden="true" tabindex="-1"></a>Cinelli and Hazlett (2020) reparameterize this in terms of partial $R^2$ values, which are easier to reason about:</span>
<span id="cb40-339"><a href="#cb40-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-340"><a href="#cb40-340" aria-hidden="true" tabindex="-1"></a>$$|\text{bias}| \propto \sqrt{\frac{R^2_{D \sim Z} \cdot R^2_{Y \sim Z|D}}{1 - R^2_{D \sim Z}}}$$</span>
<span id="cb40-341"><a href="#cb40-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-342"><a href="#cb40-342" aria-hidden="true" tabindex="-1"></a>The key insight: a confounder must predict *both* treatment and outcome to generate meaningful bias. If either partial $R^2$ is small, the bias is small.</span>
<span id="cb40-343"><a href="#cb40-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-344"><a href="#cb40-344" aria-hidden="true" tabindex="-1"></a>Let's simulate and run a sensitivity analysis:</span>
<span id="cb40-345"><a href="#cb40-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-348"><a href="#cb40-348" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-349"><a href="#cb40-349" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: sensitivity-simulation</span></span>
<span id="cb40-350"><a href="#cb40-350" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb40-351"><a href="#cb40-351" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb40-352"><a href="#cb40-352" aria-hidden="true" tabindex="-1"></a>beta_D <span class="ot">&lt;-</span> <span class="dv">2</span>; beta_Z <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb40-353"><a href="#cb40-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-354"><a href="#cb40-354" aria-hidden="true" tabindex="-1"></a>D <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(N, <span class="dv">1</span>, <span class="fl">0.5</span>)</span>
<span id="cb40-355"><a href="#cb40-355" aria-hidden="true" tabindex="-1"></a>Z <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb40-356"><a href="#cb40-356" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> beta_D <span class="sc">*</span> D <span class="sc">+</span> beta_Z <span class="sc">*</span> Z <span class="sc">+</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb40-357"><a href="#cb40-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-358"><a href="#cb40-358" aria-hidden="true" tabindex="-1"></a><span class="co"># Naive model (omitting Z) -- biased</span></span>
<span id="cb40-359"><a href="#cb40-359" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(Y <span class="sc">~</span> D))</span>
<span id="cb40-360"><a href="#cb40-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-361"><a href="#cb40-361" aria-hidden="true" tabindex="-1"></a><span class="co"># Full model (including Z) -- unbiased</span></span>
<span id="cb40-362"><a href="#cb40-362" aria-hidden="true" tabindex="-1"></a>model_full_sim <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> D <span class="sc">+</span> Z)</span>
<span id="cb40-363"><a href="#cb40-363" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(model_full_sim)</span>
<span id="cb40-364"><a href="#cb40-364" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-365"><a href="#cb40-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-366"><a href="#cb40-366" aria-hidden="true" tabindex="-1"></a>The naive model overestimates the effect of $D$. The full model recovers $\beta_D \approx 2$. But what if there were *another* confounder we couldn't observe? We use the observed confounder $Z$ as a benchmark:</span>
<span id="cb40-367"><a href="#cb40-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-370"><a href="#cb40-370" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-371"><a href="#cb40-371" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: sensitivity-manual</span></span>
<span id="cb40-372"><a href="#cb40-372" aria-hidden="true" tabindex="-1"></a><span class="co"># How strong is Z as a confounder?</span></span>
<span id="cb40-373"><a href="#cb40-373" aria-hidden="true" tabindex="-1"></a><span class="co"># Partial R^2 of Z on D</span></span>
<span id="cb40-374"><a href="#cb40-374" aria-hidden="true" tabindex="-1"></a>partial_r2_DZ <span class="ot">&lt;-</span> <span class="fu">cor</span>(D, Z)<span class="sc">^</span><span class="dv">2</span>  <span class="co"># for a single variable, partial R^2 ≈ cor^2</span></span>
<span id="cb40-375"><a href="#cb40-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-376"><a href="#cb40-376" aria-hidden="true" tabindex="-1"></a><span class="co"># Partial R^2 of Z on Y|D</span></span>
<span id="cb40-377"><a href="#cb40-377" aria-hidden="true" tabindex="-1"></a>RSS_D_only <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(<span class="fu">lm</span>(Y <span class="sc">~</span> D))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb40-378"><a href="#cb40-378" aria-hidden="true" tabindex="-1"></a>RSS_full_sim <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(model_full_sim)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb40-379"><a href="#cb40-379" aria-hidden="true" tabindex="-1"></a>partial_r2_YZ_D <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> RSS_full_sim <span class="sc">/</span> RSS_D_only</span>
<span id="cb40-380"><a href="#cb40-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-381"><a href="#cb40-381" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">R2_D_Z =</span> partial_r2_DZ, <span class="at">R2_Y_Z_given_D =</span> partial_r2_YZ_D)</span>
<span id="cb40-382"><a href="#cb40-382" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-383"><a href="#cb40-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-384"><a href="#cb40-384" aria-hidden="true" tabindex="-1"></a>An unobserved confounder would need partial $R^2$ values at least this large with both $D$ and $Y$ to generate comparable bias. If the strongest observed predictor explains only a few percent of residual variation, an omitted variable would need to be far stronger to overturn the result.</span>
<span id="cb40-385"><a href="#cb40-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-388"><a href="#cb40-388" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-389"><a href="#cb40-389" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: sensemakr</span></span>
<span id="cb40-390"><a href="#cb40-390" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb40-391"><a href="#cb40-391" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb40-392"><a href="#cb40-392" aria-hidden="true" tabindex="-1"></a><span class="co"># The sensemakr package automates this analysis</span></span>
<span id="cb40-393"><a href="#cb40-393" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">requireNamespace</span>(<span class="st">"sensemakr"</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb40-394"><a href="#cb40-394" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(sensemakr)</span>
<span id="cb40-395"><a href="#cb40-395" aria-hidden="true" tabindex="-1"></a>  sens <span class="ot">&lt;-</span> <span class="fu">sensemakr</span>(model_full_sim, <span class="at">treatment =</span> <span class="st">"D"</span>,</span>
<span id="cb40-396"><a href="#cb40-396" aria-hidden="true" tabindex="-1"></a>                    <span class="at">benchmark_covariates =</span> <span class="st">"Z"</span>)</span>
<span id="cb40-397"><a href="#cb40-397" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>(sens)</span>
<span id="cb40-398"><a href="#cb40-398" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb40-399"><a href="#cb40-399" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-400"><a href="#cb40-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-401"><a href="#cb40-401" aria-hidden="true" tabindex="-1"></a>The **robustness value** tells us the minimum strength an unobserved confounder must have (in terms of partial $R^2$ with both $D$ and $Y$) to explain away the entire estimated effect.</span>
<span id="cb40-402"><a href="#cb40-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-403"><a href="#cb40-403" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb40-404"><a href="#cb40-404" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sensitivity Does Not Prove Robustness</span></span>
<span id="cb40-405"><a href="#cb40-405" aria-hidden="true" tabindex="-1"></a>A large robustness value means the result survives *hypothetical* confounders of a given strength — but it cannot rule out their existence. Sensitivity analysis quantifies what *would* be needed to overturn a finding; it does not establish that no such confounder exists.</span>
<span id="cb40-406"><a href="#cb40-406" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb40-407"><a href="#cb40-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-408"><a href="#cb40-408" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb40-409"><a href="#cb40-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-410"><a href="#cb40-410" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**FWL theorem**: The coefficient on $X_2$ in $y = X_1\beta_1 + X_2\beta_2 + e$ equals the coefficient from regressing $M_1 y$ on $M_1 X_2$ — residualize both sides against the controls.</span>
<span id="cb40-411"><a href="#cb40-411" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Partial regression plots** let us visualize multivariate relationships in 2D using FWL residuals.</span>
<span id="cb40-412"><a href="#cb40-412" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Leverage** $h_{ii} = X_i'(X'X)^{-1}X_i$ measures how unusual observation $i$'s covariates are. High leverage + large residual = influential observation.</span>
<span id="cb40-413"><a href="#cb40-413" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Leave-one-out residuals** $\tilde{e}_i = \hat{e}_i/(1-h_{ii})$ correct for the self-influence of observation $i$.</span>
<span id="cb40-414"><a href="#cb40-414" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Regression weights**: OLS implicitly weights observations by $z_i^{*2}$, the squared residual from regressing the variable of interest on controls. Observations with more unique variation in the treatment get more weight.</span>
<span id="cb40-415"><a href="#cb40-415" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Partial $R^2$** measures the share of residual variance explained by a variable after accounting for other regressors.</span>
<span id="cb40-416"><a href="#cb40-416" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Sensitivity analysis** (Cinelli-Hazlett): bias from an omitted confounder depends on its partial $R^2$ with both treatment and outcome. Use observed covariates as benchmarks.</span>
<span id="cb40-417"><a href="#cb40-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-418"><a href="#cb40-418" aria-hidden="true" tabindex="-1"></a>Next: <span class="co">[</span><span class="ot">Efficiency and GLS</span><span class="co">](ch05-gls.qmd)</span> — the Gauss-Markov theorem and generalized least squares.</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>