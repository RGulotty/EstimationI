<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>5. Efficiency and GLS – Estimation I: Computational Companion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8b4baf804e461d9b72633f0de59a0cac.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-3bbbbd466991e281563892c5dce73c3d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>
  MathJax = {
    tex: {
      macros: {
        E: "\\mathbb{E}",
        Var: "\\text{Var}",
        Cov: "\\text{Cov}",
        plim: "\\text{plim}",
        inprob: "\\xrightarrow{p}",
        indist: "\\xrightarrow{d}",
        bhat: "\\hat{\\boldsymbol{\\beta}}",
        N: "\\mathcal{N}",
        tr: "\\text{tr}",
        rank: "\\text{rank}",
        SE: "\\text{SE}",
        diag: "\\text{diag}"
      }
    }
  };
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Estimation I: Computational Companion</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-chapters" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Chapters</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-chapters">    
        <li>
    <a class="dropdown-item" href="./ch01-review.html">
 <span class="dropdown-text">1. Probability and Linear Algebra</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch02-cef-blp.html">
 <span class="dropdown-text">2. The CEF and Best Linear Predictor</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch03-ols.html">
 <span class="dropdown-text">3. Multivariate OLS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch04-sensitivity.html">
 <span class="dropdown-text">4. Sensitivity and Leverage</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch05-gls.html">
 <span class="dropdown-text">5. Efficiency and GLS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch06-small-sample.html">
 <span class="dropdown-text">6. Small Sample Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch07-probit.html">
 <span class="dropdown-text">7. Probit and MLE</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch08-asymptotics.html">
 <span class="dropdown-text">8. Asymptotics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch09-testing.html">
 <span class="dropdown-text">9. Hypothesis Testing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch10-iv.html">
 <span class="dropdown-text">10. Instrumental Variables and 2SLS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch11-gmm.html">
 <span class="dropdown-text">11. GMM</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch12-panel.html">
 <span class="dropdown-text">12. Panel Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ch13-fixed-effects.html">
 <span class="dropdown-text">13. Fixed Effects and Modern DiD</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/UChicago-pol-methods/EstimationI"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-sandwich" id="toc-sec-sandwich" class="nav-link active" data-scroll-target="#sec-sandwich"><span class="header-section-number">1</span> The variance of OLS under non-spherical errors</a>
  <ul class="collapse">
  <li><a href="#simulation-when-classical-standard-errors-lie" id="toc-simulation-when-classical-standard-errors-lie" class="nav-link" data-scroll-target="#simulation-when-classical-standard-errors-lie"><span class="header-section-number">1.1</span> Simulation: when classical standard errors lie</a></li>
  <li><a href="#monte-carlo-coverage-of-classical-vs.-robust-intervals" id="toc-monte-carlo-coverage-of-classical-vs.-robust-intervals" class="nav-link" data-scroll-target="#monte-carlo-coverage-of-classical-vs.-robust-intervals"><span class="header-section-number">1.2</span> Monte Carlo: coverage of classical vs.&nbsp;robust intervals</a></li>
  <li><a href="#lm_robust-vs.-coeftest-two-workflows" id="toc-lm_robust-vs.-coeftest-two-workflows" class="nav-link" data-scroll-target="#lm_robust-vs.-coeftest-two-workflows"><span class="header-section-number">1.3</span> <code>lm_robust</code> vs.&nbsp;<code>coeftest</code>: two workflows</a></li>
  </ul></li>
  <li><a href="#weighted-least-squares" id="toc-weighted-least-squares" class="nav-link" data-scroll-target="#weighted-least-squares"><span class="header-section-number">2</span> Weighted least squares</a>
  <ul class="collapse">
  <li><a href="#the-idea-weight-by-precision" id="toc-the-idea-weight-by-precision" class="nav-link" data-scroll-target="#the-idea-weight-by-precision"><span class="header-section-number">2.1</span> The idea: weight by precision</a></li>
  <li><a href="#two-group-example" id="toc-two-group-example" class="nav-link" data-scroll-target="#two-group-example"><span class="header-section-number">2.2</span> Two-group example</a></li>
  <li><a href="#wls-in-r-lm...-weights" id="toc-wls-in-r-lm...-weights" class="nav-link" data-scroll-target="#wls-in-r-lm...-weights"><span class="header-section-number">2.3</span> WLS in R: <code>lm(..., weights = )</code></a></li>
  <li><a href="#wls-as-a-transformed-regression" id="toc-wls-as-a-transformed-regression" class="nav-link" data-scroll-target="#wls-as-a-transformed-regression"><span class="header-section-number">2.4</span> WLS as a transformed regression</a></li>
  </ul></li>
  <li><a href="#sec-gls" id="toc-sec-gls" class="nav-link" data-scroll-target="#sec-gls"><span class="header-section-number">3</span> GLS: The general transformation</a>
  <ul class="collapse">
  <li><a href="#eigendecomposition-of-omega" id="toc-eigendecomposition-of-omega" class="nav-link" data-scroll-target="#eigendecomposition-of-omega"><span class="header-section-number">3.1</span> Eigendecomposition of <span class="math inline">\(\Omega\)</span></a></li>
  <li><a href="#gls-formula" id="toc-gls-formula" class="nav-link" data-scroll-target="#gls-formula"><span class="header-section-number">3.2</span> GLS formula</a></li>
  <li><a href="#simulation-gls-with-correlated-errors" id="toc-simulation-gls-with-correlated-errors" class="nav-link" data-scroll-target="#simulation-gls-with-correlated-errors"><span class="header-section-number">3.3</span> Simulation: GLS with correlated errors</a></li>
  <li><a href="#the-gls-projection-matrix" id="toc-the-gls-projection-matrix" class="nav-link" data-scroll-target="#the-gls-projection-matrix"><span class="header-section-number">3.4</span> The GLS projection matrix</a></li>
  </ul></li>
  <li><a href="#feasible-gls" id="toc-feasible-gls" class="nav-link" data-scroll-target="#feasible-gls"><span class="header-section-number">4</span> Feasible GLS</a>
  <ul class="collapse">
  <li><a href="#step-by-step-fgls-for-heteroskedasticity" id="toc-step-by-step-fgls-for-heteroskedasticity" class="nav-link" data-scroll-target="#step-by-step-fgls-for-heteroskedasticity"><span class="header-section-number">4.1</span> Step-by-step FGLS for heteroskedasticity</a></li>
  <li><a href="#implementing-fgls-with-matrix-algebra" id="toc-implementing-fgls-with-matrix-algebra" class="nav-link" data-scroll-target="#implementing-fgls-with-matrix-algebra"><span class="header-section-number">4.2</span> Implementing FGLS with matrix algebra</a></li>
  <li><a href="#how-well-does-fgls-estimate-the-variance-function" id="toc-how-well-does-fgls-estimate-the-variance-function" class="nav-link" data-scroll-target="#how-well-does-fgls-estimate-the-variance-function"><span class="header-section-number">4.3</span> How well does FGLS estimate the variance function?</a></li>
  <li><a href="#monte-carlo-ols-vs.-fgls-efficiency" id="toc-monte-carlo-ols-vs.-fgls-efficiency" class="nav-link" data-scroll-target="#monte-carlo-ols-vs.-fgls-efficiency"><span class="header-section-number">4.4</span> Monte Carlo: OLS vs.&nbsp;FGLS efficiency</a></li>
  </ul></li>
  <li><a href="#two-strategies-for-heteroskedasticity" id="toc-two-strategies-for-heteroskedasticity" class="nav-link" data-scroll-target="#two-strategies-for-heteroskedasticity"><span class="header-section-number">5</span> Two strategies for heteroskedasticity</a>
  <ul class="collapse">
  <li><a href="#the-breusch-pagan-test-for-understanding-not-for-pre-testing" id="toc-the-breusch-pagan-test-for-understanding-not-for-pre-testing" class="nav-link" data-scroll-target="#the-breusch-pagan-test-for-understanding-not-for-pre-testing"><span class="header-section-number">5.1</span> The Breusch-Pagan test (for understanding, not for pre-testing)</a></li>
  </ul></li>
  <li><a href="#residual-types" id="toc-residual-types" class="nav-link" data-scroll-target="#residual-types"><span class="header-section-number">6</span> Residual types</a>
  <ul class="collapse">
  <li><a href="#the-matrices" id="toc-the-matrices" class="nav-link" data-scroll-target="#the-matrices"><span class="header-section-number">6.1</span> The matrices</a></li>
  <li><a href="#raw-residuals-hate-me" id="toc-raw-residuals-hate-me" class="nav-link" data-scroll-target="#raw-residuals-hate-me"><span class="header-section-number">6.2</span> Raw residuals: <span class="math inline">\(\hat{e} = Me\)</span></a></li>
  <li><a href="#prediction-errors-tildee-m-hate-m-m-e" id="toc-prediction-errors-tildee-m-hate-m-m-e" class="nav-link" data-scroll-target="#prediction-errors-tildee-m-hate-m-m-e"><span class="header-section-number">6.3</span> Prediction errors: <span class="math inline">\(\tilde{e} = M^* \hat{e} = M^* M e\)</span></a></li>
  <li><a href="#standardized-residuals-bare-m12-hate-hatsigma" id="toc-standardized-residuals-bare-m12-hate-hatsigma" class="nav-link" data-scroll-target="#standardized-residuals-bare-m12-hate-hatsigma"><span class="header-section-number">6.4</span> Standardized residuals: <span class="math inline">\(\bar{e} = (M^*)^{1/2} \hat{e} / \hat{\sigma}\)</span></a></li>
  <li><a href="#comparing-the-three-types" id="toc-comparing-the-three-types" class="nav-link" data-scroll-target="#comparing-the-three-types"><span class="header-section-number">6.5</span> Comparing the three types</a></li>
  </ul></li>
  <li><a href="#estimating-sigma2" id="toc-estimating-sigma2" class="nav-link" data-scroll-target="#estimating-sigma2"><span class="header-section-number">7</span> Estimating <span class="math inline">\(\sigma^2\)</span></a></li>
  <li><a href="#method-of-moments-perspective" id="toc-method-of-moments-perspective" class="nav-link" data-scroll-target="#method-of-moments-perspective"><span class="header-section-number">8</span> Method of moments perspective</a>
  <ul class="collapse">
  <li><a href="#ols-as-a-method-of-moments-estimator" id="toc-ols-as-a-method-of-moments-estimator" class="nav-link" data-scroll-target="#ols-as-a-method-of-moments-estimator"><span class="header-section-number">8.1</span> OLS as a method of moments estimator</a></li>
  <li><a href="#gls-as-efficient-method-of-moments" id="toc-gls-as-efficient-method-of-moments" class="nav-link" data-scroll-target="#gls-as-efficient-method-of-moments"><span class="header-section-number">8.2</span> GLS as efficient method of moments</a></li>
  </ul></li>
  <li><a href="#application-robust-inference-on-the-prestige-data" id="toc-application-robust-inference-on-the-prestige-data" class="nav-link" data-scroll-target="#application-robust-inference-on-the-prestige-data"><span class="header-section-number">9</span> Application: robust inference on the Prestige data</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">10</span> Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">5. Efficiency and GLS</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<p class="subtitle lead">Weighted least squares, feasible GLS, and the method of moments</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>When error variances differ across observations, OLS is still unbiased but no longer efficient. This chapter develops WLS and GLS as the natural response: weight observations by their precision. We build everything from matrix algebra, connect the estimator to the method of moments, and implement feasible GLS when the variance structure must be estimated from data. Along the way we introduce the <code>sandwich</code> and <code>estimatr</code> packages — the practical tools for robust inference in R.</p>
<p><strong>Questions this chapter answers:</strong></p>
<ol type="1">
<li>Why are classical standard errors wrong under heteroskedasticity, and what does the sandwich formula fix?</li>
<li>How do WLS and GLS improve efficiency by weighting observations by their precision?</li>
<li>When should you use FGLS vs.&nbsp;simply reporting robust standard errors?</li>
<li>What is the connection between HC0/HC1/HC2 and the leverage-corrected residual types?</li>
</ol>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sandwich)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(estimatr)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(carData)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Prestige)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>tr <span class="ot">&lt;-</span> <span class="cf">function</span>(M) <span class="fu">sum</span>(<span class="fu">diag</span>(M))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<section id="sec-sandwich" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-sandwich"><span class="header-section-number">1</span> The variance of OLS under non-spherical errors</h2>
<p>Recall the <a href="./ch03-ols.html#eq-ols">OLS estimator</a>: <span class="math inline">\(\hat{\beta} = \beta + (X'X)^{-1}X'e\)</span>. The variance is:</p>
<p><span class="math display">\[\text{Var}[\hat{\beta} \mid X] = (X'X)^{-1} X' \text{Var}[e \mid X] \, X (X'X)^{-1}\]</span></p>
<p>Under <strong>homoskedasticity</strong> (<span class="math inline">\(\text{Var}[e \mid X] = \sigma^2 I\)</span>), this simplifies to <span class="math inline">\(\sigma^2(X'X)^{-1}\)</span>. But when <span class="math inline">\(\text{Var}[e \mid X] = \Omega \neq \sigma^2 I\)</span>, we get the <strong>sandwich formula</strong>:</p>
<p><span id="eq-sandwich"><span class="math display">\[(X'X)^{-1} (X' \Omega X) (X'X)^{-1} \tag{1}\]</span></span></p>
<p>The “bread” is <span class="math inline">\((X'X)^{-1}\)</span> and the “meat” is <span class="math inline">\(X'\Omega X = \sum_{i=1}^n \sigma_i^2 x_i x_i'\)</span>. Let’s see what happens when we ignore heteroskedasticity and use the classical formula anyway.</p>
<div id="def-sandwich" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 (Sandwich Variance Estimator)</strong></span> Under heteroskedasticity (<span class="math inline">\(\text{Var}[e|X] = \Omega \neq \sigma^2 I\)</span>), the variance of OLS is <span class="math inline">\((X'X)^{-1}(X'\Omega X)(X'X)^{-1}\)</span>. The HC estimators replace <span class="math inline">\(\Omega\)</span> with diagonal matrices of squared residuals, possibly adjusted for leverage.</p>
</div>
<section id="simulation-when-classical-standard-errors-lie" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="simulation-when-classical-standard-errors-lie"><span class="header-section-number">1.1</span> Simulation: when classical standard errors lie</h3>
<p>We design a DGP with strong heteroskedasticity: the error standard deviation grows as <span class="math inline">\(x^2\)</span>, so variance ranges from 1 (at <span class="math inline">\(x = 1\)</span>) to 10,000 (at <span class="math inline">\(x = 10\)</span>). This makes the problem impossible to miss.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Strongly heteroskedastic DGP: SD = x^2</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>sigma_i <span class="ot">&lt;-</span> x<span class="sc">^</span><span class="dv">2</span>   <span class="co"># variance = x^4, ratio of 10000:1</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, sigma_i)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>First, let’s build the sandwich by hand to see the matrix algebra:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Classical variance: s^2 * (X'X)^{-1}</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>s2 <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> (n <span class="sc">-</span> <span class="dv">2</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>V_classical <span class="ot">&lt;-</span> s2 <span class="sc">*</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Sandwich variance (HC0): (X'X)^{-1} X' diag(e^2) X (X'X)^{-1}</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>e_hat <span class="ot">&lt;-</span> <span class="fu">resid</span>(mod)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>bread <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X))</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>meat <span class="ot">&lt;-</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> <span class="fu">diag</span>(e_hat<span class="sc">^</span><span class="dv">2</span>) <span class="sc">%*%</span> X</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>V_HC0 <span class="ot">&lt;-</span> bread <span class="sc">%*%</span> meat <span class="sc">%*%</span> bread</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare standard errors for the slope</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">classical =</span> <span class="fu">sqrt</span>(V_classical[<span class="dv">2</span>, <span class="dv">2</span>]),</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC0       =</span> <span class="fu">sqrt</span>(V_HC0[<span class="dv">2</span>, <span class="dv">2</span>]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>classical       HC0 
     1.31      1.48 </code></pre>
</div>
</div>
<p>Now the practical way — <code>sandwich::vcovHC()</code> computes this in one line:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># HC0 (White's original)</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC0"</span>)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)           x 
       5.48        1.48 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># HC1 (small-sample correction: multiply by n/(n-k))</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC1"</span>)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)           x 
       5.51        1.49 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># HC2 (recommended default — adjusts for leverage)</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC2"</span>)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)           x 
       5.52        1.49 </code></pre>
</div>
</div>
<p>Or even simpler — <code>estimatr::lm_robust()</code> fits the model and computes robust SEs in one step:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>mod_robust <span class="ot">&lt;-</span> <span class="fu">lm_robust</span>(y <span class="sc">~</span> x, <span class="at">se_type =</span> <span class="st">"HC2"</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_robust)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm_robust(formula = y ~ x, se_type = "HC2")

Standard error type:  HC2 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper  DF
(Intercept)     4.07       5.52   0.737    0.462   -6.816    14.95 198
x               2.30       1.49   1.540    0.125   -0.644     5.24 198

Multiple R-squared:  0.0154 ,   Adjusted R-squared:  0.0104 
F-statistic: 2.37 on 1 and 198 DF,  p-value: 0.125</code></pre>
</div>
</div>
<p>Compare the standard errors side by side:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>se_table <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">Classical =</span> <span class="fu">summary</span>(mod)<span class="sc">$</span>coefficients[, <span class="dv">2</span>],</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC0 =</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC0"</span>))),</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC1 =</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC1"</span>))),</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC2 =</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC2"</span>))),</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">row.names =</span> <span class="fu">c</span>(<span class="st">"(Intercept)"</span>, <span class="st">"x"</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(se_table, <span class="dv">3</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Classical  HC0  HC1  HC2
(Intercept)      8.20 5.48 5.51 5.52
x                1.31 1.48 1.49 1.49</code></pre>
</div>
</div>
<p>The classical SE for the slope is far too small — it ignores that the high-<span class="math inline">\(x\)</span> observations (which pull the slope) are exactly the noisiest ones.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Classical Standard Errors Can Be Dangerously Wrong
</div>
</div>
<div class="callout-body-container callout-body">
<p>Under heteroskedasticity, classical SEs can be too small by a factor of 2 or more, producing confidence intervals with far below nominal coverage. Always use robust SEs (HC2) as the default for cross-sectional data.</p>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">residual =</span> <span class="fu">resid</span>(mod))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(x, residual)) <span class="sc">+</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Residuals fan out dramatically with x"</span>,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"SD grows as x², so variance ratio is 10000:1"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch05-gls_files/figure-html/heteroskedasticity-visual-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="monte-carlo-coverage-of-classical-vs.-robust-intervals" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="monte-carlo-coverage-of-classical-vs.-robust-intervals"><span class="header-section-number">1.2</span> Monte Carlo: coverage of classical vs.&nbsp;robust intervals</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">2000</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>cover_classical <span class="ot">&lt;-</span> cover_HC0 <span class="ot">&lt;-</span> cover_HC2 <span class="ot">&lt;-</span> <span class="fu">logical</span>(B)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>beta_true <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  x_sim <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  X_sim <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x_sim)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>  sigma_sim <span class="ot">&lt;-</span> x_sim<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>  y_sim <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> beta_true <span class="sc">*</span> x_sim <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, sigma_sim)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_sim <span class="sc">~</span> x_sim)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>  b_hat <span class="ot">&lt;-</span> <span class="fu">coef</span>(fit)[<span class="dv">2</span>]</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Classical CI</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>  se_class <span class="ot">&lt;-</span> <span class="fu">summary</span>(fit)<span class="sc">$</span>coefficients[<span class="dv">2</span>, <span class="dv">2</span>]</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>  ci_class <span class="ot">&lt;-</span> b_hat <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fl">1.96</span> <span class="sc">*</span> se_class</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>  cover_classical[b] <span class="ot">&lt;-</span> ci_class[<span class="dv">1</span>] <span class="sc">&lt;</span> beta_true <span class="sc">&amp;</span> beta_true <span class="sc">&lt;</span> ci_class[<span class="dv">2</span>]</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># HC0 (White)</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>  se_hc0 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">vcovHC</span>(fit, <span class="at">type =</span> <span class="st">"HC0"</span>)[<span class="dv">2</span>, <span class="dv">2</span>])</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>  ci_hc0 <span class="ot">&lt;-</span> b_hat <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fl">1.96</span> <span class="sc">*</span> se_hc0</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>  cover_HC0[b] <span class="ot">&lt;-</span> ci_hc0[<span class="dv">1</span>] <span class="sc">&lt;</span> beta_true <span class="sc">&amp;</span> beta_true <span class="sc">&lt;</span> ci_hc0[<span class="dv">2</span>]</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># HC2 (recommended)</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>  se_hc2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">vcovHC</span>(fit, <span class="at">type =</span> <span class="st">"HC2"</span>)[<span class="dv">2</span>, <span class="dv">2</span>])</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>  ci_hc2 <span class="ot">&lt;-</span> b_hat <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fl">1.96</span> <span class="sc">*</span> se_hc2</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>  cover_HC2[b] <span class="ot">&lt;-</span> ci_hc2[<span class="dv">1</span>] <span class="sc">&lt;</span> beta_true <span class="sc">&amp;</span> beta_true <span class="sc">&lt;</span> ci_hc2[<span class="dv">2</span>]</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">classical =</span> <span class="fu">mean</span>(cover_classical),</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC0       =</span> <span class="fu">mean</span>(cover_HC0),</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC2       =</span> <span class="fu">mean</span>(cover_HC2))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>classical       HC0       HC2 
    0.894     0.953     0.954 </code></pre>
</div>
</div>
<p>Classical intervals have terrible coverage. HC0 does better. HC2 gets closest to the nominal 95% because it corrects for leverage — observations with high <span class="math inline">\(x\)</span> values both have high variance <em>and</em> high leverage. (Chapter 6 develops the HC variants in detail.)</p>
</section>
<section id="lm_robust-vs.-coeftest-two-workflows" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="lm_robust-vs.-coeftest-two-workflows"><span class="header-section-number">1.3</span> <code>lm_robust</code> vs.&nbsp;<code>coeftest</code>: two workflows</h3>
<p>In practice, there are two ways to get robust inference. Use whichever fits your workflow:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Workflow 1: estimatr — one function does everything</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>mod_r <span class="ot">&lt;-</span> <span class="fu">lm_robust</span>(y <span class="sc">~</span> x, <span class="at">se_type =</span> <span class="st">"HC2"</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(mod_r))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper  DF
(Intercept)     4.07       5.52   0.737    0.462   -6.816    14.95 198
x               2.30       1.49   1.540    0.125   -0.644     5.24 198</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Workflow 2: sandwich + lmtest — post-hoc correction to a fitted lm</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(mod, <span class="at">vcov =</span> <span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC2"</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
t test of coefficients:

            Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)     4.07       5.52    0.74     0.46
x               2.30       1.49    1.54     0.13</code></pre>
</div>
</div>
<p>The <code>coeftest()</code> approach is useful when you’ve already fit a model with <code>lm()</code> and want to report robust SEs. <code>lm_robust()</code> is cleaner when you know from the start that you want robust inference.</p>
</section>
</section>
<section id="weighted-least-squares" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="weighted-least-squares"><span class="header-section-number">2</span> Weighted least squares</h2>
<p>The sandwich formula tells us what the variance <em>is</em>. But can we do better than OLS? Yes — if we know (or can estimate) the variance structure, we should exploit it.</p>
<section id="the-idea-weight-by-precision" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="the-idea-weight-by-precision"><span class="header-section-number">2.1</span> The idea: weight by precision</h3>
<p>If observation <span class="math inline">\(i\)</span> has variance <span class="math inline">\(\sigma_i^2\)</span>, it carries less information than an observation with variance <span class="math inline">\(\sigma_j^2 &lt; \sigma_i^2\)</span>. WLS weights each observation by <span class="math inline">\(w_i = 1/\sigma_i^2\)</span>, downweighting noisy observations:</p>
<p><span id="eq-wls"><span class="math display">\[\hat{\beta}_{WLS} = \arg\min_\beta \sum_{i=1}^n w_i (y_i - x_i'\beta)^2 = (X'WX)^{-1} X'Wy \tag{2}\]</span></span></p>
<p>where <span class="math inline">\(W = \text{diag}(w_1, \ldots, w_n)\)</span>.</p>
</section>
<section id="two-group-example" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="two-group-example"><span class="header-section-number">2.2</span> Two-group example</h3>
<p>Suppose we survey two groups: Group A (<span class="math inline">\(n_A = 100\)</span>, <span class="math inline">\(\sigma_A = 10\)</span>) and Group B (<span class="math inline">\(n_B = 100\)</span>, <span class="math inline">\(\sigma_B = 1\)</span>). OLS gives equal weight to every observation. WLS gives Group A weight <span class="math inline">\(1/100\)</span> and Group B weight <span class="math inline">\(1\)</span>.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">99</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">5000</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>b_ols <span class="ot">&lt;-</span> b_wls <span class="ot">&lt;-</span> <span class="fu">numeric</span>(B)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  x_sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>  sigma_sim <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">10</span>, <span class="dv">100</span>), <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">100</span>))</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>  y_sim <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> x_sim <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">200</span>, <span class="dv">0</span>, sigma_sim)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>  b_ols[i] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y_sim <span class="sc">~</span> x_sim))[<span class="dv">2</span>]</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>  b_wls[i] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y_sim <span class="sc">~</span> x_sim, <span class="at">weights =</span> <span class="dv">1</span> <span class="sc">/</span> sigma_sim<span class="sc">^</span><span class="dv">2</span>))[<span class="dv">2</span>]</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Both unbiased, but WLS has much lower variance</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">bias_ols =</span> <span class="fu">mean</span>(b_ols) <span class="sc">-</span> <span class="dv">2</span>, <span class="at">bias_wls =</span> <span class="fu">mean</span>(b_wls) <span class="sc">-</span> <span class="dv">2</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>bias_ols bias_wls 
-0.00434 -0.00125 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">sd_ols =</span> <span class="fu">sd</span>(b_ols), <span class="at">sd_wls =</span> <span class="fu">sd</span>(b_wls))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>sd_ols sd_wls 
 0.507  0.103 </code></pre>
</div>
</div>
<p>Both estimators are unbiased, but WLS standard errors are dramatically smaller. GLS is just common sense: trust precise observations more.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>df_sim <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> <span class="fu">c</span>(b_ols, b_wls),</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"OLS"</span>, <span class="st">"WLS"</span>), <span class="at">each =</span> B)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_sim, <span class="fu">aes</span>(estimate, <span class="at">fill =</span> method)) <span class="sc">+</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"OLS vs. WLS sampling distributions"</span>,</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Both centered on truth, but WLS is much tighter"</span>,</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="fu">expression</span>(<span class="fu">hat</span>(beta)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch05-gls_files/figure-html/two-group-density-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>OLS vs.&nbsp;WLS sampling distributions: both unbiased, but WLS is tighter</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="wls-in-r-lm...-weights" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="wls-in-r-lm...-weights"><span class="header-section-number">2.3</span> WLS in R: <code>lm(..., weights = )</code></h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>mod_ols <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Suppose we know variance is proportional to income</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># (higher-income occupations have more variable prestige)</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> Prestige<span class="sc">$</span>income</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>mod_wls <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige, <span class="at">weights =</span> w)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare coefficients</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">OLS =</span> <span class="fu">coef</span>(mod_ols), <span class="at">WLS =</span> <span class="fu">coef</span>(mod_wls))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 OLS      WLS
(Intercept) -6.79433 -9.97061
education    4.18664  3.18162
income       0.00131  0.00303
women       -0.00891  0.07049</code></pre>
</div>
</div>
</section>
<section id="wls-as-a-transformed-regression" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="wls-as-a-transformed-regression"><span class="header-section-number">2.4</span> WLS as a transformed regression</h3>
<p>WLS is equivalent to pre-multiplying the model by <span class="math inline">\(W^{1/2}\)</span>:</p>
<p><span class="math display">\[W^{1/2} y = W^{1/2} X \beta + W^{1/2} e\]</span></p>
<p>The transformed errors have variance <span class="math inline">\(W^{1/2} \Omega W^{1/2} = I\)</span> (if <span class="math inline">\(W = \Omega^{-1}\)</span>), so OLS on the transformed data is efficient. Let’s verify:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Manual transformation</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>W_half <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="fu">sqrt</span>(w))</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>y_tilde <span class="ot">&lt;-</span> W_half <span class="sc">%*%</span> Prestige<span class="sc">$</span>prestige</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>X_raw <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, Prestige<span class="sc">$</span>education, Prestige<span class="sc">$</span>income, Prestige<span class="sc">$</span>women)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>X_tilde <span class="ot">&lt;-</span> W_half <span class="sc">%*%</span> X_raw</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS on transformed data</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>beta_transformed <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X_tilde)) <span class="sc">%*%</span> <span class="fu">crossprod</span>(X_tilde, y_tilde)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare to lm(..., weights = )</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.numeric</span>(beta_transformed), <span class="fu">as.numeric</span>(<span class="fu">coef</span>(mod_wls)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
<p>The transformation approach makes clear what <code>weights</code> does: it rescales each observation so that the transformed errors are homoskedastic.</p>
<p><strong>Important note on the intercept.</strong> After transformation, the column of ones becomes <span class="math inline">\(W^{1/2} \mathbf{1} = (\sqrt{w_1}, \ldots, \sqrt{w_n})'\)</span>, which is no longer constant. If you run the transformed regression manually, you must suppress the automatic intercept and include the transformed constant as a regressor:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformed data</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>df_t <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">as.numeric</span>(y_tilde),</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">const =</span> <span class="fu">as.numeric</span>(W_half <span class="sc">%*%</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">nrow</span>(Prestige))),</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">education =</span> <span class="fu">as.numeric</span>(W_half <span class="sc">%*%</span> Prestige<span class="sc">$</span>education),</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">income =</span> <span class="fu">as.numeric</span>(W_half <span class="sc">%*%</span> Prestige<span class="sc">$</span>income),</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">women =</span> <span class="fu">as.numeric</span>(W_half <span class="sc">%*%</span> Prestige<span class="sc">$</span>women)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="co"># -1 suppresses R's intercept; 'const' is the transformed intercept</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>mod_manual <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> const <span class="sc">+</span> education <span class="sc">+</span> income <span class="sc">+</span> women <span class="sc">-</span> <span class="dv">1</span>, <span class="at">data =</span> df_t)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.numeric</span>(<span class="fu">coef</span>(mod_manual)), <span class="fu">as.numeric</span>(<span class="fu">coef</span>(mod_wls)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
</section>
</section>
<section id="sec-gls" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="sec-gls"><span class="header-section-number">3</span> GLS: The general transformation</h2>
<p>WLS handles the case where <span class="math inline">\(\Omega\)</span> is diagonal (heteroskedasticity only). GLS handles the general case where errors may also be correlated. The key idea is the same: find a transformation <span class="math inline">\(\Omega^{-1/2}\)</span> that sphericizes the errors.</p>
<section id="eigendecomposition-of-omega" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="eigendecomposition-of-omega"><span class="header-section-number">3.1</span> Eigendecomposition of <span class="math inline">\(\Omega\)</span></h3>
<p>Any positive definite symmetric matrix can be factored as <span class="math inline">\(\Omega = C \Lambda C'\)</span>, where <span class="math inline">\(C\)</span> is the matrix of eigenvectors and <span class="math inline">\(\Lambda\)</span> is diagonal with eigenvalues. Then:</p>
<p><span class="math display">\[\Omega^{-1/2} = C \Lambda^{-1/2} C'\]</span></p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># A small example: 4x4 covariance matrix with correlation</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>n_small <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.6</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>Omega_small <span class="ot">&lt;-</span> rho<span class="sc">^</span><span class="fu">abs</span>(<span class="fu">outer</span>(<span class="dv">1</span><span class="sc">:</span>n_small, <span class="dv">1</span><span class="sc">:</span>n_small, <span class="st">"-"</span>))  <span class="co"># AR(1) structure</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>Omega_small</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1] [,2] [,3]  [,4]
[1,] 1.000 0.60 0.36 0.216
[2,] 0.600 1.00 0.60 0.360
[3,] 0.360 0.60 1.00 0.600
[4,] 0.216 0.36 0.60 1.000</code></pre>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>eig <span class="ot">&lt;-</span> <span class="fu">eigen</span>(Omega_small)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>C <span class="ot">&lt;-</span> eig<span class="sc">$</span>vectors</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>Lambda <span class="ot">&lt;-</span> <span class="fu">diag</span>(eig<span class="sc">$</span>values)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Omega^{-1/2}</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>Omega_inv_half <span class="ot">&lt;-</span> C <span class="sc">%*%</span> <span class="fu">diag</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">sqrt</span>(eig<span class="sc">$</span>values)) <span class="sc">%*%</span> <span class="fu">t</span>(C)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify: Omega^{-1/2} Omega Omega^{-1/2} = I</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(Omega_inv_half <span class="sc">%*%</span> Omega_small <span class="sc">%*%</span> Omega_inv_half, <span class="fu">diag</span>(n_small),</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>          <span class="at">check.attributes =</span> <span class="cn">FALSE</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
</section>
<section id="gls-formula" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="gls-formula"><span class="header-section-number">3.2</span> GLS formula</h3>
<p>The GLS estimator pre-multiplies by <span class="math inline">\(\Omega^{-1/2}\)</span>, then applies OLS:</p>
<p><span id="eq-gls"><span class="math display">\[\hat{\beta}_{GLS} = (X'\Omega^{-1}X)^{-1} X'\Omega^{-1}y \tag{3}\]</span></span></p>
<p>Its variance is <span class="math inline">\(\sigma^2(X'\Omega^{-1}X)^{-1}\)</span>, which is the efficiency lower bound — no other linear unbiased estimator can do better.</p>
<div id="thm-gls" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (GLS Estimator)</strong></span> The GLS estimator <span class="math inline">\(\hat\beta_{GLS} = (X'\Omega^{-1}X)^{-1}X'\Omega^{-1}y\)</span> is the best linear unbiased estimator (BLUE) when <span class="math inline">\(\text{Var}[e|X] = \sigma^2\Omega\)</span>. Its variance <span class="math inline">\(\sigma^2(X'\Omega^{-1}X)^{-1}\)</span> achieves the efficiency lower bound among linear unbiased estimators.</p>
</div>
<div id="thm-gauss-markov" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2 (Gauss-Markov Theorem)</strong></span> Under the assumptions <span class="math inline">\(\mathbb{E}[e|X] = 0\)</span> and <span class="math inline">\(\text{Var}[e|X] = \sigma^2 I\)</span> (homoskedasticity), OLS is BLUE — the Best Linear Unbiased Estimator. No other linear unbiased estimator has smaller variance. When homoskedasticity fails, GLS replaces OLS as BLUE.</p>
</div>
</section>
<section id="simulation-gls-with-correlated-errors" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="simulation-gls-with-correlated-errors"><span class="header-section-number">3.3</span> Simulation: GLS with correlated errors</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">7</span>)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">80</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.8</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="co"># AR(1) correlation matrix</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>Omega <span class="ot">&lt;-</span> rho<span class="sc">^</span><span class="fu">abs</span>(<span class="fu">outer</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="dv">1</span><span class="sc">:</span>n, <span class="st">"-"</span>))</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>Omega_inv <span class="ot">&lt;-</span> <span class="fu">solve</span>(Omega)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Cholesky factor for generating correlated errors</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>L <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">chol</span>(Omega))</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="fu">runif</span>(n, <span class="dv">0</span>, <span class="dv">10</span>))</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x)</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>beta_true <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">3000</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>b_ols <span class="ot">&lt;-</span> b_gls <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, B, <span class="dv">2</span>)</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>  e <span class="ot">&lt;-</span> L <span class="sc">%*%</span> <span class="fu">rnorm</span>(n)  <span class="co"># correlated errors</span></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>  y_sim <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta_true <span class="sc">+</span> e</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>  b_ols[b, ] <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">solve</span>(<span class="fu">crossprod</span>(X)) <span class="sc">%*%</span> <span class="fu">crossprod</span>(X, y_sim))</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>  b_gls[b, ] <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> Omega_inv <span class="sc">%*%</span> X) <span class="sc">%*%</span></span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>                              (<span class="fu">t</span>(X) <span class="sc">%*%</span> Omega_inv <span class="sc">%*%</span> y_sim))</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Both unbiased</span></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(b_ols) <span class="sc">-</span> beta_true</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  0.01416 -0.00327</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(b_gls) <span class="sc">-</span> beta_true</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  0.01215 -0.00282</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># But GLS is more efficient (lower SD for slope)</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">sd_ols_slope =</span> <span class="fu">sd</span>(b_ols[, <span class="dv">2</span>]), <span class="at">sd_gls_slope =</span> <span class="fu">sd</span>(b_gls[, <span class="dv">2</span>]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>sd_ols_slope sd_gls_slope 
       0.109        0.101 </code></pre>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>df_ar <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">slope =</span> <span class="fu">c</span>(b_ols[, <span class="dv">2</span>], b_gls[, <span class="dv">2</span>]),</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"OLS"</span>, <span class="st">"GLS"</span>), <span class="at">each =</span> B)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_ar, <span class="fu">aes</span>(slope, <span class="at">fill =</span> method)) <span class="sc">+</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"OLS vs. GLS with AR(1) errors (ρ = 0.8)"</span>,</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"GLS recovers the efficiency lost to serial correlation"</span>,</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="fu">expression</span>(<span class="fu">hat</span>(beta)[<span class="dv">1</span>]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch05-gls_files/figure-html/gls-ar1-density-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="the-gls-projection-matrix" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="the-gls-projection-matrix"><span class="header-section-number">3.4</span> The GLS projection matrix</h3>
<p>In Chapter 3, we studied <span class="math inline">\(P = X(X'X)^{-1}X'\)</span>. The GLS analog replaces the inner product:</p>
<p><span class="math display">\[P_{GLS} = X(X'\Omega^{-1}X)^{-1}X'\Omega^{-1}\]</span></p>
<p>Unlike the OLS projection, <span class="math inline">\(P_{GLS}\)</span> is <strong>not symmetric</strong> — but it is still idempotent:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>P_gls <span class="ot">&lt;-</span> X <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> Omega_inv <span class="sc">%*%</span> X) <span class="sc">%*%</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> Omega_inv</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Not symmetric</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">abs</span>(P_gls <span class="sc">-</span> <span class="fu">t</span>(P_gls)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.272</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># But idempotent</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(P_gls <span class="sc">%*%</span> P_gls, P_gls)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
</section>
</section>
<section id="feasible-gls" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="feasible-gls"><span class="header-section-number">4</span> Feasible GLS</h2>
<p>GLS requires knowing <span class="math inline">\(\Omega\)</span>. In practice, we never know the true variance structure. <strong>Feasible GLS</strong> (FGLS) estimates <span class="math inline">\(\Omega\)</span> from the data in a first step, then applies GLS with <span class="math inline">\(\hat{\Omega}\)</span>.</p>
<section id="step-by-step-fgls-for-heteroskedasticity" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="step-by-step-fgls-for-heteroskedasticity"><span class="header-section-number">4.1</span> Step-by-step FGLS for heteroskedasticity</h3>
<p>The most common approach assumes a <strong>multiplicative heteroskedasticity</strong> model:</p>
<p><span class="math display">\[\sigma_i^2 = \text{Var}[e_i \mid x_i] = \exp(\gamma_0 + \gamma_1 z_i)\]</span></p>
<p>where <span class="math inline">\(z_i\)</span> is some function of <span class="math inline">\(x_i\)</span>.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">300</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="co"># DGP: variance depends strongly on x</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>sigma_true <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">*</span> x)  <span class="co"># log-linear variance</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(n) <span class="sc">*</span> <span class="fu">sqrt</span>(sigma_true)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Run OLS, save residuals</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>mod_step1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Regress log(e^2) on x to estimate the variance function</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>log_e2 <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">resid</span>(mod_step1)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>mod_var <span class="ot">&lt;-</span> <span class="fu">lm</span>(log_e2 <span class="sc">~</span> x)</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Predicted variances -&gt; weights</span></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>sigma2_hat <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">fitted</span>(mod_var))</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a>w_fgls <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> sigma2_hat</span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Run WLS with estimated weights</span></span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a>mod_fgls <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">weights =</span> w_fgls)</span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">OLS =</span> <span class="fu">coef</span>(mod_step1), <span class="at">FGLS =</span> <span class="fu">coef</span>(mod_fgls), <span class="at">Truth =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>             OLS FGLS Truth
(Intercept) 1.85 2.03     2
x           3.02 2.98     3</code></pre>
</div>
</div>
<p>Compare standard errors — OLS classical, OLS with HC2, and FGLS:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>X_fgls <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>se_compare <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">OLS_classical =</span> <span class="fu">summary</span>(mod_step1)<span class="sc">$</span>coefficients[, <span class="dv">2</span>],</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">OLS_HC2       =</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod_step1, <span class="at">type =</span> <span class="st">"HC2"</span>))),</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">FGLS          =</span> <span class="fu">summary</span>(mod_fgls)<span class="sc">$</span>coefficients[, <span class="dv">2</span>],</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">row.names =</span> <span class="fu">c</span>(<span class="st">"(Intercept)"</span>, <span class="st">"x"</span>)</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(se_compare, <span class="dv">4</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>            OLS_classical OLS_HC2  FGLS
(Intercept)        0.4559  0.3641 0.255
x                  0.0753  0.0886 0.062</code></pre>
</div>
</div>
<p>HC2 corrects the SE without changing the point estimate. FGLS changes <em>both</em> — it re-estimates <span class="math inline">\(\hat{\beta}\)</span> using the variance information, gaining efficiency.</p>
</section>
<section id="implementing-fgls-with-matrix-algebra" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="implementing-fgls-with-matrix-algebra"><span class="header-section-number">4.2</span> Implementing FGLS with matrix algebra</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>X_mat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>Omega_hat_inv <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="dv">1</span> <span class="sc">/</span> sigma2_hat)</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="co"># GLS formula with estimated Omega</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>beta_fgls <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">t</span>(X_mat) <span class="sc">%*%</span> Omega_hat_inv <span class="sc">%*%</span> X_mat) <span class="sc">%*%</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>             (<span class="fu">t</span>(X_mat) <span class="sc">%*%</span> Omega_hat_inv <span class="sc">%*%</span> y)</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.numeric</span>(beta_fgls), <span class="fu">as.numeric</span>(<span class="fu">coef</span>(mod_fgls)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
</section>
<section id="how-well-does-fgls-estimate-the-variance-function" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="how-well-does-fgls-estimate-the-variance-function"><span class="header-section-number">4.3</span> How well does FGLS estimate the variance function?</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>df_var <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> x,</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">log_e2 =</span> log_e2,</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">fitted_log_var =</span> <span class="fu">fitted</span>(mod_var),</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">true_log_var =</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">*</span> x</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_var, <span class="fu">aes</span>(x)) <span class="sc">+</span></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> log_e2), <span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> fitted_log_var, <span class="at">color =</span> <span class="st">"Estimated"</span>), <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> true_log_var, <span class="at">color =</span> <span class="st">"True"</span>), <span class="at">linewidth =</span> <span class="dv">1</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"FGLS variance function estimation"</span>,</span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Regressing log(ê²) on x recovers the variance structure"</span>,</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"log(σ²)"</span>, <span class="at">color =</span> <span class="cn">NULL</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch05-gls_files/figure-html/fgls-variance-fit-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="monte-carlo-ols-vs.-fgls-efficiency" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="monte-carlo-ols-vs.-fgls-efficiency"><span class="header-section-number">4.4</span> Monte Carlo: OLS vs.&nbsp;FGLS efficiency</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">2000</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>b_ols_mc <span class="ot">&lt;-</span> b_fgls_mc <span class="ot">&lt;-</span> <span class="fu">numeric</span>(B)</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>  x_mc <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>  sigma_mc <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">*</span> x_mc)</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>  y_mc <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> x_mc <span class="sc">+</span> <span class="fu">rnorm</span>(n) <span class="sc">*</span> <span class="fu">sqrt</span>(sigma_mc)</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># OLS</span></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>  fit_ols <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_mc <span class="sc">~</span> x_mc)</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>  b_ols_mc[b] <span class="ot">&lt;-</span> <span class="fu">coef</span>(fit_ols)[<span class="dv">2</span>]</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># FGLS</span></span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a>  log_e2_mc <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">resid</span>(fit_ols)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a>  sigma2_hat_mc <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">fitted</span>(<span class="fu">lm</span>(log_e2_mc <span class="sc">~</span> x_mc)))</span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a>  b_fgls_mc[b] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y_mc <span class="sc">~</span> x_mc, <span class="at">weights =</span> <span class="dv">1</span> <span class="sc">/</span> sigma2_hat_mc))[<span class="dv">2</span>]</span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-20"><a href="#cb55-20" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">sd_ols =</span> <span class="fu">sd</span>(b_ols_mc), <span class="at">sd_fgls =</span> <span class="fu">sd</span>(b_fgls_mc),</span>
<span id="cb55-21"><a href="#cb55-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">efficiency_gain =</span> <span class="fu">sd</span>(b_ols_mc) <span class="sc">/</span> <span class="fu">sd</span>(b_fgls_mc))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>         sd_ols         sd_fgls efficiency_gain 
         0.0841          0.0687          1.2255 </code></pre>
</div>
</div>
<p>Even though FGLS must <em>estimate</em> the weights, it still substantially improves on OLS when the heteroskedasticity is strong.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>FGLS Requires a Correct Variance Model
</div>
</div>
<div class="callout-body-container callout-body">
<p>FGLS gains efficiency over OLS + robust SEs only when the variance model is correctly specified. If <span class="math inline">\(\hat\Omega\)</span> is misspecified, FGLS point estimates are still consistent but may be less efficient than OLS, and its reported SEs may be wrong. Use FGLS only when you have a substantive reason to model the variance.</p>
</div>
</div>
</section>
</section>
<section id="two-strategies-for-heteroskedasticity" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="two-strategies-for-heteroskedasticity"><span class="header-section-number">5</span> Two strategies for heteroskedasticity</h2>
<p>You have two options when errors may be heteroskedastic:</p>
<ol type="1">
<li><strong>Robust SEs (agnostic).</strong> Keep the OLS point estimates and correct only the standard errors with the sandwich formula. Requires no model for the variance — always valid.</li>
<li><strong>WLS/FGLS (model-based).</strong> Specify a model for the variance, estimate it, and re-weight. More efficient <em>if</em> the variance model is correct; potentially worse if it’s misspecified.</li>
</ol>
<p>A common older workflow was to first <em>test</em> for heteroskedasticity (Breusch-Pagan, White’s test), then decide whether to apply WLS. This is <strong>pre-testing</strong> — using the same data to choose the estimator and then to estimate — and it distorts the sampling distribution of the final estimate. The resulting “test, then decide” procedure is neither the OLS distribution nor the WLS distribution; its true coverage and size are hard to characterize.</p>
<p>The modern recommendation: <strong>always report robust SEs</strong> (HC2 by default for cross-sectional data). Use WLS/FGLS only when you have a <em>substantive</em> reason to model the variance — for instance, when observations are group averages with known group sizes, or when a theoretical model predicts the variance form. The decision to use WLS should come from domain knowledge, not from a hypothesis test on the same data.</p>
<section id="the-breusch-pagan-test-for-understanding-not-for-pre-testing" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="the-breusch-pagan-test-for-understanding-not-for-pre-testing"><span class="header-section-number">5.1</span> The Breusch-Pagan test (for understanding, not for pre-testing)</h3>
<p>The Breusch-Pagan test is still useful as a <em>descriptive</em> diagnostic — it tells you whether your residuals exhibit systematic patterns in spread. The mechanics are simple: regress <span class="math inline">\(\hat{e}^2 / \bar{\hat{e}^2}\)</span> on <span class="math inline">\(X\)</span> and check whether the <span class="math inline">\(R^2\)</span> is significantly different from zero.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>mod_diag <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Breusch-Pagan by hand</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>e2 <span class="ot">&lt;-</span> <span class="fu">resid</span>(mod_diag)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> e2 <span class="sc">/</span> <span class="fu">mean</span>(e2)  <span class="co"># normalize by average squared residual</span></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>aux <span class="ot">&lt;-</span> <span class="fu">lm</span>(p <span class="sc">~</span> x)</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Test statistic: explained sum of squares / 2</span></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>bp_stat <span class="ot">&lt;-</span> <span class="fu">sum</span>((<span class="fu">fitted</span>(aux) <span class="sc">-</span> <span class="fu">mean</span>(p))<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>bp_pval <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pchisq</span>(bp_stat, <span class="at">df =</span> <span class="dv">1</span>)</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">BP_statistic =</span> bp_stat, <span class="at">p_value =</span> bp_pval)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>BP_statistic      p_value 
         111            0 </code></pre>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same thing via lmtest (studentized version is robust to non-normal errors)</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="fu">bptest</span>(mod_diag)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    studentized Breusch-Pagan test

data:  mod_diag
BP = 66, df = 1, p-value = 4e-16</code></pre>
</div>
</div>
<p>A large test statistic tells you heteroskedasticity is present, which is useful information for understanding your data. But the right response is to always use robust SEs — not to condition your estimator on the test result.</p>
</section>
</section>
<section id="residual-types" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="residual-types"><span class="header-section-number">6</span> Residual types</h2>
<p>OLS residuals are <span class="math inline">\(\hat{e} = My\)</span>, but they are <strong>not</strong> equal to the true errors. The lecture develops three residual types using projection matrices. Each applies a different diagonal scaling matrix <span class="math inline">\(M^*\)</span> to correct for leverage.</p>
<section id="the-matrices" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="the-matrices"><span class="header-section-number">6.1</span> The matrices</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>X_d <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="fu">ncol</span>(X_d)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>P_d <span class="ot">&lt;-</span> X_d <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X_d)) <span class="sc">%*%</span> <span class="fu">t</span>(X_d)</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>M_d <span class="ot">&lt;-</span> <span class="fu">diag</span>(n) <span class="sc">-</span> P_d</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="fu">diag</span>(P_d)  <span class="co"># leverage values</span></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a><span class="co"># M* = diag{(1 - h_ii)^{-1}} — inflates by leverage</span></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>M_star <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> h))</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a><span class="co"># (M*)^{1/2} = diag{(1 - h_ii)^{-1/2}} — square root scaling</span></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>M_star_half <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">-</span> h))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>The key relationship: <span class="math inline">\(\text{Var}[\hat{e} \mid X] = M \, \text{Var}[e \mid X] \, M\)</span>. Under homoskedasticity this gives <span class="math inline">\(\text{Var}[\hat{e}_i \mid X] = (1 - h_{ii})\sigma^2\)</span>, so residuals are heteroskedastic even when the errors are not. The diagonal of <span class="math inline">\(M\)</span> shows the uneven scaling:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="dv">1</span> <span class="sc">-</span> h)  <span class="co"># ranges from near 0 (high leverage) to near 1</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  0.987   0.991   0.994   0.993   0.996   0.997 </code></pre>
</div>
</div>
</section>
<section id="raw-residuals-hate-me" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="raw-residuals-hate-me"><span class="header-section-number">6.2</span> Raw residuals: <span class="math inline">\(\hat{e} = Me\)</span></h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>e_raw <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(M_d <span class="sc">%*%</span> y)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Same as resid()</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(e_raw, <span class="fu">as.numeric</span>(<span class="fu">resid</span>(mod_diag)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
</section>
<section id="prediction-errors-tildee-m-hate-m-m-e" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="prediction-errors-tildee-m-hate-m-m-e"><span class="header-section-number">6.3</span> Prediction errors: <span class="math inline">\(\tilde{e} = M^* \hat{e} = M^* M e\)</span></h3>
<p>The prediction error <span class="math inline">\(\tilde{e}_i = \hat{e}_i / (1 - h_{ii})\)</span> is the leave-one-out residual from Chapter 4. In matrix form, pre-multiplying by <span class="math inline">\(M^*\)</span> inflates each residual by the inverse of its leverage correction:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>e_pred <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(M_star <span class="sc">%*%</span> M_d <span class="sc">%*%</span> y)</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Equivalently: e_hat / (1 - h)</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(e_pred, e_raw <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> h))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
<p>Under homoskedasticity, <span class="math inline">\(\text{Var}[\tilde{e}_i \mid X] = (1 - h_{ii})^{-1}\sigma^2\)</span>. These inflate at high-leverage points — the opposite of raw residuals.</p>
</section>
<section id="standardized-residuals-bare-m12-hate-hatsigma" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="standardized-residuals-bare-m12-hate-hatsigma"><span class="header-section-number">6.4</span> Standardized residuals: <span class="math inline">\(\bar{e} = (M^*)^{1/2} \hat{e} / \hat{\sigma}\)</span></h3>
<p>The standardized residual applies the square-root scaling to make residuals have (approximately) unit variance under homoskedasticity:</p>
<p><span class="math display">\[\bar{e} = \frac{1}{\hat{\sigma}}(M^*)^{1/2} M y\]</span></p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>sigma_hat <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(e_raw<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> (n <span class="sc">-</span> K))</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>e_std <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(M_star_half <span class="sc">%*%</span> M_d <span class="sc">%*%</span> y) <span class="sc">/</span> sigma_hat</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Same as rstandard()</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(e_std, <span class="fu">as.numeric</span>(<span class="fu">rstandard</span>(mod_diag)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
</section>
<section id="comparing-the-three-types" class="level3" data-number="6.5">
<h3 data-number="6.5" class="anchored" data-anchor-id="comparing-the-three-types"><span class="header-section-number">6.5</span> Comparing the three types</h3>
<p>The three residual types tell different stories. Raw residuals show the fan pattern of heteroskedasticity. Prediction errors <em>amplify</em> it — high-leverage observations get inflated further. Standardized residuals divide out the leverage effect, putting everything on a common scale.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>df_resid <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">rep</span>(x, <span class="dv">3</span>),</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">residual =</span> <span class="fu">c</span>(e_raw, e_pred, e_std),</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="fu">factor</span>(<span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"Raw: Me"</span>, <span class="st">"Prediction: M*Me"</span>, <span class="st">"Standardized: (M*)^½Me / σ̂"</span>),</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">each =</span> n),</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>                <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Raw: Me"</span>, <span class="st">"Prediction: M*Me"</span>, <span class="st">"Standardized: (M*)^½Me / σ̂"</span>))</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_resid, <span class="fu">aes</span>(x, residual)) <span class="sc">+</span></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> type, <span class="at">scales =</span> <span class="st">"free_y"</span>) <span class="sc">+</span></span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Three residual types from the same regression"</span>,</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Each panel applies a different diagonal scaling matrix to ê = My"</span>,</span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Residual value"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch05-gls_files/figure-html/residual-comparison-1.png" class="img-fluid figure-img" width="864"></p>
</figure>
</div>
</div>
</div>
<p>The fan shape is visible in all three (because the true DGP is heteroskedastic), but the <em>scale</em> differs: raw residuals have variance <span class="math inline">\((1 - h_{ii})\sigma_i^2\)</span>, prediction errors have variance <span class="math inline">\((1 - h_{ii})^{-1}\sigma_i^2\)</span>, and standardized residuals remove the leverage component, leaving only the heteroskedasticity <span class="math inline">\(\sigma_i^2 / \sigma^2\)</span>.</p>
<p><strong>Studentized residuals.</strong> R also provides <code>rstudent()</code>, which replaces <span class="math inline">\(\hat{\sigma}\)</span> with the leave-one-out estimate <span class="math inline">\(s_{(-i)}\)</span>. In practice, studentized and standardized residuals are nearly identical for moderate <span class="math inline">\(n\)</span> — the difference is just one observation’s contribution to <span class="math inline">\(\hat{\sigma}^2\)</span>. The studentized version follows a <span class="math inline">\(t_{n-K-1}\)</span> distribution under normality, which is useful for formal outlier tests:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Studentized ≈ standardized, but uses leave-one-out sigma</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">abs</span>(<span class="fu">rstudent</span>(mod_diag) <span class="sc">-</span> <span class="fu">rstandard</span>(mod_diag)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.059</code></pre>
</div>
</div>
</section>
</section>
<section id="estimating-sigma2" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="estimating-sigma2"><span class="header-section-number">7</span> Estimating <span class="math inline">\(\sigma^2\)</span></h2>
<p>Three estimators of the error variance:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="fu">ncol</span>(X_d)</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Method of moments (biased)</span></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>sigma2_mm <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod_diag)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> n</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Bias-corrected (used by summary.lm)</span></span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>sigma2_s2 <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod_diag)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> (n <span class="sc">-</span> K)</span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Standardized estimator (unbiased under heteroskedasticity)</span></span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>sigma2_bar <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">resid</span>(mod_diag)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> h))</span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">MM =</span> sigma2_mm, <span class="at">s2 =</span> sigma2_s2, <span class="at">standardized =</span> sigma2_bar)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>          MM           s2 standardized 
        11.6         11.7         11.7 </code></pre>
</div>
</div>
<p>Under homoskedasticity, <span class="math inline">\(s^2\)</span> is unbiased: <span class="math inline">\(E[s^2 \mid X] = \sigma^2\)</span>. The key identity is <span class="math inline">\(E[\hat{e}'\hat{e} \mid X] = \text{tr}(M) \cdot \sigma^2 = (n - K)\sigma^2\)</span>.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The trace trick: E[e'Me] = tr(M * E[ee']) = tr(M) * sigma^2 under homoskedasticity</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">trace_M =</span> <span class="fu">tr</span>(M_d), <span class="at">n_minus_K =</span> n <span class="sc">-</span> K)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>  trace_M n_minus_K 
      298       298 </code></pre>
</div>
</div>
<p>The standardized estimator <span class="math inline">\(\bar{\sigma}^2 = \frac{1}{n}\sum (1-h_{ii})^{-1}\hat{e}_i^2\)</span> is unbiased even under heteroskedasticity — it corrects each squared residual for its leverage. This is the logic behind HC2 standard errors: replace <span class="math inline">\(\hat{e}_i^2\)</span> with <span class="math inline">\(\hat{e}_i^2 / (1 - h_{ii})\)</span> in the sandwich meat.</p>
</section>
<section id="method-of-moments-perspective" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="method-of-moments-perspective"><span class="header-section-number">8</span> Method of moments perspective</h2>
<section id="ols-as-a-method-of-moments-estimator" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="ols-as-a-method-of-moments-estimator"><span class="header-section-number">8.1</span> OLS as a method of moments estimator</h3>
<p>OLS solves the sample analog of <span class="math inline">\(E[x_i(y_i - x_i'\beta)] = 0\)</span>:</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^n x_i(y_i - x_i'\hat{\beta}) = 0 \quad \Longleftrightarrow \quad X'(y - X\hat{\beta}) = 0\]</span></p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The OLS normal equations are moment conditions</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>moment <span class="ot">&lt;-</span> <span class="fu">t</span>(X_d) <span class="sc">%*%</span> <span class="fu">resid</span>(mod_diag)</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>moment  <span class="co"># numerically zero</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1]
  2.78e-15
x 5.62e-13</code></pre>
</div>
</div>
</section>
<section id="gls-as-efficient-method-of-moments" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="gls-as-efficient-method-of-moments"><span class="header-section-number">8.2</span> GLS as efficient method of moments</h3>
<p>GLS solves a <em>weighted</em> version of the same moment condition:</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^n \frac{1}{\sigma_i^2} x_i(y_i - x_i'\hat{\beta}_{GLS}) = 0 \quad \Longleftrightarrow \quad X'\Omega^{-1}(y - X\hat{\beta}_{GLS}) = 0\]</span></p>
<p>This is a <strong>generalized method of moments</strong> (GMM) estimator with weight matrix <span class="math inline">\(\Omega^{-1}\)</span>.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># GLS normal equations</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>Omega_hat_inv_diag <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="dv">1</span> <span class="sc">/</span> sigma2_hat)  <span class="co"># from our FGLS above</span></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>moment_gls <span class="ot">&lt;-</span> <span class="fu">t</span>(X_d) <span class="sc">%*%</span> Omega_hat_inv_diag <span class="sc">%*%</span> <span class="fu">resid</span>(mod_fgls)</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>moment_gls  <span class="co"># numerically zero</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>       [,1]
   1.11e-14
x -2.22e-14</code></pre>
</div>
</div>
<p>When we have exactly as many moment conditions as parameters (<span class="math inline">\(K\)</span> equations, <span class="math inline">\(K\)</span> unknowns), the GMM estimator reduces to method of moments. The efficiency of GLS comes from choosing the optimal weight matrix.</p>
<p>In Chapter 14, we’ll see that this logic extends to <strong>overidentified</strong> models: when you have <em>more</em> moment conditions than parameters, GMM finds the optimal combination. The GLS insight — weight by precision — is the same insight that drives GMM.</p>
</section>
</section>
<section id="application-robust-inference-on-the-prestige-data" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="application-robust-inference-on-the-prestige-data"><span class="header-section-number">9</span> Application: robust inference on the Prestige data</h2>
<p>Let’s apply the practical workflow to the Prestige dataset. We start with <code>lm_robust()</code> as the default — no pre-testing required.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The default workflow: OLS with HC2 robust SEs</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>mod_p_robust <span class="ot">&lt;-</span> <span class="fu">lm_robust</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> women,</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>                           <span class="at">data =</span> Prestige, <span class="at">se_type =</span> <span class="st">"HC2"</span>)</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_p_robust)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm_robust(formula = prestige ~ education + income + women, data = Prestige, 
    se_type = "HC2")

Standard error type:  HC2 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)  CI Lower CI Upper DF
(Intercept) -6.79433   3.216715  -2.112 3.72e-02 -13.17780 -0.41087 98
education    4.18664   0.446857   9.369 2.83e-15   3.29986  5.07341 98
income       0.00131   0.000375   3.504 6.91e-04   0.00057  0.00206 98
women       -0.00891   0.035522  -0.251 8.03e-01  -0.07940  0.06159 98

Multiple R-squared:  0.798 ,    Adjusted R-squared:  0.792 
F-statistic:  137 on 3 and 98 DF,  p-value: &lt;2e-16</code></pre>
</div>
</div>
<p>That’s the complete inference in one line. The residual plot is still useful as a <em>descriptive</em> tool for understanding your data — it just shouldn’t gate your choice of estimator:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>mod_p <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige)</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>df_p <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">income =</span> Prestige<span class="sc">$</span>income, <span class="at">resid =</span> <span class="fu">resid</span>(mod_p))</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_p, <span class="fu">aes</span>(income, resid)) <span class="sc">+</span></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"steelblue"</span>, <span class="at">method =</span> <span class="st">"loess"</span>, <span class="at">formula =</span> y <span class="sc">~</span> x) <span class="sc">+</span></span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Prestige: residuals vs. income"</span>,</span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Useful for understanding the data, not for choosing an estimator"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ch05-gls_files/figure-html/prestige-resid-plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>For comparison, here is what FGLS would give if we had a <em>substantive</em> reason to believe variance is proportional to income (e.g., because occupational prestige surveys sample more respondents for common jobs):</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># FGLS: only if we have a theoretical reason for the variance model</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>log_e2_p <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">resid</span>(mod_p)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>mod_var_p <span class="ot">&lt;-</span> <span class="fu">lm</span>(log_e2_p <span class="sc">~</span> income, <span class="at">data =</span> Prestige)</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>sigma2_hat_p <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">fitted</span>(mod_var_p))</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>mod_fgls_p <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> women,</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> Prestige, <span class="at">weights =</span> <span class="dv">1</span> <span class="sc">/</span> sigma2_hat_p)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb85"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Full comparison: coefficients and standard errors</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>coefs <span class="ot">&lt;-</span> <span class="fu">cbind</span>(</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">OLS  =</span> <span class="fu">coef</span>(mod_p),</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC2  =</span> <span class="fu">coef</span>(mod_p),      <span class="co"># same point estimates</span></span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">FGLS =</span> <span class="fu">coef</span>(mod_fgls_p)  <span class="co"># different point estimates</span></span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>ses <span class="ot">&lt;-</span> <span class="fu">cbind</span>(</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">Classical =</span> <span class="fu">summary</span>(mod_p)<span class="sc">$</span>coefficients[, <span class="dv">2</span>],</span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC2       =</span> <span class="fu">summary</span>(mod_p_robust)<span class="sc">$</span>coefficients[, <span class="dv">2</span>],</span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">FGLS      =</span> <span class="fu">summary</span>(mod_fgls_p)<span class="sc">$</span>coefficients[, <span class="dv">2</span>]</span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-14"><a href="#cb85-14" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Point estimates:</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Point estimates:</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb87"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(coefs, <span class="dv">4</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>                OLS     HC2    FGLS
(Intercept) -6.7943 -6.7943 -6.6482
education    4.1866  4.1866  4.2360
income       0.0013  0.0013  0.0012
women       -0.0089 -0.0089 -0.0132</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb89"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Standard errors:</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Standard errors:</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(ses, <span class="dv">4</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Classical    HC2   FGLS
(Intercept)    3.2391 3.2167 3.2241
education      0.3887 0.4469 0.3816
income         0.0003 0.0004 0.0003
women          0.0304 0.0355 0.0302</code></pre>
</div>
</div>
<p>The differences here are modest. The pattern illustrates the two strategies:</p>
<ul>
<li><strong>Robust SEs (HC2)</strong>: Keep the OLS point estimates, correct only the standard errors. No assumptions about the variance structure — always valid.</li>
<li><strong>FGLS</strong>: Re-estimate <span class="math inline">\(\hat{\beta}\)</span> using the variance structure. More efficient <em>if</em> your variance model is correct; potentially worse if it’s wrong.</li>
</ul>
<p>The default for cross-sectional data is HC2. Use FGLS when you have a substantive reason to model the variance — not because a test told you to.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>HC2 as Default
</div>
</div>
<div class="callout-body-container callout-body">
<p>For cross-sectional data, use <code>lm_robust(y ~ x, se_type = "HC2")</code> or <code>vcovHC(mod, type = "HC2")</code> as the default. HC2 adjusts for leverage and provides better finite-sample coverage than HC0 or HC1.</p>
</div>
</div>
</section>
<section id="summary" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="summary"><span class="header-section-number">10</span> Summary</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 46%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Concept</th>
<th>Matrix formula</th>
<th>R code</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sandwich variance</td>
<td><span class="math inline">\((X'X)^{-1}X'\Omega X(X'X)^{-1}\)</span></td>
<td><code>vcovHC(mod, type = "HC2")</code></td>
</tr>
<tr class="even">
<td>Robust SEs</td>
<td><span class="math inline">\(\sqrt{\text{diag}(\hat{V}_{HC})}\)</span></td>
<td><code>lm_robust(y ~ x, se_type = "HC2")</code></td>
</tr>
<tr class="odd">
<td>Robust t-test</td>
<td>—</td>
<td><code>coeftest(mod, vcov = vcovHC)</code></td>
</tr>
<tr class="even">
<td>WLS</td>
<td><span class="math inline">\((X'WX)^{-1}X'Wy\)</span></td>
<td><code>lm(y ~ x, weights = w)</code></td>
</tr>
<tr class="odd">
<td>GLS</td>
<td><span class="math inline">\((X'\Omega^{-1}X)^{-1}X'\Omega^{-1}y\)</span></td>
<td><code>solve(t(X) %*% Oi %*% X) %*% t(X) %*% Oi %*% y</code></td>
</tr>
<tr class="even">
<td>Eigendecomposition</td>
<td><span class="math inline">\(\Omega = C\Lambda C'\)</span></td>
<td><code>eigen(Omega)</code></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\Omega^{-1/2}\)</span></td>
<td><span class="math inline">\(C\Lambda^{-1/2}C'\)</span></td>
<td><code>C %*% diag(1/sqrt(lam)) %*% t(C)</code></td>
</tr>
<tr class="even">
<td>FGLS</td>
<td>Estimate <span class="math inline">\(\hat{\Omega}\)</span>, then GLS</td>
<td><code>lm(log(e^2) ~ z)</code> then <code>lm(y ~ x, weights = ...)</code></td>
</tr>
<tr class="odd">
<td>Breusch-Pagan</td>
<td><span class="math inline">\(nR^2\)</span> from <span class="math inline">\(\hat{e}^2/\bar{\hat{e}^2} \sim X\)</span></td>
<td><code>bptest(mod)</code></td>
</tr>
<tr class="even">
<td>Standardized residual</td>
<td><span class="math inline">\(\hat{e}_i / (\hat{\sigma}\sqrt{1-h_{ii}})\)</span></td>
<td><code>rstandard(mod)</code></td>
</tr>
<tr class="odd">
<td>Studentized residual</td>
<td><span class="math inline">\(\hat{e}_i / (s_{(-i)}\sqrt{1-h_{ii}})\)</span></td>
<td><code>rstudent(mod)</code></td>
</tr>
</tbody>
</table>
<p><strong>Key takeaway.</strong> When you know (or can estimate) the variance structure, exploit it: WLS/GLS gives you tighter estimates by trusting precise observations more. When you don’t trust your variance model, use <code>lm_robust()</code> with HC2 standard errors — it’s always valid and requires no assumptions about the form of heteroskedasticity. In either case, the method of moments logic — choosing the right weight matrix — connects directly to GMM (Chapter 14).</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/UChicago-pol-methods\.github\.io\/EstimationI\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb93" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "5. Efficiency and GLS"</span></span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Weighted least squares, feasible GLS, and the method of moments"</span></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>When error variances differ across observations, OLS is still unbiased but no longer efficient. This chapter develops WLS and GLS as the natural response: weight observations by their precision. We build everything from matrix algebra, connect the estimator to the method of moments, and implement feasible GLS when the variance structure must be estimated from data. Along the way we introduce the <span class="in">`sandwich`</span> and <span class="in">`estimatr`</span> packages — the practical tools for robust inference in R.</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>**Questions this chapter answers:**</span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Why are classical standard errors wrong under heteroskedasticity, and what does the sandwich formula fix?</span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>How do WLS and GLS improve efficiency by weighting observations by their precision?</span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>When should you use FGLS vs. simply reporting robust standard errors?</span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>What is the connection between HC0/HC1/HC2 and the leverage-corrected residual types?</span>
<span id="cb93-14"><a href="#cb93-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-17"><a href="#cb93-17" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-18"><a href="#cb93-18" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup</span></span>
<span id="cb93-19"><a href="#cb93-19" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb93-20"><a href="#cb93-20" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb93-21"><a href="#cb93-21" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb93-22"><a href="#cb93-22" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sandwich)</span>
<span id="cb93-23"><a href="#cb93-23" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb93-24"><a href="#cb93-24" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(estimatr)</span>
<span id="cb93-25"><a href="#cb93-25" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(carData)</span>
<span id="cb93-26"><a href="#cb93-26" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Prestige)</span>
<span id="cb93-27"><a href="#cb93-27" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb93-28"><a href="#cb93-28" aria-hidden="true" tabindex="-1"></a>tr <span class="ot">&lt;-</span> <span class="cf">function</span>(M) <span class="fu">sum</span>(<span class="fu">diag</span>(M))</span>
<span id="cb93-29"><a href="#cb93-29" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-30"><a href="#cb93-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-31"><a href="#cb93-31" aria-hidden="true" tabindex="-1"></a><span class="fu">## The variance of OLS under non-spherical errors {#sec-sandwich}</span></span>
<span id="cb93-32"><a href="#cb93-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-33"><a href="#cb93-33" aria-hidden="true" tabindex="-1"></a>Recall the <span class="co">[</span><span class="ot">OLS estimator</span><span class="co">](ch03-ols.qmd#eq-ols)</span>: $\hat{\beta} = \beta + (X'X)^{-1}X'e$. The variance is:</span>
<span id="cb93-34"><a href="#cb93-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-35"><a href="#cb93-35" aria-hidden="true" tabindex="-1"></a>$$\text{Var}<span class="co">[</span><span class="ot">\hat{\beta} \mid X</span><span class="co">]</span> = (X'X)^{-1} X' \text{Var}<span class="co">[</span><span class="ot">e \mid X</span><span class="co">]</span> \, X (X'X)^{-1}$$</span>
<span id="cb93-36"><a href="#cb93-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-37"><a href="#cb93-37" aria-hidden="true" tabindex="-1"></a>Under **homoskedasticity** ($\text{Var}[e \mid X] = \sigma^2 I$), this simplifies to $\sigma^2(X'X)^{-1}$. But when $\text{Var}[e \mid X] = \Omega \neq \sigma^2 I$, we get the **sandwich formula**:</span>
<span id="cb93-38"><a href="#cb93-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-39"><a href="#cb93-39" aria-hidden="true" tabindex="-1"></a>$$(X'X)^{-1} (X' \Omega X) (X'X)^{-1}$$ {#eq-sandwich}</span>
<span id="cb93-40"><a href="#cb93-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-41"><a href="#cb93-41" aria-hidden="true" tabindex="-1"></a>The "bread" is $(X'X)^{-1}$ and the "meat" is $X'\Omega X = \sum_{i=1}^n \sigma_i^2 x_i x_i'$. Let's see what happens when we ignore heteroskedasticity and use the classical formula anyway.</span>
<span id="cb93-42"><a href="#cb93-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-43"><a href="#cb93-43" aria-hidden="true" tabindex="-1"></a>::: {#def-sandwich}</span>
<span id="cb93-44"><a href="#cb93-44" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sandwich Variance Estimator</span></span>
<span id="cb93-45"><a href="#cb93-45" aria-hidden="true" tabindex="-1"></a>Under heteroskedasticity ($\text{Var}<span class="co">[</span><span class="ot">e|X</span><span class="co">]</span> = \Omega \neq \sigma^2 I$), the variance of OLS is $(X'X)^{-1}(X'\Omega X)(X'X)^{-1}$. The HC estimators replace $\Omega$ with diagonal matrices of squared residuals, possibly adjusted for leverage.</span>
<span id="cb93-46"><a href="#cb93-46" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-47"><a href="#cb93-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-48"><a href="#cb93-48" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simulation: when classical standard errors lie</span></span>
<span id="cb93-49"><a href="#cb93-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-50"><a href="#cb93-50" aria-hidden="true" tabindex="-1"></a>We design a DGP with strong heteroskedasticity: the error standard deviation grows as $x^2$, so variance ranges from 1 (at $x = 1$) to 10,000 (at $x = 10$). This makes the problem impossible to miss.</span>
<span id="cb93-51"><a href="#cb93-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-54"><a href="#cb93-54" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-55"><a href="#cb93-55" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: classical-se-wrong</span></span>
<span id="cb93-56"><a href="#cb93-56" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb93-57"><a href="#cb93-57" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb93-58"><a href="#cb93-58" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb93-59"><a href="#cb93-59" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x)</span>
<span id="cb93-60"><a href="#cb93-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-61"><a href="#cb93-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Strongly heteroskedastic DGP: SD = x^2</span></span>
<span id="cb93-62"><a href="#cb93-62" aria-hidden="true" tabindex="-1"></a>sigma_i <span class="ot">&lt;-</span> x<span class="sc">^</span><span class="dv">2</span>   <span class="co"># variance = x^4, ratio of 10000:1</span></span>
<span id="cb93-63"><a href="#cb93-63" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, sigma_i)</span>
<span id="cb93-64"><a href="#cb93-64" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb93-65"><a href="#cb93-65" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-66"><a href="#cb93-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-67"><a href="#cb93-67" aria-hidden="true" tabindex="-1"></a>First, let's build the sandwich by hand to see the matrix algebra:</span>
<span id="cb93-68"><a href="#cb93-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-71"><a href="#cb93-71" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-72"><a href="#cb93-72" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: sandwich-by-hand</span></span>
<span id="cb93-73"><a href="#cb93-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Classical variance: s^2 * (X'X)^{-1}</span></span>
<span id="cb93-74"><a href="#cb93-74" aria-hidden="true" tabindex="-1"></a>s2 <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> (n <span class="sc">-</span> <span class="dv">2</span>)</span>
<span id="cb93-75"><a href="#cb93-75" aria-hidden="true" tabindex="-1"></a>V_classical <span class="ot">&lt;-</span> s2 <span class="sc">*</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X))</span>
<span id="cb93-76"><a href="#cb93-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-77"><a href="#cb93-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Sandwich variance (HC0): (X'X)^{-1} X' diag(e^2) X (X'X)^{-1}</span></span>
<span id="cb93-78"><a href="#cb93-78" aria-hidden="true" tabindex="-1"></a>e_hat <span class="ot">&lt;-</span> <span class="fu">resid</span>(mod)</span>
<span id="cb93-79"><a href="#cb93-79" aria-hidden="true" tabindex="-1"></a>bread <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X))</span>
<span id="cb93-80"><a href="#cb93-80" aria-hidden="true" tabindex="-1"></a>meat <span class="ot">&lt;-</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> <span class="fu">diag</span>(e_hat<span class="sc">^</span><span class="dv">2</span>) <span class="sc">%*%</span> X</span>
<span id="cb93-81"><a href="#cb93-81" aria-hidden="true" tabindex="-1"></a>V_HC0 <span class="ot">&lt;-</span> bread <span class="sc">%*%</span> meat <span class="sc">%*%</span> bread</span>
<span id="cb93-82"><a href="#cb93-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-83"><a href="#cb93-83" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare standard errors for the slope</span></span>
<span id="cb93-84"><a href="#cb93-84" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">classical =</span> <span class="fu">sqrt</span>(V_classical[<span class="dv">2</span>, <span class="dv">2</span>]),</span>
<span id="cb93-85"><a href="#cb93-85" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC0       =</span> <span class="fu">sqrt</span>(V_HC0[<span class="dv">2</span>, <span class="dv">2</span>]))</span>
<span id="cb93-86"><a href="#cb93-86" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-87"><a href="#cb93-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-88"><a href="#cb93-88" aria-hidden="true" tabindex="-1"></a>Now the practical way — <span class="in">`sandwich::vcovHC()`</span> computes this in one line:</span>
<span id="cb93-89"><a href="#cb93-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-92"><a href="#cb93-92" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-93"><a href="#cb93-93" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: sandwich-vcovHC</span></span>
<span id="cb93-94"><a href="#cb93-94" aria-hidden="true" tabindex="-1"></a><span class="co"># HC0 (White's original)</span></span>
<span id="cb93-95"><a href="#cb93-95" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC0"</span>)))</span>
<span id="cb93-96"><a href="#cb93-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-97"><a href="#cb93-97" aria-hidden="true" tabindex="-1"></a><span class="co"># HC1 (small-sample correction: multiply by n/(n-k))</span></span>
<span id="cb93-98"><a href="#cb93-98" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC1"</span>)))</span>
<span id="cb93-99"><a href="#cb93-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-100"><a href="#cb93-100" aria-hidden="true" tabindex="-1"></a><span class="co"># HC2 (recommended default — adjusts for leverage)</span></span>
<span id="cb93-101"><a href="#cb93-101" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC2"</span>)))</span>
<span id="cb93-102"><a href="#cb93-102" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-103"><a href="#cb93-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-104"><a href="#cb93-104" aria-hidden="true" tabindex="-1"></a>Or even simpler — <span class="in">`estimatr::lm_robust()`</span> fits the model and computes robust SEs in one step:</span>
<span id="cb93-105"><a href="#cb93-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-108"><a href="#cb93-108" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-109"><a href="#cb93-109" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: lm-robust-intro</span></span>
<span id="cb93-110"><a href="#cb93-110" aria-hidden="true" tabindex="-1"></a>mod_robust <span class="ot">&lt;-</span> <span class="fu">lm_robust</span>(y <span class="sc">~</span> x, <span class="at">se_type =</span> <span class="st">"HC2"</span>)</span>
<span id="cb93-111"><a href="#cb93-111" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_robust)</span>
<span id="cb93-112"><a href="#cb93-112" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-113"><a href="#cb93-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-114"><a href="#cb93-114" aria-hidden="true" tabindex="-1"></a>Compare the standard errors side by side:</span>
<span id="cb93-115"><a href="#cb93-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-118"><a href="#cb93-118" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-119"><a href="#cb93-119" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: se-comparison-table</span></span>
<span id="cb93-120"><a href="#cb93-120" aria-hidden="true" tabindex="-1"></a>se_table <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb93-121"><a href="#cb93-121" aria-hidden="true" tabindex="-1"></a>  <span class="at">Classical =</span> <span class="fu">summary</span>(mod)<span class="sc">$</span>coefficients[, <span class="dv">2</span>],</span>
<span id="cb93-122"><a href="#cb93-122" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC0 =</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC0"</span>))),</span>
<span id="cb93-123"><a href="#cb93-123" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC1 =</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC1"</span>))),</span>
<span id="cb93-124"><a href="#cb93-124" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC2 =</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC2"</span>))),</span>
<span id="cb93-125"><a href="#cb93-125" aria-hidden="true" tabindex="-1"></a>  <span class="at">row.names =</span> <span class="fu">c</span>(<span class="st">"(Intercept)"</span>, <span class="st">"x"</span>)</span>
<span id="cb93-126"><a href="#cb93-126" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-127"><a href="#cb93-127" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(se_table, <span class="dv">3</span>)</span>
<span id="cb93-128"><a href="#cb93-128" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-129"><a href="#cb93-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-130"><a href="#cb93-130" aria-hidden="true" tabindex="-1"></a>The classical SE for the slope is far too small — it ignores that the high-$x$ observations (which pull the slope) are exactly the noisiest ones.</span>
<span id="cb93-131"><a href="#cb93-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-132"><a href="#cb93-132" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb93-133"><a href="#cb93-133" aria-hidden="true" tabindex="-1"></a><span class="fu">## Classical Standard Errors Can Be Dangerously Wrong</span></span>
<span id="cb93-134"><a href="#cb93-134" aria-hidden="true" tabindex="-1"></a>Under heteroskedasticity, classical SEs can be too small by a factor of 2 or more, producing confidence intervals with far below nominal coverage. Always use robust SEs (HC2) as the default for cross-sectional data.</span>
<span id="cb93-135"><a href="#cb93-135" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-136"><a href="#cb93-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-139"><a href="#cb93-139" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-140"><a href="#cb93-140" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: heteroskedasticity-visual</span></span>
<span id="cb93-141"><a href="#cb93-141" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb93-142"><a href="#cb93-142" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb93-143"><a href="#cb93-143" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">residual =</span> <span class="fu">resid</span>(mod))</span>
<span id="cb93-144"><a href="#cb93-144" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(x, residual)) <span class="sc">+</span></span>
<span id="cb93-145"><a href="#cb93-145" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb93-146"><a href="#cb93-146" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb93-147"><a href="#cb93-147" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Residuals fan out dramatically with x"</span>,</span>
<span id="cb93-148"><a href="#cb93-148" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"SD grows as x², so variance ratio is 10000:1"</span>)</span>
<span id="cb93-149"><a href="#cb93-149" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-150"><a href="#cb93-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-151"><a href="#cb93-151" aria-hidden="true" tabindex="-1"></a><span class="fu">### Monte Carlo: coverage of classical vs. robust intervals</span></span>
<span id="cb93-152"><a href="#cb93-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-155"><a href="#cb93-155" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-156"><a href="#cb93-156" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: coverage-sim</span></span>
<span id="cb93-157"><a href="#cb93-157" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb93-158"><a href="#cb93-158" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">2000</span></span>
<span id="cb93-159"><a href="#cb93-159" aria-hidden="true" tabindex="-1"></a>cover_classical <span class="ot">&lt;-</span> cover_HC0 <span class="ot">&lt;-</span> cover_HC2 <span class="ot">&lt;-</span> <span class="fu">logical</span>(B)</span>
<span id="cb93-160"><a href="#cb93-160" aria-hidden="true" tabindex="-1"></a>beta_true <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb93-161"><a href="#cb93-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-162"><a href="#cb93-162" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb93-163"><a href="#cb93-163" aria-hidden="true" tabindex="-1"></a>  x_sim <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb93-164"><a href="#cb93-164" aria-hidden="true" tabindex="-1"></a>  X_sim <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x_sim)</span>
<span id="cb93-165"><a href="#cb93-165" aria-hidden="true" tabindex="-1"></a>  sigma_sim <span class="ot">&lt;-</span> x_sim<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb93-166"><a href="#cb93-166" aria-hidden="true" tabindex="-1"></a>  y_sim <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> beta_true <span class="sc">*</span> x_sim <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, sigma_sim)</span>
<span id="cb93-167"><a href="#cb93-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-168"><a href="#cb93-168" aria-hidden="true" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_sim <span class="sc">~</span> x_sim)</span>
<span id="cb93-169"><a href="#cb93-169" aria-hidden="true" tabindex="-1"></a>  b_hat <span class="ot">&lt;-</span> <span class="fu">coef</span>(fit)[<span class="dv">2</span>]</span>
<span id="cb93-170"><a href="#cb93-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-171"><a href="#cb93-171" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Classical CI</span></span>
<span id="cb93-172"><a href="#cb93-172" aria-hidden="true" tabindex="-1"></a>  se_class <span class="ot">&lt;-</span> <span class="fu">summary</span>(fit)<span class="sc">$</span>coefficients[<span class="dv">2</span>, <span class="dv">2</span>]</span>
<span id="cb93-173"><a href="#cb93-173" aria-hidden="true" tabindex="-1"></a>  ci_class <span class="ot">&lt;-</span> b_hat <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fl">1.96</span> <span class="sc">*</span> se_class</span>
<span id="cb93-174"><a href="#cb93-174" aria-hidden="true" tabindex="-1"></a>  cover_classical[b] <span class="ot">&lt;-</span> ci_class[<span class="dv">1</span>] <span class="sc">&lt;</span> beta_true <span class="sc">&amp;</span> beta_true <span class="sc">&lt;</span> ci_class[<span class="dv">2</span>]</span>
<span id="cb93-175"><a href="#cb93-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-176"><a href="#cb93-176" aria-hidden="true" tabindex="-1"></a>  <span class="co"># HC0 (White)</span></span>
<span id="cb93-177"><a href="#cb93-177" aria-hidden="true" tabindex="-1"></a>  se_hc0 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">vcovHC</span>(fit, <span class="at">type =</span> <span class="st">"HC0"</span>)[<span class="dv">2</span>, <span class="dv">2</span>])</span>
<span id="cb93-178"><a href="#cb93-178" aria-hidden="true" tabindex="-1"></a>  ci_hc0 <span class="ot">&lt;-</span> b_hat <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fl">1.96</span> <span class="sc">*</span> se_hc0</span>
<span id="cb93-179"><a href="#cb93-179" aria-hidden="true" tabindex="-1"></a>  cover_HC0[b] <span class="ot">&lt;-</span> ci_hc0[<span class="dv">1</span>] <span class="sc">&lt;</span> beta_true <span class="sc">&amp;</span> beta_true <span class="sc">&lt;</span> ci_hc0[<span class="dv">2</span>]</span>
<span id="cb93-180"><a href="#cb93-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-181"><a href="#cb93-181" aria-hidden="true" tabindex="-1"></a>  <span class="co"># HC2 (recommended)</span></span>
<span id="cb93-182"><a href="#cb93-182" aria-hidden="true" tabindex="-1"></a>  se_hc2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">vcovHC</span>(fit, <span class="at">type =</span> <span class="st">"HC2"</span>)[<span class="dv">2</span>, <span class="dv">2</span>])</span>
<span id="cb93-183"><a href="#cb93-183" aria-hidden="true" tabindex="-1"></a>  ci_hc2 <span class="ot">&lt;-</span> b_hat <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fl">1.96</span> <span class="sc">*</span> se_hc2</span>
<span id="cb93-184"><a href="#cb93-184" aria-hidden="true" tabindex="-1"></a>  cover_HC2[b] <span class="ot">&lt;-</span> ci_hc2[<span class="dv">1</span>] <span class="sc">&lt;</span> beta_true <span class="sc">&amp;</span> beta_true <span class="sc">&lt;</span> ci_hc2[<span class="dv">2</span>]</span>
<span id="cb93-185"><a href="#cb93-185" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb93-186"><a href="#cb93-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-187"><a href="#cb93-187" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">classical =</span> <span class="fu">mean</span>(cover_classical),</span>
<span id="cb93-188"><a href="#cb93-188" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC0       =</span> <span class="fu">mean</span>(cover_HC0),</span>
<span id="cb93-189"><a href="#cb93-189" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC2       =</span> <span class="fu">mean</span>(cover_HC2))</span>
<span id="cb93-190"><a href="#cb93-190" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-191"><a href="#cb93-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-192"><a href="#cb93-192" aria-hidden="true" tabindex="-1"></a>Classical intervals have terrible coverage. HC0 does better. HC2 gets closest to the nominal 95% because it corrects for leverage — observations with high $x$ values both have high variance *and* high leverage. (Chapter 6 develops the HC variants in detail.)</span>
<span id="cb93-193"><a href="#cb93-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-194"><a href="#cb93-194" aria-hidden="true" tabindex="-1"></a><span class="fu">### `lm_robust` vs. `coeftest`: two workflows</span></span>
<span id="cb93-195"><a href="#cb93-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-196"><a href="#cb93-196" aria-hidden="true" tabindex="-1"></a>In practice, there are two ways to get robust inference. Use whichever fits your workflow:</span>
<span id="cb93-197"><a href="#cb93-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-200"><a href="#cb93-200" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-201"><a href="#cb93-201" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: two-workflows</span></span>
<span id="cb93-202"><a href="#cb93-202" aria-hidden="true" tabindex="-1"></a><span class="co"># Workflow 1: estimatr — one function does everything</span></span>
<span id="cb93-203"><a href="#cb93-203" aria-hidden="true" tabindex="-1"></a>mod_r <span class="ot">&lt;-</span> <span class="fu">lm_robust</span>(y <span class="sc">~</span> x, <span class="at">se_type =</span> <span class="st">"HC2"</span>)</span>
<span id="cb93-204"><a href="#cb93-204" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">summary</span>(mod_r))</span>
<span id="cb93-205"><a href="#cb93-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-206"><a href="#cb93-206" aria-hidden="true" tabindex="-1"></a><span class="co"># Workflow 2: sandwich + lmtest — post-hoc correction to a fitted lm</span></span>
<span id="cb93-207"><a href="#cb93-207" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(mod, <span class="at">vcov =</span> <span class="fu">vcovHC</span>(mod, <span class="at">type =</span> <span class="st">"HC2"</span>))</span>
<span id="cb93-208"><a href="#cb93-208" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-209"><a href="#cb93-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-210"><a href="#cb93-210" aria-hidden="true" tabindex="-1"></a>The <span class="in">`coeftest()`</span> approach is useful when you've already fit a model with <span class="in">`lm()`</span> and want to report robust SEs. <span class="in">`lm_robust()`</span> is cleaner when you know from the start that you want robust inference.</span>
<span id="cb93-211"><a href="#cb93-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-212"><a href="#cb93-212" aria-hidden="true" tabindex="-1"></a><span class="fu">## Weighted least squares</span></span>
<span id="cb93-213"><a href="#cb93-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-214"><a href="#cb93-214" aria-hidden="true" tabindex="-1"></a>The sandwich formula tells us what the variance *is*. But can we do better than OLS? Yes — if we know (or can estimate) the variance structure, we should exploit it.</span>
<span id="cb93-215"><a href="#cb93-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-216"><a href="#cb93-216" aria-hidden="true" tabindex="-1"></a><span class="fu">### The idea: weight by precision</span></span>
<span id="cb93-217"><a href="#cb93-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-218"><a href="#cb93-218" aria-hidden="true" tabindex="-1"></a>If observation $i$ has variance $\sigma_i^2$, it carries less information than an observation with variance $\sigma_j^2 &lt; \sigma_i^2$. WLS weights each observation by $w_i = 1/\sigma_i^2$, downweighting noisy observations:</span>
<span id="cb93-219"><a href="#cb93-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-220"><a href="#cb93-220" aria-hidden="true" tabindex="-1"></a>$$\hat{\beta}_{WLS} = \arg\min_\beta \sum_{i=1}^n w_i (y_i - x_i'\beta)^2 = (X'WX)^{-1} X'Wy$$ {#eq-wls}</span>
<span id="cb93-221"><a href="#cb93-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-222"><a href="#cb93-222" aria-hidden="true" tabindex="-1"></a>where $W = \text{diag}(w_1, \ldots, w_n)$.</span>
<span id="cb93-223"><a href="#cb93-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-224"><a href="#cb93-224" aria-hidden="true" tabindex="-1"></a><span class="fu">### Two-group example</span></span>
<span id="cb93-225"><a href="#cb93-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-226"><a href="#cb93-226" aria-hidden="true" tabindex="-1"></a>Suppose we survey two groups: Group A ($n_A = 100$, $\sigma_A = 10$) and Group B ($n_B = 100$, $\sigma_B = 1$). OLS gives equal weight to every observation. WLS gives Group A weight $1/100$ and Group B weight $1$.</span>
<span id="cb93-227"><a href="#cb93-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-230"><a href="#cb93-230" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-231"><a href="#cb93-231" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: two-group-sim</span></span>
<span id="cb93-232"><a href="#cb93-232" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">99</span>)</span>
<span id="cb93-233"><a href="#cb93-233" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">5000</span></span>
<span id="cb93-234"><a href="#cb93-234" aria-hidden="true" tabindex="-1"></a>b_ols <span class="ot">&lt;-</span> b_wls <span class="ot">&lt;-</span> <span class="fu">numeric</span>(B)</span>
<span id="cb93-235"><a href="#cb93-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-236"><a href="#cb93-236" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb93-237"><a href="#cb93-237" aria-hidden="true" tabindex="-1"></a>  x_sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb93-238"><a href="#cb93-238" aria-hidden="true" tabindex="-1"></a>  sigma_sim <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">10</span>, <span class="dv">100</span>), <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">100</span>))</span>
<span id="cb93-239"><a href="#cb93-239" aria-hidden="true" tabindex="-1"></a>  y_sim <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> x_sim <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">200</span>, <span class="dv">0</span>, sigma_sim)</span>
<span id="cb93-240"><a href="#cb93-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-241"><a href="#cb93-241" aria-hidden="true" tabindex="-1"></a>  b_ols[i] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y_sim <span class="sc">~</span> x_sim))[<span class="dv">2</span>]</span>
<span id="cb93-242"><a href="#cb93-242" aria-hidden="true" tabindex="-1"></a>  b_wls[i] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y_sim <span class="sc">~</span> x_sim, <span class="at">weights =</span> <span class="dv">1</span> <span class="sc">/</span> sigma_sim<span class="sc">^</span><span class="dv">2</span>))[<span class="dv">2</span>]</span>
<span id="cb93-243"><a href="#cb93-243" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb93-244"><a href="#cb93-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-245"><a href="#cb93-245" aria-hidden="true" tabindex="-1"></a><span class="co"># Both unbiased, but WLS has much lower variance</span></span>
<span id="cb93-246"><a href="#cb93-246" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">bias_ols =</span> <span class="fu">mean</span>(b_ols) <span class="sc">-</span> <span class="dv">2</span>, <span class="at">bias_wls =</span> <span class="fu">mean</span>(b_wls) <span class="sc">-</span> <span class="dv">2</span>)</span>
<span id="cb93-247"><a href="#cb93-247" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">sd_ols =</span> <span class="fu">sd</span>(b_ols), <span class="at">sd_wls =</span> <span class="fu">sd</span>(b_wls))</span>
<span id="cb93-248"><a href="#cb93-248" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-249"><a href="#cb93-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-250"><a href="#cb93-250" aria-hidden="true" tabindex="-1"></a>Both estimators are unbiased, but WLS standard errors are dramatically smaller. GLS is just common sense: trust precise observations more.</span>
<span id="cb93-251"><a href="#cb93-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-254"><a href="#cb93-254" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-255"><a href="#cb93-255" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: two-group-density</span></span>
<span id="cb93-256"><a href="#cb93-256" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb93-257"><a href="#cb93-257" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb93-258"><a href="#cb93-258" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "OLS vs. WLS sampling distributions: both unbiased, but WLS is tighter"</span></span>
<span id="cb93-259"><a href="#cb93-259" aria-hidden="true" tabindex="-1"></a>df_sim <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb93-260"><a href="#cb93-260" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> <span class="fu">c</span>(b_ols, b_wls),</span>
<span id="cb93-261"><a href="#cb93-261" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"OLS"</span>, <span class="st">"WLS"</span>), <span class="at">each =</span> B)</span>
<span id="cb93-262"><a href="#cb93-262" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-263"><a href="#cb93-263" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_sim, <span class="fu">aes</span>(estimate, <span class="at">fill =</span> method)) <span class="sc">+</span></span>
<span id="cb93-264"><a href="#cb93-264" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb93-265"><a href="#cb93-265" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb93-266"><a href="#cb93-266" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"OLS vs. WLS sampling distributions"</span>,</span>
<span id="cb93-267"><a href="#cb93-267" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Both centered on truth, but WLS is much tighter"</span>,</span>
<span id="cb93-268"><a href="#cb93-268" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="fu">expression</span>(<span class="fu">hat</span>(beta)))</span>
<span id="cb93-269"><a href="#cb93-269" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-270"><a href="#cb93-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-271"><a href="#cb93-271" aria-hidden="true" tabindex="-1"></a><span class="fu">### WLS in R: `lm(..., weights = )`</span></span>
<span id="cb93-272"><a href="#cb93-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-275"><a href="#cb93-275" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-276"><a href="#cb93-276" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: wls-prestige</span></span>
<span id="cb93-277"><a href="#cb93-277" aria-hidden="true" tabindex="-1"></a>mod_ols <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige)</span>
<span id="cb93-278"><a href="#cb93-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-279"><a href="#cb93-279" aria-hidden="true" tabindex="-1"></a><span class="co"># Suppose we know variance is proportional to income</span></span>
<span id="cb93-280"><a href="#cb93-280" aria-hidden="true" tabindex="-1"></a><span class="co"># (higher-income occupations have more variable prestige)</span></span>
<span id="cb93-281"><a href="#cb93-281" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> Prestige<span class="sc">$</span>income</span>
<span id="cb93-282"><a href="#cb93-282" aria-hidden="true" tabindex="-1"></a>mod_wls <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige, <span class="at">weights =</span> w)</span>
<span id="cb93-283"><a href="#cb93-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-284"><a href="#cb93-284" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare coefficients</span></span>
<span id="cb93-285"><a href="#cb93-285" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">OLS =</span> <span class="fu">coef</span>(mod_ols), <span class="at">WLS =</span> <span class="fu">coef</span>(mod_wls))</span>
<span id="cb93-286"><a href="#cb93-286" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-287"><a href="#cb93-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-288"><a href="#cb93-288" aria-hidden="true" tabindex="-1"></a><span class="fu">### WLS as a transformed regression</span></span>
<span id="cb93-289"><a href="#cb93-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-290"><a href="#cb93-290" aria-hidden="true" tabindex="-1"></a>WLS is equivalent to pre-multiplying the model by $W^{1/2}$:</span>
<span id="cb93-291"><a href="#cb93-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-292"><a href="#cb93-292" aria-hidden="true" tabindex="-1"></a>$$W^{1/2} y = W^{1/2} X \beta + W^{1/2} e$$</span>
<span id="cb93-293"><a href="#cb93-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-294"><a href="#cb93-294" aria-hidden="true" tabindex="-1"></a>The transformed errors have variance $W^{1/2} \Omega W^{1/2} = I$ (if $W = \Omega^{-1}$), so OLS on the transformed data is efficient. Let's verify:</span>
<span id="cb93-295"><a href="#cb93-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-298"><a href="#cb93-298" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-299"><a href="#cb93-299" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: wls-transformation</span></span>
<span id="cb93-300"><a href="#cb93-300" aria-hidden="true" tabindex="-1"></a><span class="co"># Manual transformation</span></span>
<span id="cb93-301"><a href="#cb93-301" aria-hidden="true" tabindex="-1"></a>W_half <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="fu">sqrt</span>(w))</span>
<span id="cb93-302"><a href="#cb93-302" aria-hidden="true" tabindex="-1"></a>y_tilde <span class="ot">&lt;-</span> W_half <span class="sc">%*%</span> Prestige<span class="sc">$</span>prestige</span>
<span id="cb93-303"><a href="#cb93-303" aria-hidden="true" tabindex="-1"></a>X_raw <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, Prestige<span class="sc">$</span>education, Prestige<span class="sc">$</span>income, Prestige<span class="sc">$</span>women)</span>
<span id="cb93-304"><a href="#cb93-304" aria-hidden="true" tabindex="-1"></a>X_tilde <span class="ot">&lt;-</span> W_half <span class="sc">%*%</span> X_raw</span>
<span id="cb93-305"><a href="#cb93-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-306"><a href="#cb93-306" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS on transformed data</span></span>
<span id="cb93-307"><a href="#cb93-307" aria-hidden="true" tabindex="-1"></a>beta_transformed <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X_tilde)) <span class="sc">%*%</span> <span class="fu">crossprod</span>(X_tilde, y_tilde)</span>
<span id="cb93-308"><a href="#cb93-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-309"><a href="#cb93-309" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare to lm(..., weights = )</span></span>
<span id="cb93-310"><a href="#cb93-310" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.numeric</span>(beta_transformed), <span class="fu">as.numeric</span>(<span class="fu">coef</span>(mod_wls)))</span>
<span id="cb93-311"><a href="#cb93-311" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-312"><a href="#cb93-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-313"><a href="#cb93-313" aria-hidden="true" tabindex="-1"></a>The transformation approach makes clear what <span class="in">`weights`</span> does: it rescales each observation so that the transformed errors are homoskedastic.</span>
<span id="cb93-314"><a href="#cb93-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-315"><a href="#cb93-315" aria-hidden="true" tabindex="-1"></a>**Important note on the intercept.** After transformation, the column of ones becomes $W^{1/2} \mathbf{1} = (\sqrt{w_1}, \ldots, \sqrt{w_n})'$, which is no longer constant. If you run the transformed regression manually, you must suppress the automatic intercept and include the transformed constant as a regressor:</span>
<span id="cb93-316"><a href="#cb93-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-319"><a href="#cb93-319" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-320"><a href="#cb93-320" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: wls-manual-lm</span></span>
<span id="cb93-321"><a href="#cb93-321" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformed data</span></span>
<span id="cb93-322"><a href="#cb93-322" aria-hidden="true" tabindex="-1"></a>df_t <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb93-323"><a href="#cb93-323" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">as.numeric</span>(y_tilde),</span>
<span id="cb93-324"><a href="#cb93-324" aria-hidden="true" tabindex="-1"></a>  <span class="at">const =</span> <span class="fu">as.numeric</span>(W_half <span class="sc">%*%</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">nrow</span>(Prestige))),</span>
<span id="cb93-325"><a href="#cb93-325" aria-hidden="true" tabindex="-1"></a>  <span class="at">education =</span> <span class="fu">as.numeric</span>(W_half <span class="sc">%*%</span> Prestige<span class="sc">$</span>education),</span>
<span id="cb93-326"><a href="#cb93-326" aria-hidden="true" tabindex="-1"></a>  <span class="at">income =</span> <span class="fu">as.numeric</span>(W_half <span class="sc">%*%</span> Prestige<span class="sc">$</span>income),</span>
<span id="cb93-327"><a href="#cb93-327" aria-hidden="true" tabindex="-1"></a>  <span class="at">women =</span> <span class="fu">as.numeric</span>(W_half <span class="sc">%*%</span> Prestige<span class="sc">$</span>women)</span>
<span id="cb93-328"><a href="#cb93-328" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-329"><a href="#cb93-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-330"><a href="#cb93-330" aria-hidden="true" tabindex="-1"></a><span class="co"># -1 suppresses R's intercept; 'const' is the transformed intercept</span></span>
<span id="cb93-331"><a href="#cb93-331" aria-hidden="true" tabindex="-1"></a>mod_manual <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> const <span class="sc">+</span> education <span class="sc">+</span> income <span class="sc">+</span> women <span class="sc">-</span> <span class="dv">1</span>, <span class="at">data =</span> df_t)</span>
<span id="cb93-332"><a href="#cb93-332" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.numeric</span>(<span class="fu">coef</span>(mod_manual)), <span class="fu">as.numeric</span>(<span class="fu">coef</span>(mod_wls)))</span>
<span id="cb93-333"><a href="#cb93-333" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-334"><a href="#cb93-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-335"><a href="#cb93-335" aria-hidden="true" tabindex="-1"></a><span class="fu">## GLS: The general transformation {#sec-gls}</span></span>
<span id="cb93-336"><a href="#cb93-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-337"><a href="#cb93-337" aria-hidden="true" tabindex="-1"></a>WLS handles the case where $\Omega$ is diagonal (heteroskedasticity only). GLS handles the general case where errors may also be correlated. The key idea is the same: find a transformation $\Omega^{-1/2}$ that sphericizes the errors.</span>
<span id="cb93-338"><a href="#cb93-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-339"><a href="#cb93-339" aria-hidden="true" tabindex="-1"></a><span class="fu">### Eigendecomposition of $\Omega$</span></span>
<span id="cb93-340"><a href="#cb93-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-341"><a href="#cb93-341" aria-hidden="true" tabindex="-1"></a>Any positive definite symmetric matrix can be factored as $\Omega = C \Lambda C'$, where $C$ is the matrix of eigenvectors and $\Lambda$ is diagonal with eigenvalues. Then:</span>
<span id="cb93-342"><a href="#cb93-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-343"><a href="#cb93-343" aria-hidden="true" tabindex="-1"></a>$$\Omega^{-1/2} = C \Lambda^{-1/2} C'$$</span>
<span id="cb93-344"><a href="#cb93-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-347"><a href="#cb93-347" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-348"><a href="#cb93-348" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: eigen-decomposition</span></span>
<span id="cb93-349"><a href="#cb93-349" aria-hidden="true" tabindex="-1"></a><span class="co"># A small example: 4x4 covariance matrix with correlation</span></span>
<span id="cb93-350"><a href="#cb93-350" aria-hidden="true" tabindex="-1"></a>n_small <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb93-351"><a href="#cb93-351" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.6</span></span>
<span id="cb93-352"><a href="#cb93-352" aria-hidden="true" tabindex="-1"></a>Omega_small <span class="ot">&lt;-</span> rho<span class="sc">^</span><span class="fu">abs</span>(<span class="fu">outer</span>(<span class="dv">1</span><span class="sc">:</span>n_small, <span class="dv">1</span><span class="sc">:</span>n_small, <span class="st">"-"</span>))  <span class="co"># AR(1) structure</span></span>
<span id="cb93-353"><a href="#cb93-353" aria-hidden="true" tabindex="-1"></a>Omega_small</span>
<span id="cb93-354"><a href="#cb93-354" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-355"><a href="#cb93-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-358"><a href="#cb93-358" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-359"><a href="#cb93-359" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: omega-inverse-sqrt</span></span>
<span id="cb93-360"><a href="#cb93-360" aria-hidden="true" tabindex="-1"></a>eig <span class="ot">&lt;-</span> <span class="fu">eigen</span>(Omega_small)</span>
<span id="cb93-361"><a href="#cb93-361" aria-hidden="true" tabindex="-1"></a>C <span class="ot">&lt;-</span> eig<span class="sc">$</span>vectors</span>
<span id="cb93-362"><a href="#cb93-362" aria-hidden="true" tabindex="-1"></a>Lambda <span class="ot">&lt;-</span> <span class="fu">diag</span>(eig<span class="sc">$</span>values)</span>
<span id="cb93-363"><a href="#cb93-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-364"><a href="#cb93-364" aria-hidden="true" tabindex="-1"></a><span class="co"># Omega^{-1/2}</span></span>
<span id="cb93-365"><a href="#cb93-365" aria-hidden="true" tabindex="-1"></a>Omega_inv_half <span class="ot">&lt;-</span> C <span class="sc">%*%</span> <span class="fu">diag</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">sqrt</span>(eig<span class="sc">$</span>values)) <span class="sc">%*%</span> <span class="fu">t</span>(C)</span>
<span id="cb93-366"><a href="#cb93-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-367"><a href="#cb93-367" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify: Omega^{-1/2} Omega Omega^{-1/2} = I</span></span>
<span id="cb93-368"><a href="#cb93-368" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(Omega_inv_half <span class="sc">%*%</span> Omega_small <span class="sc">%*%</span> Omega_inv_half, <span class="fu">diag</span>(n_small),</span>
<span id="cb93-369"><a href="#cb93-369" aria-hidden="true" tabindex="-1"></a>          <span class="at">check.attributes =</span> <span class="cn">FALSE</span>)</span>
<span id="cb93-370"><a href="#cb93-370" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-371"><a href="#cb93-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-372"><a href="#cb93-372" aria-hidden="true" tabindex="-1"></a><span class="fu">### GLS formula</span></span>
<span id="cb93-373"><a href="#cb93-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-374"><a href="#cb93-374" aria-hidden="true" tabindex="-1"></a>The GLS estimator pre-multiplies by $\Omega^{-1/2}$, then applies OLS:</span>
<span id="cb93-375"><a href="#cb93-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-376"><a href="#cb93-376" aria-hidden="true" tabindex="-1"></a>$$\hat{\beta}_{GLS} = (X'\Omega^{-1}X)^{-1} X'\Omega^{-1}y$$ {#eq-gls}</span>
<span id="cb93-377"><a href="#cb93-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-378"><a href="#cb93-378" aria-hidden="true" tabindex="-1"></a>Its variance is $\sigma^2(X'\Omega^{-1}X)^{-1}$, which is the efficiency lower bound — no other linear unbiased estimator can do better.</span>
<span id="cb93-379"><a href="#cb93-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-380"><a href="#cb93-380" aria-hidden="true" tabindex="-1"></a>::: {#thm-gls}</span>
<span id="cb93-381"><a href="#cb93-381" aria-hidden="true" tabindex="-1"></a><span class="fu">## GLS Estimator</span></span>
<span id="cb93-382"><a href="#cb93-382" aria-hidden="true" tabindex="-1"></a>The GLS estimator $\hat\beta_{GLS} = (X'\Omega^{-1}X)^{-1}X'\Omega^{-1}y$ is the best linear unbiased estimator (BLUE) when $\text{Var}<span class="co">[</span><span class="ot">e|X</span><span class="co">]</span> = \sigma^2\Omega$. Its variance $\sigma^2(X'\Omega^{-1}X)^{-1}$ achieves the efficiency lower bound among linear unbiased estimators.</span>
<span id="cb93-383"><a href="#cb93-383" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-384"><a href="#cb93-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-385"><a href="#cb93-385" aria-hidden="true" tabindex="-1"></a>::: {#thm-gauss-markov}</span>
<span id="cb93-386"><a href="#cb93-386" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gauss-Markov Theorem</span></span>
<span id="cb93-387"><a href="#cb93-387" aria-hidden="true" tabindex="-1"></a>Under the assumptions $\mathbb{E}<span class="co">[</span><span class="ot">e|X</span><span class="co">]</span> = 0$ and $\text{Var}<span class="co">[</span><span class="ot">e|X</span><span class="co">]</span> = \sigma^2 I$ (homoskedasticity), OLS is BLUE — the Best Linear Unbiased Estimator. No other linear unbiased estimator has smaller variance. When homoskedasticity fails, GLS replaces OLS as BLUE.</span>
<span id="cb93-388"><a href="#cb93-388" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-389"><a href="#cb93-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-390"><a href="#cb93-390" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simulation: GLS with correlated errors</span></span>
<span id="cb93-391"><a href="#cb93-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-394"><a href="#cb93-394" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-395"><a href="#cb93-395" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: gls-ar1-sim</span></span>
<span id="cb93-396"><a href="#cb93-396" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">7</span>)</span>
<span id="cb93-397"><a href="#cb93-397" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">80</span></span>
<span id="cb93-398"><a href="#cb93-398" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.8</span></span>
<span id="cb93-399"><a href="#cb93-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-400"><a href="#cb93-400" aria-hidden="true" tabindex="-1"></a><span class="co"># AR(1) correlation matrix</span></span>
<span id="cb93-401"><a href="#cb93-401" aria-hidden="true" tabindex="-1"></a>Omega <span class="ot">&lt;-</span> rho<span class="sc">^</span><span class="fu">abs</span>(<span class="fu">outer</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="dv">1</span><span class="sc">:</span>n, <span class="st">"-"</span>))</span>
<span id="cb93-402"><a href="#cb93-402" aria-hidden="true" tabindex="-1"></a>Omega_inv <span class="ot">&lt;-</span> <span class="fu">solve</span>(Omega)</span>
<span id="cb93-403"><a href="#cb93-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-404"><a href="#cb93-404" aria-hidden="true" tabindex="-1"></a><span class="co"># Cholesky factor for generating correlated errors</span></span>
<span id="cb93-405"><a href="#cb93-405" aria-hidden="true" tabindex="-1"></a>L <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">chol</span>(Omega))</span>
<span id="cb93-406"><a href="#cb93-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-407"><a href="#cb93-407" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="fu">runif</span>(n, <span class="dv">0</span>, <span class="dv">10</span>))</span>
<span id="cb93-408"><a href="#cb93-408" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x)</span>
<span id="cb93-409"><a href="#cb93-409" aria-hidden="true" tabindex="-1"></a>beta_true <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb93-410"><a href="#cb93-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-411"><a href="#cb93-411" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">3000</span></span>
<span id="cb93-412"><a href="#cb93-412" aria-hidden="true" tabindex="-1"></a>b_ols <span class="ot">&lt;-</span> b_gls <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, B, <span class="dv">2</span>)</span>
<span id="cb93-413"><a href="#cb93-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-414"><a href="#cb93-414" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb93-415"><a href="#cb93-415" aria-hidden="true" tabindex="-1"></a>  e <span class="ot">&lt;-</span> L <span class="sc">%*%</span> <span class="fu">rnorm</span>(n)  <span class="co"># correlated errors</span></span>
<span id="cb93-416"><a href="#cb93-416" aria-hidden="true" tabindex="-1"></a>  y_sim <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta_true <span class="sc">+</span> e</span>
<span id="cb93-417"><a href="#cb93-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-418"><a href="#cb93-418" aria-hidden="true" tabindex="-1"></a>  b_ols[b, ] <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">solve</span>(<span class="fu">crossprod</span>(X)) <span class="sc">%*%</span> <span class="fu">crossprod</span>(X, y_sim))</span>
<span id="cb93-419"><a href="#cb93-419" aria-hidden="true" tabindex="-1"></a>  b_gls[b, ] <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> Omega_inv <span class="sc">%*%</span> X) <span class="sc">%*%</span></span>
<span id="cb93-420"><a href="#cb93-420" aria-hidden="true" tabindex="-1"></a>                              (<span class="fu">t</span>(X) <span class="sc">%*%</span> Omega_inv <span class="sc">%*%</span> y_sim))</span>
<span id="cb93-421"><a href="#cb93-421" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb93-422"><a href="#cb93-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-423"><a href="#cb93-423" aria-hidden="true" tabindex="-1"></a><span class="co"># Both unbiased</span></span>
<span id="cb93-424"><a href="#cb93-424" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(b_ols) <span class="sc">-</span> beta_true</span>
<span id="cb93-425"><a href="#cb93-425" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(b_gls) <span class="sc">-</span> beta_true</span>
<span id="cb93-426"><a href="#cb93-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-427"><a href="#cb93-427" aria-hidden="true" tabindex="-1"></a><span class="co"># But GLS is more efficient (lower SD for slope)</span></span>
<span id="cb93-428"><a href="#cb93-428" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">sd_ols_slope =</span> <span class="fu">sd</span>(b_ols[, <span class="dv">2</span>]), <span class="at">sd_gls_slope =</span> <span class="fu">sd</span>(b_gls[, <span class="dv">2</span>]))</span>
<span id="cb93-429"><a href="#cb93-429" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-430"><a href="#cb93-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-433"><a href="#cb93-433" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-434"><a href="#cb93-434" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: gls-ar1-density</span></span>
<span id="cb93-435"><a href="#cb93-435" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb93-436"><a href="#cb93-436" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb93-437"><a href="#cb93-437" aria-hidden="true" tabindex="-1"></a>df_ar <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb93-438"><a href="#cb93-438" aria-hidden="true" tabindex="-1"></a>  <span class="at">slope =</span> <span class="fu">c</span>(b_ols[, <span class="dv">2</span>], b_gls[, <span class="dv">2</span>]),</span>
<span id="cb93-439"><a href="#cb93-439" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"OLS"</span>, <span class="st">"GLS"</span>), <span class="at">each =</span> B)</span>
<span id="cb93-440"><a href="#cb93-440" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-441"><a href="#cb93-441" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_ar, <span class="fu">aes</span>(slope, <span class="at">fill =</span> method)) <span class="sc">+</span></span>
<span id="cb93-442"><a href="#cb93-442" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb93-443"><a href="#cb93-443" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">2</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb93-444"><a href="#cb93-444" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"OLS vs. GLS with AR(1) errors (ρ = 0.8)"</span>,</span>
<span id="cb93-445"><a href="#cb93-445" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"GLS recovers the efficiency lost to serial correlation"</span>,</span>
<span id="cb93-446"><a href="#cb93-446" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="fu">expression</span>(<span class="fu">hat</span>(beta)[<span class="dv">1</span>]))</span>
<span id="cb93-447"><a href="#cb93-447" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-448"><a href="#cb93-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-449"><a href="#cb93-449" aria-hidden="true" tabindex="-1"></a><span class="fu">### The GLS projection matrix</span></span>
<span id="cb93-450"><a href="#cb93-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-451"><a href="#cb93-451" aria-hidden="true" tabindex="-1"></a>In Chapter 3, we studied $P = X(X'X)^{-1}X'$. The GLS analog replaces the inner product:</span>
<span id="cb93-452"><a href="#cb93-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-453"><a href="#cb93-453" aria-hidden="true" tabindex="-1"></a>$$P_{GLS} = X(X'\Omega^{-1}X)^{-1}X'\Omega^{-1}$$</span>
<span id="cb93-454"><a href="#cb93-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-455"><a href="#cb93-455" aria-hidden="true" tabindex="-1"></a>Unlike the OLS projection, $P_{GLS}$ is **not symmetric** — but it is still idempotent:</span>
<span id="cb93-456"><a href="#cb93-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-459"><a href="#cb93-459" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-460"><a href="#cb93-460" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: gls-projection</span></span>
<span id="cb93-461"><a href="#cb93-461" aria-hidden="true" tabindex="-1"></a>P_gls <span class="ot">&lt;-</span> X <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> Omega_inv <span class="sc">%*%</span> X) <span class="sc">%*%</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> Omega_inv</span>
<span id="cb93-462"><a href="#cb93-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-463"><a href="#cb93-463" aria-hidden="true" tabindex="-1"></a><span class="co"># Not symmetric</span></span>
<span id="cb93-464"><a href="#cb93-464" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">abs</span>(P_gls <span class="sc">-</span> <span class="fu">t</span>(P_gls)))</span>
<span id="cb93-465"><a href="#cb93-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-466"><a href="#cb93-466" aria-hidden="true" tabindex="-1"></a><span class="co"># But idempotent</span></span>
<span id="cb93-467"><a href="#cb93-467" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(P_gls <span class="sc">%*%</span> P_gls, P_gls)</span>
<span id="cb93-468"><a href="#cb93-468" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-469"><a href="#cb93-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-470"><a href="#cb93-470" aria-hidden="true" tabindex="-1"></a><span class="fu">## Feasible GLS</span></span>
<span id="cb93-471"><a href="#cb93-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-472"><a href="#cb93-472" aria-hidden="true" tabindex="-1"></a>GLS requires knowing $\Omega$. In practice, we never know the true variance structure. **Feasible GLS** (FGLS) estimates $\Omega$ from the data in a first step, then applies GLS with $\hat{\Omega}$.</span>
<span id="cb93-473"><a href="#cb93-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-474"><a href="#cb93-474" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step-by-step FGLS for heteroskedasticity</span></span>
<span id="cb93-475"><a href="#cb93-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-476"><a href="#cb93-476" aria-hidden="true" tabindex="-1"></a>The most common approach assumes a **multiplicative heteroskedasticity** model:</span>
<span id="cb93-477"><a href="#cb93-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-478"><a href="#cb93-478" aria-hidden="true" tabindex="-1"></a>$$\sigma_i^2 = \text{Var}<span class="co">[</span><span class="ot">e_i \mid x_i</span><span class="co">]</span> = \exp(\gamma_0 + \gamma_1 z_i)$$</span>
<span id="cb93-479"><a href="#cb93-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-480"><a href="#cb93-480" aria-hidden="true" tabindex="-1"></a>where $z_i$ is some function of $x_i$.</span>
<span id="cb93-481"><a href="#cb93-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-484"><a href="#cb93-484" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-485"><a href="#cb93-485" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fgls-steps</span></span>
<span id="cb93-486"><a href="#cb93-486" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb93-487"><a href="#cb93-487" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">300</span></span>
<span id="cb93-488"><a href="#cb93-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-489"><a href="#cb93-489" aria-hidden="true" tabindex="-1"></a><span class="co"># DGP: variance depends strongly on x</span></span>
<span id="cb93-490"><a href="#cb93-490" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb93-491"><a href="#cb93-491" aria-hidden="true" tabindex="-1"></a>sigma_true <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">*</span> x)  <span class="co"># log-linear variance</span></span>
<span id="cb93-492"><a href="#cb93-492" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(n) <span class="sc">*</span> <span class="fu">sqrt</span>(sigma_true)</span>
<span id="cb93-493"><a href="#cb93-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-494"><a href="#cb93-494" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Run OLS, save residuals</span></span>
<span id="cb93-495"><a href="#cb93-495" aria-hidden="true" tabindex="-1"></a>mod_step1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb93-496"><a href="#cb93-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-497"><a href="#cb93-497" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Regress log(e^2) on x to estimate the variance function</span></span>
<span id="cb93-498"><a href="#cb93-498" aria-hidden="true" tabindex="-1"></a>log_e2 <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">resid</span>(mod_step1)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb93-499"><a href="#cb93-499" aria-hidden="true" tabindex="-1"></a>mod_var <span class="ot">&lt;-</span> <span class="fu">lm</span>(log_e2 <span class="sc">~</span> x)</span>
<span id="cb93-500"><a href="#cb93-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-501"><a href="#cb93-501" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Predicted variances -&gt; weights</span></span>
<span id="cb93-502"><a href="#cb93-502" aria-hidden="true" tabindex="-1"></a>sigma2_hat <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">fitted</span>(mod_var))</span>
<span id="cb93-503"><a href="#cb93-503" aria-hidden="true" tabindex="-1"></a>w_fgls <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> sigma2_hat</span>
<span id="cb93-504"><a href="#cb93-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-505"><a href="#cb93-505" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Run WLS with estimated weights</span></span>
<span id="cb93-506"><a href="#cb93-506" aria-hidden="true" tabindex="-1"></a>mod_fgls <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">weights =</span> w_fgls)</span>
<span id="cb93-507"><a href="#cb93-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-508"><a href="#cb93-508" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">OLS =</span> <span class="fu">coef</span>(mod_step1), <span class="at">FGLS =</span> <span class="fu">coef</span>(mod_fgls), <span class="at">Truth =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>))</span>
<span id="cb93-509"><a href="#cb93-509" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-510"><a href="#cb93-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-511"><a href="#cb93-511" aria-hidden="true" tabindex="-1"></a>Compare standard errors — OLS classical, OLS with HC2, and FGLS:</span>
<span id="cb93-512"><a href="#cb93-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-515"><a href="#cb93-515" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-516"><a href="#cb93-516" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fgls-se-comparison</span></span>
<span id="cb93-517"><a href="#cb93-517" aria-hidden="true" tabindex="-1"></a>X_fgls <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x)</span>
<span id="cb93-518"><a href="#cb93-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-519"><a href="#cb93-519" aria-hidden="true" tabindex="-1"></a>se_compare <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb93-520"><a href="#cb93-520" aria-hidden="true" tabindex="-1"></a>  <span class="at">OLS_classical =</span> <span class="fu">summary</span>(mod_step1)<span class="sc">$</span>coefficients[, <span class="dv">2</span>],</span>
<span id="cb93-521"><a href="#cb93-521" aria-hidden="true" tabindex="-1"></a>  <span class="at">OLS_HC2       =</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">vcovHC</span>(mod_step1, <span class="at">type =</span> <span class="st">"HC2"</span>))),</span>
<span id="cb93-522"><a href="#cb93-522" aria-hidden="true" tabindex="-1"></a>  <span class="at">FGLS          =</span> <span class="fu">summary</span>(mod_fgls)<span class="sc">$</span>coefficients[, <span class="dv">2</span>],</span>
<span id="cb93-523"><a href="#cb93-523" aria-hidden="true" tabindex="-1"></a>  <span class="at">row.names =</span> <span class="fu">c</span>(<span class="st">"(Intercept)"</span>, <span class="st">"x"</span>)</span>
<span id="cb93-524"><a href="#cb93-524" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-525"><a href="#cb93-525" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(se_compare, <span class="dv">4</span>)</span>
<span id="cb93-526"><a href="#cb93-526" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-527"><a href="#cb93-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-528"><a href="#cb93-528" aria-hidden="true" tabindex="-1"></a>HC2 corrects the SE without changing the point estimate. FGLS changes *both* — it re-estimates $\hat{\beta}$ using the variance information, gaining efficiency.</span>
<span id="cb93-529"><a href="#cb93-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-530"><a href="#cb93-530" aria-hidden="true" tabindex="-1"></a><span class="fu">### Implementing FGLS with matrix algebra</span></span>
<span id="cb93-531"><a href="#cb93-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-534"><a href="#cb93-534" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-535"><a href="#cb93-535" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fgls-matrix</span></span>
<span id="cb93-536"><a href="#cb93-536" aria-hidden="true" tabindex="-1"></a>X_mat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x)</span>
<span id="cb93-537"><a href="#cb93-537" aria-hidden="true" tabindex="-1"></a>Omega_hat_inv <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="dv">1</span> <span class="sc">/</span> sigma2_hat)</span>
<span id="cb93-538"><a href="#cb93-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-539"><a href="#cb93-539" aria-hidden="true" tabindex="-1"></a><span class="co"># GLS formula with estimated Omega</span></span>
<span id="cb93-540"><a href="#cb93-540" aria-hidden="true" tabindex="-1"></a>beta_fgls <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">t</span>(X_mat) <span class="sc">%*%</span> Omega_hat_inv <span class="sc">%*%</span> X_mat) <span class="sc">%*%</span></span>
<span id="cb93-541"><a href="#cb93-541" aria-hidden="true" tabindex="-1"></a>             (<span class="fu">t</span>(X_mat) <span class="sc">%*%</span> Omega_hat_inv <span class="sc">%*%</span> y)</span>
<span id="cb93-542"><a href="#cb93-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-543"><a href="#cb93-543" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">as.numeric</span>(beta_fgls), <span class="fu">as.numeric</span>(<span class="fu">coef</span>(mod_fgls)))</span>
<span id="cb93-544"><a href="#cb93-544" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-545"><a href="#cb93-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-546"><a href="#cb93-546" aria-hidden="true" tabindex="-1"></a><span class="fu">### How well does FGLS estimate the variance function?</span></span>
<span id="cb93-547"><a href="#cb93-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-550"><a href="#cb93-550" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-551"><a href="#cb93-551" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fgls-variance-fit</span></span>
<span id="cb93-552"><a href="#cb93-552" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb93-553"><a href="#cb93-553" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb93-554"><a href="#cb93-554" aria-hidden="true" tabindex="-1"></a>df_var <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb93-555"><a href="#cb93-555" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> x,</span>
<span id="cb93-556"><a href="#cb93-556" aria-hidden="true" tabindex="-1"></a>  <span class="at">log_e2 =</span> log_e2,</span>
<span id="cb93-557"><a href="#cb93-557" aria-hidden="true" tabindex="-1"></a>  <span class="at">fitted_log_var =</span> <span class="fu">fitted</span>(mod_var),</span>
<span id="cb93-558"><a href="#cb93-558" aria-hidden="true" tabindex="-1"></a>  <span class="at">true_log_var =</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">*</span> x</span>
<span id="cb93-559"><a href="#cb93-559" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-560"><a href="#cb93-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-561"><a href="#cb93-561" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_var, <span class="fu">aes</span>(x)) <span class="sc">+</span></span>
<span id="cb93-562"><a href="#cb93-562" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> log_e2), <span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb93-563"><a href="#cb93-563" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> fitted_log_var, <span class="at">color =</span> <span class="st">"Estimated"</span>), <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb93-564"><a href="#cb93-564" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> true_log_var, <span class="at">color =</span> <span class="st">"True"</span>), <span class="at">linewidth =</span> <span class="dv">1</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb93-565"><a href="#cb93-565" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"FGLS variance function estimation"</span>,</span>
<span id="cb93-566"><a href="#cb93-566" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Regressing log(ê²) on x recovers the variance structure"</span>,</span>
<span id="cb93-567"><a href="#cb93-567" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"log(σ²)"</span>, <span class="at">color =</span> <span class="cn">NULL</span>)</span>
<span id="cb93-568"><a href="#cb93-568" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-569"><a href="#cb93-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-570"><a href="#cb93-570" aria-hidden="true" tabindex="-1"></a><span class="fu">### Monte Carlo: OLS vs. FGLS efficiency</span></span>
<span id="cb93-571"><a href="#cb93-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-574"><a href="#cb93-574" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-575"><a href="#cb93-575" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fgls-monte-carlo</span></span>
<span id="cb93-576"><a href="#cb93-576" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb93-577"><a href="#cb93-577" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">2000</span></span>
<span id="cb93-578"><a href="#cb93-578" aria-hidden="true" tabindex="-1"></a>b_ols_mc <span class="ot">&lt;-</span> b_fgls_mc <span class="ot">&lt;-</span> <span class="fu">numeric</span>(B)</span>
<span id="cb93-579"><a href="#cb93-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-580"><a href="#cb93-580" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb93-581"><a href="#cb93-581" aria-hidden="true" tabindex="-1"></a>  x_mc <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb93-582"><a href="#cb93-582" aria-hidden="true" tabindex="-1"></a>  sigma_mc <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">*</span> x_mc)</span>
<span id="cb93-583"><a href="#cb93-583" aria-hidden="true" tabindex="-1"></a>  y_mc <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> x_mc <span class="sc">+</span> <span class="fu">rnorm</span>(n) <span class="sc">*</span> <span class="fu">sqrt</span>(sigma_mc)</span>
<span id="cb93-584"><a href="#cb93-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-585"><a href="#cb93-585" aria-hidden="true" tabindex="-1"></a>  <span class="co"># OLS</span></span>
<span id="cb93-586"><a href="#cb93-586" aria-hidden="true" tabindex="-1"></a>  fit_ols <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_mc <span class="sc">~</span> x_mc)</span>
<span id="cb93-587"><a href="#cb93-587" aria-hidden="true" tabindex="-1"></a>  b_ols_mc[b] <span class="ot">&lt;-</span> <span class="fu">coef</span>(fit_ols)[<span class="dv">2</span>]</span>
<span id="cb93-588"><a href="#cb93-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-589"><a href="#cb93-589" aria-hidden="true" tabindex="-1"></a>  <span class="co"># FGLS</span></span>
<span id="cb93-590"><a href="#cb93-590" aria-hidden="true" tabindex="-1"></a>  log_e2_mc <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">resid</span>(fit_ols)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb93-591"><a href="#cb93-591" aria-hidden="true" tabindex="-1"></a>  sigma2_hat_mc <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">fitted</span>(<span class="fu">lm</span>(log_e2_mc <span class="sc">~</span> x_mc)))</span>
<span id="cb93-592"><a href="#cb93-592" aria-hidden="true" tabindex="-1"></a>  b_fgls_mc[b] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y_mc <span class="sc">~</span> x_mc, <span class="at">weights =</span> <span class="dv">1</span> <span class="sc">/</span> sigma2_hat_mc))[<span class="dv">2</span>]</span>
<span id="cb93-593"><a href="#cb93-593" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb93-594"><a href="#cb93-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-595"><a href="#cb93-595" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">sd_ols =</span> <span class="fu">sd</span>(b_ols_mc), <span class="at">sd_fgls =</span> <span class="fu">sd</span>(b_fgls_mc),</span>
<span id="cb93-596"><a href="#cb93-596" aria-hidden="true" tabindex="-1"></a>  <span class="at">efficiency_gain =</span> <span class="fu">sd</span>(b_ols_mc) <span class="sc">/</span> <span class="fu">sd</span>(b_fgls_mc))</span>
<span id="cb93-597"><a href="#cb93-597" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-598"><a href="#cb93-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-599"><a href="#cb93-599" aria-hidden="true" tabindex="-1"></a>Even though FGLS must *estimate* the weights, it still substantially improves on OLS when the heteroskedasticity is strong.</span>
<span id="cb93-600"><a href="#cb93-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-601"><a href="#cb93-601" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb93-602"><a href="#cb93-602" aria-hidden="true" tabindex="-1"></a><span class="fu">## FGLS Requires a Correct Variance Model</span></span>
<span id="cb93-603"><a href="#cb93-603" aria-hidden="true" tabindex="-1"></a>FGLS gains efficiency over OLS + robust SEs only when the variance model is correctly specified. If $\hat\Omega$ is misspecified, FGLS point estimates are still consistent but may be less efficient than OLS, and its reported SEs may be wrong. Use FGLS only when you have a substantive reason to model the variance.</span>
<span id="cb93-604"><a href="#cb93-604" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-605"><a href="#cb93-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-606"><a href="#cb93-606" aria-hidden="true" tabindex="-1"></a><span class="fu">## Two strategies for heteroskedasticity</span></span>
<span id="cb93-607"><a href="#cb93-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-608"><a href="#cb93-608" aria-hidden="true" tabindex="-1"></a>You have two options when errors may be heteroskedastic:</span>
<span id="cb93-609"><a href="#cb93-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-610"><a href="#cb93-610" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Robust SEs (agnostic).** Keep the OLS point estimates and correct only the standard errors with the sandwich formula. Requires no model for the variance — always valid.</span>
<span id="cb93-611"><a href="#cb93-611" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**WLS/FGLS (model-based).** Specify a model for the variance, estimate it, and re-weight. More efficient *if* the variance model is correct; potentially worse if it's misspecified.</span>
<span id="cb93-612"><a href="#cb93-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-613"><a href="#cb93-613" aria-hidden="true" tabindex="-1"></a>A common older workflow was to first *test* for heteroskedasticity (Breusch-Pagan, White's test), then decide whether to apply WLS. This is **pre-testing** — using the same data to choose the estimator and then to estimate — and it distorts the sampling distribution of the final estimate. The resulting "test, then decide" procedure is neither the OLS distribution nor the WLS distribution; its true coverage and size are hard to characterize.</span>
<span id="cb93-614"><a href="#cb93-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-615"><a href="#cb93-615" aria-hidden="true" tabindex="-1"></a>The modern recommendation: **always report robust SEs** (HC2 by default for cross-sectional data). Use WLS/FGLS only when you have a *substantive* reason to model the variance — for instance, when observations are group averages with known group sizes, or when a theoretical model predicts the variance form. The decision to use WLS should come from domain knowledge, not from a hypothesis test on the same data.</span>
<span id="cb93-616"><a href="#cb93-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-617"><a href="#cb93-617" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Breusch-Pagan test (for understanding, not for pre-testing)</span></span>
<span id="cb93-618"><a href="#cb93-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-619"><a href="#cb93-619" aria-hidden="true" tabindex="-1"></a>The Breusch-Pagan test is still useful as a *descriptive* diagnostic — it tells you whether your residuals exhibit systematic patterns in spread. The mechanics are simple: regress $\hat{e}^2 / \bar{\hat{e}^2}$ on $X$ and check whether the $R^2$ is significantly different from zero.</span>
<span id="cb93-620"><a href="#cb93-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-623"><a href="#cb93-623" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-624"><a href="#cb93-624" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: bp-by-hand</span></span>
<span id="cb93-625"><a href="#cb93-625" aria-hidden="true" tabindex="-1"></a>mod_diag <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb93-626"><a href="#cb93-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-627"><a href="#cb93-627" aria-hidden="true" tabindex="-1"></a><span class="co"># Breusch-Pagan by hand</span></span>
<span id="cb93-628"><a href="#cb93-628" aria-hidden="true" tabindex="-1"></a>e2 <span class="ot">&lt;-</span> <span class="fu">resid</span>(mod_diag)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb93-629"><a href="#cb93-629" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> e2 <span class="sc">/</span> <span class="fu">mean</span>(e2)  <span class="co"># normalize by average squared residual</span></span>
<span id="cb93-630"><a href="#cb93-630" aria-hidden="true" tabindex="-1"></a>aux <span class="ot">&lt;-</span> <span class="fu">lm</span>(p <span class="sc">~</span> x)</span>
<span id="cb93-631"><a href="#cb93-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-632"><a href="#cb93-632" aria-hidden="true" tabindex="-1"></a><span class="co"># Test statistic: explained sum of squares / 2</span></span>
<span id="cb93-633"><a href="#cb93-633" aria-hidden="true" tabindex="-1"></a>bp_stat <span class="ot">&lt;-</span> <span class="fu">sum</span>((<span class="fu">fitted</span>(aux) <span class="sc">-</span> <span class="fu">mean</span>(p))<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb93-634"><a href="#cb93-634" aria-hidden="true" tabindex="-1"></a>bp_pval <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pchisq</span>(bp_stat, <span class="at">df =</span> <span class="dv">1</span>)</span>
<span id="cb93-635"><a href="#cb93-635" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">BP_statistic =</span> bp_stat, <span class="at">p_value =</span> bp_pval)</span>
<span id="cb93-636"><a href="#cb93-636" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-637"><a href="#cb93-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-640"><a href="#cb93-640" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-641"><a href="#cb93-641" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: bp-lmtest</span></span>
<span id="cb93-642"><a href="#cb93-642" aria-hidden="true" tabindex="-1"></a><span class="co"># Same thing via lmtest (studentized version is robust to non-normal errors)</span></span>
<span id="cb93-643"><a href="#cb93-643" aria-hidden="true" tabindex="-1"></a><span class="fu">bptest</span>(mod_diag)</span>
<span id="cb93-644"><a href="#cb93-644" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-645"><a href="#cb93-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-646"><a href="#cb93-646" aria-hidden="true" tabindex="-1"></a>A large test statistic tells you heteroskedasticity is present, which is useful information for understanding your data. But the right response is to always use robust SEs — not to condition your estimator on the test result.</span>
<span id="cb93-647"><a href="#cb93-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-648"><a href="#cb93-648" aria-hidden="true" tabindex="-1"></a><span class="fu">## Residual types</span></span>
<span id="cb93-649"><a href="#cb93-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-650"><a href="#cb93-650" aria-hidden="true" tabindex="-1"></a>OLS residuals are $\hat{e} = My$, but they are **not** equal to the true errors. The lecture develops three residual types using projection matrices. Each applies a different diagonal scaling matrix $M^*$ to correct for leverage.</span>
<span id="cb93-651"><a href="#cb93-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-652"><a href="#cb93-652" aria-hidden="true" tabindex="-1"></a><span class="fu">### The matrices</span></span>
<span id="cb93-653"><a href="#cb93-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-656"><a href="#cb93-656" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-657"><a href="#cb93-657" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: residual-matrices</span></span>
<span id="cb93-658"><a href="#cb93-658" aria-hidden="true" tabindex="-1"></a>X_d <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x)</span>
<span id="cb93-659"><a href="#cb93-659" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="fu">ncol</span>(X_d)</span>
<span id="cb93-660"><a href="#cb93-660" aria-hidden="true" tabindex="-1"></a>P_d <span class="ot">&lt;-</span> X_d <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(X_d)) <span class="sc">%*%</span> <span class="fu">t</span>(X_d)</span>
<span id="cb93-661"><a href="#cb93-661" aria-hidden="true" tabindex="-1"></a>M_d <span class="ot">&lt;-</span> <span class="fu">diag</span>(n) <span class="sc">-</span> P_d</span>
<span id="cb93-662"><a href="#cb93-662" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="fu">diag</span>(P_d)  <span class="co"># leverage values</span></span>
<span id="cb93-663"><a href="#cb93-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-664"><a href="#cb93-664" aria-hidden="true" tabindex="-1"></a><span class="co"># M* = diag{(1 - h_ii)^{-1}} — inflates by leverage</span></span>
<span id="cb93-665"><a href="#cb93-665" aria-hidden="true" tabindex="-1"></a>M_star <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> h))</span>
<span id="cb93-666"><a href="#cb93-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-667"><a href="#cb93-667" aria-hidden="true" tabindex="-1"></a><span class="co"># (M*)^{1/2} = diag{(1 - h_ii)^{-1/2}} — square root scaling</span></span>
<span id="cb93-668"><a href="#cb93-668" aria-hidden="true" tabindex="-1"></a>M_star_half <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">-</span> h))</span>
<span id="cb93-669"><a href="#cb93-669" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-670"><a href="#cb93-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-671"><a href="#cb93-671" aria-hidden="true" tabindex="-1"></a>The key relationship: $\text{Var}<span class="co">[</span><span class="ot">\hat{e} \mid X</span><span class="co">]</span> = M \, \text{Var}<span class="co">[</span><span class="ot">e \mid X</span><span class="co">]</span> \, M$. Under homoskedasticity this gives $\text{Var}<span class="co">[</span><span class="ot">\hat{e}_i \mid X</span><span class="co">]</span> = (1 - h_{ii})\sigma^2$, so residuals are heteroskedastic even when the errors are not. The diagonal of $M$ shows the uneven scaling:</span>
<span id="cb93-672"><a href="#cb93-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-675"><a href="#cb93-675" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-676"><a href="#cb93-676" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: leverage-summary</span></span>
<span id="cb93-677"><a href="#cb93-677" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="dv">1</span> <span class="sc">-</span> h)  <span class="co"># ranges from near 0 (high leverage) to near 1</span></span>
<span id="cb93-678"><a href="#cb93-678" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-679"><a href="#cb93-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-680"><a href="#cb93-680" aria-hidden="true" tabindex="-1"></a><span class="fu">### Raw residuals: $\hat{e} = Me$</span></span>
<span id="cb93-681"><a href="#cb93-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-684"><a href="#cb93-684" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-685"><a href="#cb93-685" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: raw-residuals</span></span>
<span id="cb93-686"><a href="#cb93-686" aria-hidden="true" tabindex="-1"></a>e_raw <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(M_d <span class="sc">%*%</span> y)</span>
<span id="cb93-687"><a href="#cb93-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-688"><a href="#cb93-688" aria-hidden="true" tabindex="-1"></a><span class="co"># Same as resid()</span></span>
<span id="cb93-689"><a href="#cb93-689" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(e_raw, <span class="fu">as.numeric</span>(<span class="fu">resid</span>(mod_diag)))</span>
<span id="cb93-690"><a href="#cb93-690" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-691"><a href="#cb93-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-692"><a href="#cb93-692" aria-hidden="true" tabindex="-1"></a><span class="fu">### Prediction errors: $\tilde{e} = M^* \hat{e} = M^* M e$</span></span>
<span id="cb93-693"><a href="#cb93-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-694"><a href="#cb93-694" aria-hidden="true" tabindex="-1"></a>The prediction error $\tilde{e}_i = \hat{e}_i / (1 - h_{ii})$ is the leave-one-out residual from Chapter 4. In matrix form, pre-multiplying by $M^*$ inflates each residual by the inverse of its leverage correction:</span>
<span id="cb93-695"><a href="#cb93-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-698"><a href="#cb93-698" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-699"><a href="#cb93-699" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: prediction-errors</span></span>
<span id="cb93-700"><a href="#cb93-700" aria-hidden="true" tabindex="-1"></a>e_pred <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(M_star <span class="sc">%*%</span> M_d <span class="sc">%*%</span> y)</span>
<span id="cb93-701"><a href="#cb93-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-702"><a href="#cb93-702" aria-hidden="true" tabindex="-1"></a><span class="co"># Equivalently: e_hat / (1 - h)</span></span>
<span id="cb93-703"><a href="#cb93-703" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(e_pred, e_raw <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> h))</span>
<span id="cb93-704"><a href="#cb93-704" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-705"><a href="#cb93-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-706"><a href="#cb93-706" aria-hidden="true" tabindex="-1"></a>Under homoskedasticity, $\text{Var}<span class="co">[</span><span class="ot">\tilde{e}_i \mid X</span><span class="co">]</span> = (1 - h_{ii})^{-1}\sigma^2$. These inflate at high-leverage points — the opposite of raw residuals.</span>
<span id="cb93-707"><a href="#cb93-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-708"><a href="#cb93-708" aria-hidden="true" tabindex="-1"></a><span class="fu">### Standardized residuals: $\bar{e} = (M^*)^{1/2} \hat{e} / \hat{\sigma}$</span></span>
<span id="cb93-709"><a href="#cb93-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-710"><a href="#cb93-710" aria-hidden="true" tabindex="-1"></a>The standardized residual applies the square-root scaling to make residuals have (approximately) unit variance under homoskedasticity:</span>
<span id="cb93-711"><a href="#cb93-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-712"><a href="#cb93-712" aria-hidden="true" tabindex="-1"></a>$$\bar{e} = \frac{1}{\hat{\sigma}}(M^*)^{1/2} M y$$</span>
<span id="cb93-713"><a href="#cb93-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-716"><a href="#cb93-716" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-717"><a href="#cb93-717" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: standardized-residuals</span></span>
<span id="cb93-718"><a href="#cb93-718" aria-hidden="true" tabindex="-1"></a>sigma_hat <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(e_raw<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> (n <span class="sc">-</span> K))</span>
<span id="cb93-719"><a href="#cb93-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-720"><a href="#cb93-720" aria-hidden="true" tabindex="-1"></a>e_std <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(M_star_half <span class="sc">%*%</span> M_d <span class="sc">%*%</span> y) <span class="sc">/</span> sigma_hat</span>
<span id="cb93-721"><a href="#cb93-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-722"><a href="#cb93-722" aria-hidden="true" tabindex="-1"></a><span class="co"># Same as rstandard()</span></span>
<span id="cb93-723"><a href="#cb93-723" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(e_std, <span class="fu">as.numeric</span>(<span class="fu">rstandard</span>(mod_diag)))</span>
<span id="cb93-724"><a href="#cb93-724" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-725"><a href="#cb93-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-726"><a href="#cb93-726" aria-hidden="true" tabindex="-1"></a><span class="fu">### Comparing the three types</span></span>
<span id="cb93-727"><a href="#cb93-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-728"><a href="#cb93-728" aria-hidden="true" tabindex="-1"></a>The three residual types tell different stories. Raw residuals show the fan pattern of heteroskedasticity. Prediction errors *amplify* it — high-leverage observations get inflated further. Standardized residuals divide out the leverage effect, putting everything on a common scale.</span>
<span id="cb93-729"><a href="#cb93-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-732"><a href="#cb93-732" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-733"><a href="#cb93-733" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: residual-comparison</span></span>
<span id="cb93-734"><a href="#cb93-734" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 9</span></span>
<span id="cb93-735"><a href="#cb93-735" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb93-736"><a href="#cb93-736" aria-hidden="true" tabindex="-1"></a>df_resid <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb93-737"><a href="#cb93-737" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">rep</span>(x, <span class="dv">3</span>),</span>
<span id="cb93-738"><a href="#cb93-738" aria-hidden="true" tabindex="-1"></a>  <span class="at">residual =</span> <span class="fu">c</span>(e_raw, e_pred, e_std),</span>
<span id="cb93-739"><a href="#cb93-739" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="fu">factor</span>(<span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"Raw: Me"</span>, <span class="st">"Prediction: M*Me"</span>, <span class="st">"Standardized: (M*)^½Me / σ̂"</span>),</span>
<span id="cb93-740"><a href="#cb93-740" aria-hidden="true" tabindex="-1"></a>                    <span class="at">each =</span> n),</span>
<span id="cb93-741"><a href="#cb93-741" aria-hidden="true" tabindex="-1"></a>                <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Raw: Me"</span>, <span class="st">"Prediction: M*Me"</span>, <span class="st">"Standardized: (M*)^½Me / σ̂"</span>))</span>
<span id="cb93-742"><a href="#cb93-742" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-743"><a href="#cb93-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-744"><a href="#cb93-744" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_resid, <span class="fu">aes</span>(x, residual)) <span class="sc">+</span></span>
<span id="cb93-745"><a href="#cb93-745" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb93-746"><a href="#cb93-746" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb93-747"><a href="#cb93-747" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> type, <span class="at">scales =</span> <span class="st">"free_y"</span>) <span class="sc">+</span></span>
<span id="cb93-748"><a href="#cb93-748" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Three residual types from the same regression"</span>,</span>
<span id="cb93-749"><a href="#cb93-749" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Each panel applies a different diagonal scaling matrix to ê = My"</span>,</span>
<span id="cb93-750"><a href="#cb93-750" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Residual value"</span>)</span>
<span id="cb93-751"><a href="#cb93-751" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-752"><a href="#cb93-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-753"><a href="#cb93-753" aria-hidden="true" tabindex="-1"></a>The fan shape is visible in all three (because the true DGP is heteroskedastic), but the *scale* differs: raw residuals have variance $(1 - h_{ii})\sigma_i^2$, prediction errors have variance $(1 - h_{ii})^{-1}\sigma_i^2$, and standardized residuals remove the leverage component, leaving only the heteroskedasticity $\sigma_i^2 / \sigma^2$.</span>
<span id="cb93-754"><a href="#cb93-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-755"><a href="#cb93-755" aria-hidden="true" tabindex="-1"></a>**Studentized residuals.** R also provides <span class="in">`rstudent()`</span>, which replaces $\hat{\sigma}$ with the leave-one-out estimate $s_{(-i)}$. In practice, studentized and standardized residuals are nearly identical for moderate $n$ — the difference is just one observation's contribution to $\hat{\sigma}^2$. The studentized version follows a $t_{n-K-1}$ distribution under normality, which is useful for formal outlier tests:</span>
<span id="cb93-756"><a href="#cb93-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-759"><a href="#cb93-759" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-760"><a href="#cb93-760" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: studentized-residuals</span></span>
<span id="cb93-761"><a href="#cb93-761" aria-hidden="true" tabindex="-1"></a><span class="co"># Studentized ≈ standardized, but uses leave-one-out sigma</span></span>
<span id="cb93-762"><a href="#cb93-762" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">abs</span>(<span class="fu">rstudent</span>(mod_diag) <span class="sc">-</span> <span class="fu">rstandard</span>(mod_diag)))</span>
<span id="cb93-763"><a href="#cb93-763" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-764"><a href="#cb93-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-765"><a href="#cb93-765" aria-hidden="true" tabindex="-1"></a><span class="fu">## Estimating $\sigma^2$</span></span>
<span id="cb93-766"><a href="#cb93-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-767"><a href="#cb93-767" aria-hidden="true" tabindex="-1"></a>Three estimators of the error variance:</span>
<span id="cb93-768"><a href="#cb93-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-771"><a href="#cb93-771" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-772"><a href="#cb93-772" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: sigma2-estimators</span></span>
<span id="cb93-773"><a href="#cb93-773" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="fu">ncol</span>(X_d)</span>
<span id="cb93-774"><a href="#cb93-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-775"><a href="#cb93-775" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Method of moments (biased)</span></span>
<span id="cb93-776"><a href="#cb93-776" aria-hidden="true" tabindex="-1"></a>sigma2_mm <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod_diag)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> n</span>
<span id="cb93-777"><a href="#cb93-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-778"><a href="#cb93-778" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Bias-corrected (used by summary.lm)</span></span>
<span id="cb93-779"><a href="#cb93-779" aria-hidden="true" tabindex="-1"></a>sigma2_s2 <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">resid</span>(mod_diag)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> (n <span class="sc">-</span> K)</span>
<span id="cb93-780"><a href="#cb93-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-781"><a href="#cb93-781" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Standardized estimator (unbiased under heteroskedasticity)</span></span>
<span id="cb93-782"><a href="#cb93-782" aria-hidden="true" tabindex="-1"></a>sigma2_bar <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">resid</span>(mod_diag)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> h))</span>
<span id="cb93-783"><a href="#cb93-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-784"><a href="#cb93-784" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">MM =</span> sigma2_mm, <span class="at">s2 =</span> sigma2_s2, <span class="at">standardized =</span> sigma2_bar)</span>
<span id="cb93-785"><a href="#cb93-785" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-786"><a href="#cb93-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-787"><a href="#cb93-787" aria-hidden="true" tabindex="-1"></a>Under homoskedasticity, $s^2$ is unbiased: $E<span class="co">[</span><span class="ot">s^2 \mid X</span><span class="co">]</span> = \sigma^2$. The key identity is $E<span class="co">[</span><span class="ot">\hat{e}'\hat{e} \mid X</span><span class="co">]</span> = \text{tr}(M) \cdot \sigma^2 = (n - K)\sigma^2$.</span>
<span id="cb93-788"><a href="#cb93-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-791"><a href="#cb93-791" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-792"><a href="#cb93-792" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: trace-identity</span></span>
<span id="cb93-793"><a href="#cb93-793" aria-hidden="true" tabindex="-1"></a><span class="co"># The trace trick: E[e'Me] = tr(M * E[ee']) = tr(M) * sigma^2 under homoskedasticity</span></span>
<span id="cb93-794"><a href="#cb93-794" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">trace_M =</span> <span class="fu">tr</span>(M_d), <span class="at">n_minus_K =</span> n <span class="sc">-</span> K)</span>
<span id="cb93-795"><a href="#cb93-795" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-796"><a href="#cb93-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-797"><a href="#cb93-797" aria-hidden="true" tabindex="-1"></a>The standardized estimator $\bar{\sigma}^2 = \frac{1}{n}\sum (1-h_{ii})^{-1}\hat{e}_i^2$ is unbiased even under heteroskedasticity — it corrects each squared residual for its leverage. This is the logic behind HC2 standard errors: replace $\hat{e}_i^2$ with $\hat{e}_i^2 / (1 - h_{ii})$ in the sandwich meat.</span>
<span id="cb93-798"><a href="#cb93-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-799"><a href="#cb93-799" aria-hidden="true" tabindex="-1"></a><span class="fu">## Method of moments perspective</span></span>
<span id="cb93-800"><a href="#cb93-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-801"><a href="#cb93-801" aria-hidden="true" tabindex="-1"></a><span class="fu">### OLS as a method of moments estimator</span></span>
<span id="cb93-802"><a href="#cb93-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-803"><a href="#cb93-803" aria-hidden="true" tabindex="-1"></a>OLS solves the sample analog of $E<span class="co">[</span><span class="ot">x_i(y_i - x_i'\beta)</span><span class="co">]</span> = 0$:</span>
<span id="cb93-804"><a href="#cb93-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-805"><a href="#cb93-805" aria-hidden="true" tabindex="-1"></a>$$\frac{1}{n} \sum_{i=1}^n x_i(y_i - x_i'\hat{\beta}) = 0 \quad \Longleftrightarrow \quad X'(y - X\hat{\beta}) = 0$$</span>
<span id="cb93-806"><a href="#cb93-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-809"><a href="#cb93-809" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-810"><a href="#cb93-810" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: ols-moment-condition</span></span>
<span id="cb93-811"><a href="#cb93-811" aria-hidden="true" tabindex="-1"></a><span class="co"># The OLS normal equations are moment conditions</span></span>
<span id="cb93-812"><a href="#cb93-812" aria-hidden="true" tabindex="-1"></a>moment <span class="ot">&lt;-</span> <span class="fu">t</span>(X_d) <span class="sc">%*%</span> <span class="fu">resid</span>(mod_diag)</span>
<span id="cb93-813"><a href="#cb93-813" aria-hidden="true" tabindex="-1"></a>moment  <span class="co"># numerically zero</span></span>
<span id="cb93-814"><a href="#cb93-814" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-815"><a href="#cb93-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-816"><a href="#cb93-816" aria-hidden="true" tabindex="-1"></a><span class="fu">### GLS as efficient method of moments</span></span>
<span id="cb93-817"><a href="#cb93-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-818"><a href="#cb93-818" aria-hidden="true" tabindex="-1"></a>GLS solves a *weighted* version of the same moment condition:</span>
<span id="cb93-819"><a href="#cb93-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-820"><a href="#cb93-820" aria-hidden="true" tabindex="-1"></a>$$\frac{1}{n} \sum_{i=1}^n \frac{1}{\sigma_i^2} x_i(y_i - x_i'\hat{\beta}_{GLS}) = 0 \quad \Longleftrightarrow \quad X'\Omega^{-1}(y - X\hat{\beta}_{GLS}) = 0$$</span>
<span id="cb93-821"><a href="#cb93-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-822"><a href="#cb93-822" aria-hidden="true" tabindex="-1"></a>This is a **generalized method of moments** (GMM) estimator with weight matrix $\Omega^{-1}$.</span>
<span id="cb93-823"><a href="#cb93-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-826"><a href="#cb93-826" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-827"><a href="#cb93-827" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: gls-moment-condition</span></span>
<span id="cb93-828"><a href="#cb93-828" aria-hidden="true" tabindex="-1"></a><span class="co"># GLS normal equations</span></span>
<span id="cb93-829"><a href="#cb93-829" aria-hidden="true" tabindex="-1"></a>Omega_hat_inv_diag <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="dv">1</span> <span class="sc">/</span> sigma2_hat)  <span class="co"># from our FGLS above</span></span>
<span id="cb93-830"><a href="#cb93-830" aria-hidden="true" tabindex="-1"></a>moment_gls <span class="ot">&lt;-</span> <span class="fu">t</span>(X_d) <span class="sc">%*%</span> Omega_hat_inv_diag <span class="sc">%*%</span> <span class="fu">resid</span>(mod_fgls)</span>
<span id="cb93-831"><a href="#cb93-831" aria-hidden="true" tabindex="-1"></a>moment_gls  <span class="co"># numerically zero</span></span>
<span id="cb93-832"><a href="#cb93-832" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-833"><a href="#cb93-833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-834"><a href="#cb93-834" aria-hidden="true" tabindex="-1"></a>When we have exactly as many moment conditions as parameters ($K$ equations, $K$ unknowns), the GMM estimator reduces to method of moments. The efficiency of GLS comes from choosing the optimal weight matrix.</span>
<span id="cb93-835"><a href="#cb93-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-836"><a href="#cb93-836" aria-hidden="true" tabindex="-1"></a>In Chapter 14, we'll see that this logic extends to **overidentified** models: when you have *more* moment conditions than parameters, GMM finds the optimal combination. The GLS insight — weight by precision — is the same insight that drives GMM.</span>
<span id="cb93-837"><a href="#cb93-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-838"><a href="#cb93-838" aria-hidden="true" tabindex="-1"></a><span class="fu">## Application: robust inference on the Prestige data</span></span>
<span id="cb93-839"><a href="#cb93-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-840"><a href="#cb93-840" aria-hidden="true" tabindex="-1"></a>Let's apply the practical workflow to the Prestige dataset. We start with <span class="in">`lm_robust()`</span> as the default — no pre-testing required.</span>
<span id="cb93-841"><a href="#cb93-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-844"><a href="#cb93-844" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-845"><a href="#cb93-845" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: prestige-application</span></span>
<span id="cb93-846"><a href="#cb93-846" aria-hidden="true" tabindex="-1"></a><span class="co"># The default workflow: OLS with HC2 robust SEs</span></span>
<span id="cb93-847"><a href="#cb93-847" aria-hidden="true" tabindex="-1"></a>mod_p_robust <span class="ot">&lt;-</span> <span class="fu">lm_robust</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> women,</span>
<span id="cb93-848"><a href="#cb93-848" aria-hidden="true" tabindex="-1"></a>                           <span class="at">data =</span> Prestige, <span class="at">se_type =</span> <span class="st">"HC2"</span>)</span>
<span id="cb93-849"><a href="#cb93-849" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_p_robust)</span>
<span id="cb93-850"><a href="#cb93-850" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-851"><a href="#cb93-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-852"><a href="#cb93-852" aria-hidden="true" tabindex="-1"></a>That's the complete inference in one line. The residual plot is still useful as a *descriptive* tool for understanding your data — it just shouldn't gate your choice of estimator:</span>
<span id="cb93-853"><a href="#cb93-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-856"><a href="#cb93-856" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-857"><a href="#cb93-857" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: prestige-resid-plot</span></span>
<span id="cb93-858"><a href="#cb93-858" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb93-859"><a href="#cb93-859" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb93-860"><a href="#cb93-860" aria-hidden="true" tabindex="-1"></a>mod_p <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> women, <span class="at">data =</span> Prestige)</span>
<span id="cb93-861"><a href="#cb93-861" aria-hidden="true" tabindex="-1"></a>df_p <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">income =</span> Prestige<span class="sc">$</span>income, <span class="at">resid =</span> <span class="fu">resid</span>(mod_p))</span>
<span id="cb93-862"><a href="#cb93-862" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_p, <span class="fu">aes</span>(income, resid)) <span class="sc">+</span></span>
<span id="cb93-863"><a href="#cb93-863" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb93-864"><a href="#cb93-864" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb93-865"><a href="#cb93-865" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"steelblue"</span>, <span class="at">method =</span> <span class="st">"loess"</span>, <span class="at">formula =</span> y <span class="sc">~</span> x) <span class="sc">+</span></span>
<span id="cb93-866"><a href="#cb93-866" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Prestige: residuals vs. income"</span>,</span>
<span id="cb93-867"><a href="#cb93-867" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Useful for understanding the data, not for choosing an estimator"</span>)</span>
<span id="cb93-868"><a href="#cb93-868" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-869"><a href="#cb93-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-870"><a href="#cb93-870" aria-hidden="true" tabindex="-1"></a>For comparison, here is what FGLS would give if we had a *substantive* reason to believe variance is proportional to income (e.g., because occupational prestige surveys sample more respondents for common jobs):</span>
<span id="cb93-871"><a href="#cb93-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-874"><a href="#cb93-874" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-875"><a href="#cb93-875" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: prestige-fgls</span></span>
<span id="cb93-876"><a href="#cb93-876" aria-hidden="true" tabindex="-1"></a><span class="co"># FGLS: only if we have a theoretical reason for the variance model</span></span>
<span id="cb93-877"><a href="#cb93-877" aria-hidden="true" tabindex="-1"></a>log_e2_p <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">resid</span>(mod_p)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb93-878"><a href="#cb93-878" aria-hidden="true" tabindex="-1"></a>mod_var_p <span class="ot">&lt;-</span> <span class="fu">lm</span>(log_e2_p <span class="sc">~</span> income, <span class="at">data =</span> Prestige)</span>
<span id="cb93-879"><a href="#cb93-879" aria-hidden="true" tabindex="-1"></a>sigma2_hat_p <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">fitted</span>(mod_var_p))</span>
<span id="cb93-880"><a href="#cb93-880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-881"><a href="#cb93-881" aria-hidden="true" tabindex="-1"></a>mod_fgls_p <span class="ot">&lt;-</span> <span class="fu">lm</span>(prestige <span class="sc">~</span> education <span class="sc">+</span> income <span class="sc">+</span> women,</span>
<span id="cb93-882"><a href="#cb93-882" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> Prestige, <span class="at">weights =</span> <span class="dv">1</span> <span class="sc">/</span> sigma2_hat_p)</span>
<span id="cb93-883"><a href="#cb93-883" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-884"><a href="#cb93-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-887"><a href="#cb93-887" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb93-888"><a href="#cb93-888" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: prestige-full-comparison</span></span>
<span id="cb93-889"><a href="#cb93-889" aria-hidden="true" tabindex="-1"></a><span class="co"># Full comparison: coefficients and standard errors</span></span>
<span id="cb93-890"><a href="#cb93-890" aria-hidden="true" tabindex="-1"></a>coefs <span class="ot">&lt;-</span> <span class="fu">cbind</span>(</span>
<span id="cb93-891"><a href="#cb93-891" aria-hidden="true" tabindex="-1"></a>  <span class="at">OLS  =</span> <span class="fu">coef</span>(mod_p),</span>
<span id="cb93-892"><a href="#cb93-892" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC2  =</span> <span class="fu">coef</span>(mod_p),      <span class="co"># same point estimates</span></span>
<span id="cb93-893"><a href="#cb93-893" aria-hidden="true" tabindex="-1"></a>  <span class="at">FGLS =</span> <span class="fu">coef</span>(mod_fgls_p)  <span class="co"># different point estimates</span></span>
<span id="cb93-894"><a href="#cb93-894" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-895"><a href="#cb93-895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-896"><a href="#cb93-896" aria-hidden="true" tabindex="-1"></a>ses <span class="ot">&lt;-</span> <span class="fu">cbind</span>(</span>
<span id="cb93-897"><a href="#cb93-897" aria-hidden="true" tabindex="-1"></a>  <span class="at">Classical =</span> <span class="fu">summary</span>(mod_p)<span class="sc">$</span>coefficients[, <span class="dv">2</span>],</span>
<span id="cb93-898"><a href="#cb93-898" aria-hidden="true" tabindex="-1"></a>  <span class="at">HC2       =</span> <span class="fu">summary</span>(mod_p_robust)<span class="sc">$</span>coefficients[, <span class="dv">2</span>],</span>
<span id="cb93-899"><a href="#cb93-899" aria-hidden="true" tabindex="-1"></a>  <span class="at">FGLS      =</span> <span class="fu">summary</span>(mod_fgls_p)<span class="sc">$</span>coefficients[, <span class="dv">2</span>]</span>
<span id="cb93-900"><a href="#cb93-900" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-901"><a href="#cb93-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-902"><a href="#cb93-902" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Point estimates:</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb93-903"><a href="#cb93-903" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(coefs, <span class="dv">4</span>)</span>
<span id="cb93-904"><a href="#cb93-904" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Standard errors:</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb93-905"><a href="#cb93-905" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(ses, <span class="dv">4</span>)</span>
<span id="cb93-906"><a href="#cb93-906" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb93-907"><a href="#cb93-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-908"><a href="#cb93-908" aria-hidden="true" tabindex="-1"></a>The differences here are modest. The pattern illustrates the two strategies:</span>
<span id="cb93-909"><a href="#cb93-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-910"><a href="#cb93-910" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Robust SEs (HC2)**: Keep the OLS point estimates, correct only the standard errors. No assumptions about the variance structure — always valid.</span>
<span id="cb93-911"><a href="#cb93-911" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**FGLS**: Re-estimate $\hat{\beta}$ using the variance structure. More efficient *if* your variance model is correct; potentially worse if it's wrong.</span>
<span id="cb93-912"><a href="#cb93-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-913"><a href="#cb93-913" aria-hidden="true" tabindex="-1"></a>The default for cross-sectional data is HC2. Use FGLS when you have a substantive reason to model the variance — not because a test told you to.</span>
<span id="cb93-914"><a href="#cb93-914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-915"><a href="#cb93-915" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb93-916"><a href="#cb93-916" aria-hidden="true" tabindex="-1"></a><span class="fu">## HC2 as Default</span></span>
<span id="cb93-917"><a href="#cb93-917" aria-hidden="true" tabindex="-1"></a>For cross-sectional data, use <span class="in">`lm_robust(y ~ x, se_type = "HC2")`</span> or <span class="in">`vcovHC(mod, type = "HC2")`</span> as the default. HC2 adjusts for leverage and provides better finite-sample coverage than HC0 or HC1.</span>
<span id="cb93-918"><a href="#cb93-918" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb93-919"><a href="#cb93-919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-920"><a href="#cb93-920" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb93-921"><a href="#cb93-921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-922"><a href="#cb93-922" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Concept <span class="pp">|</span> Matrix formula <span class="pp">|</span> R code <span class="pp">|</span></span>
<span id="cb93-923"><a href="#cb93-923" aria-hidden="true" tabindex="-1"></a><span class="pp">|---------|---------------|--------|</span></span>
<span id="cb93-924"><a href="#cb93-924" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Sandwich variance <span class="pp">|</span> $(X'X)^{-1}X'\Omega X(X'X)^{-1}$ <span class="pp">|</span> <span class="in">`vcovHC(mod, type = "HC2")`</span> <span class="pp">|</span></span>
<span id="cb93-925"><a href="#cb93-925" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Robust SEs <span class="pp">|</span> $\sqrt{\text{diag}(\hat{V}_{HC})}$ <span class="pp">|</span> <span class="in">`lm_robust(y ~ x, se_type = "HC2")`</span> <span class="pp">|</span></span>
<span id="cb93-926"><a href="#cb93-926" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Robust t-test <span class="pp">|</span> — <span class="pp">|</span> <span class="in">`coeftest(mod, vcov = vcovHC)`</span> <span class="pp">|</span></span>
<span id="cb93-927"><a href="#cb93-927" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> WLS <span class="pp">|</span> $(X'WX)^{-1}X'Wy$ <span class="pp">|</span> <span class="in">`lm(y ~ x, weights = w)`</span> <span class="pp">|</span></span>
<span id="cb93-928"><a href="#cb93-928" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> GLS <span class="pp">|</span> $(X'\Omega^{-1}X)^{-1}X'\Omega^{-1}y$ <span class="pp">|</span> <span class="in">`solve(t(X) %*% Oi %*% X) %*% t(X) %*% Oi %*% y`</span> <span class="pp">|</span></span>
<span id="cb93-929"><a href="#cb93-929" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Eigendecomposition <span class="pp">|</span> $\Omega = C\Lambda C'$ <span class="pp">|</span> <span class="in">`eigen(Omega)`</span> <span class="pp">|</span></span>
<span id="cb93-930"><a href="#cb93-930" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $\Omega^{-1/2}$ <span class="pp">|</span> $C\Lambda^{-1/2}C'$ <span class="pp">|</span> <span class="in">`C %*% diag(1/sqrt(lam)) %*% t(C)`</span> <span class="pp">|</span></span>
<span id="cb93-931"><a href="#cb93-931" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> FGLS <span class="pp">|</span> Estimate $\hat{\Omega}$, then GLS <span class="pp">|</span> <span class="in">`lm(log(e^2) ~ z)`</span> then <span class="in">`lm(y ~ x, weights = ...)`</span> <span class="pp">|</span></span>
<span id="cb93-932"><a href="#cb93-932" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Breusch-Pagan <span class="pp">|</span> $nR^2$ from $\hat{e}^2/\bar{\hat{e}^2} \sim X$ <span class="pp">|</span> <span class="in">`bptest(mod)`</span> <span class="pp">|</span></span>
<span id="cb93-933"><a href="#cb93-933" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Standardized residual <span class="pp">|</span> $\hat{e}_i / (\hat{\sigma}\sqrt{1-h_{ii}})$ <span class="pp">|</span> <span class="in">`rstandard(mod)`</span> <span class="pp">|</span></span>
<span id="cb93-934"><a href="#cb93-934" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Studentized residual <span class="pp">|</span> $\hat{e}_i / (s_{(-i)}\sqrt{1-h_{ii}})$ <span class="pp">|</span> <span class="in">`rstudent(mod)`</span> <span class="pp">|</span></span>
<span id="cb93-935"><a href="#cb93-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-936"><a href="#cb93-936" aria-hidden="true" tabindex="-1"></a>**Key takeaway.** When you know (or can estimate) the variance structure, exploit it: WLS/GLS gives you tighter estimates by trusting precise observations more. When you don't trust your variance model, use <span class="in">`lm_robust()`</span> with HC2 standard errors — it's always valid and requires no assumptions about the form of heteroskedasticity. In either case, the method of moments logic — choosing the right weight matrix — connects directly to GMM (Chapter 14).</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>